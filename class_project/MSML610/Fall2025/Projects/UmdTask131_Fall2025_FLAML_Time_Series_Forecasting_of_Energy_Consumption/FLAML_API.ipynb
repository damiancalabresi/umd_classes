{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4c243a9",
   "metadata": {},
   "source": [
    "---\n",
    "# **FLAML API Demonstration**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75f0ff1-22d3-4ae8-9f14-c77b9f4d0722",
   "metadata": {},
   "source": [
    "This notebook is designed to guide you through the core API functions used in **FLAML (Fast and Lightweight AutoML)** , Microsoft’s efficient, budget-aware automated machine learning library. While the main workflow for your project may live elsewhere, this notebook serves as a **standalone, hands-on companion** that breaks down how FLAML works under the hood and how to use it effectively across different ML tasks.\n",
    "\n",
    "Whether you're new to AutoML or simply curious about how FLAML achieves strong results with minimal computational cost, this notebook walks through the essentials. We’ll explore how FLAML **searches for models**, **manages resources**, **adapts its search space**, and **balances accuracy with efficiency**. Along the way, we’ll demonstrate practical examples for **classification**, **regression**, and **time-series forecasting** using FLAML’s simple yet powerful Python API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3d8d42-30fb-47be-9862-b7ddf26ca513",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## 1. **Introduction**\n",
    "\n",
    "**FLAML (Fast and Lightweight AutoML)** is an open-source Python library developed by Microsoft Research. Its goal is to provide accurate and efficient automated machine learning without the heavy computational overhead typical of other AutoML frameworks.\n",
    "\n",
    "Most AutoML tools are powerful yet computationally heavy. **FLAML solves this problem by offering a budget-aware, resource-optimized, and highly flexible AutoML engine.**\n",
    "\n",
    "<br>\n",
    "This notebook provides a mini-course-style walkthrough of FLAML. By the end, you will understand:\n",
    "\n",
    "- **How FLAML automates model selection and hyperparameter optimization**  \n",
    "- **The design principles that make FLAML lightweight and efficient**  \n",
    "- **The internal logic** (search spaces, pruning, and cost-aware optimization)  \n",
    "- **How to interpret FLAML’s outputs and optimization strategy**  \n",
    "- **Demonstrations** of FLAML applied to classification, regression, and time series tasks  \n",
    "- **When FLAML is a good fit—and when manual tuning may be preferable**  \n",
    "- **How to integrate FLAML into a larger ML workflow or pipeline**\n",
    "\n",
    "If you're exploring AutoML for the first time, don’t worry—each step is explained clearly with practical examples, making this notebook both a **learning resource** and a **practical reference** for real-world ML projects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f44302b",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. **Installation and Setup**\n",
    "\n",
    "Before getting started, install the core libraries used in this notebook.\n",
    "FLAML integrates smoothly with common Python machine learning tools such as scikit-learn, pandas, and matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a271aa88-f17c-4beb-8f0e-04708ef402a1",
   "metadata": {},
   "source": [
    "#### Option 1: Using Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83404f26-33d5-4d0a-9109-0ade9e0bb0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install flaml scikit-learn pandas matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d00e75-49a9-4fbe-b144-83b60fed91ac",
   "metadata": {},
   "source": [
    "#### Option 2: Using a Terminal or Command Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d3f2554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install flaml scikit-learn pandas matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b854cb7-e56f-407d-8e2a-2d207028c696",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## 3. **Understanding FLAML: What It Is and What It Does ?!**\n",
    "\n",
    "FLAML automates the most time-consuming parts of the machine learning workflow—model selection, hyperparameter tuning, and optimization under constraints. \n",
    "\n",
    "Its design focuses on **efficiency, speed, and low computational cost**, making it ideal for both research and production environments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50c8655-186e-49b4-ab9e-f6bc940026b8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.1 **Problems FLAML Solves**\n",
    "\n",
    "Traditional ML workflows often require:\n",
    "\n",
    "- Deep knowledge of many model families  \n",
    "- Expertise in configuring complex hyperparameters  \n",
    "- Repeated cycles of trial-and-error  \n",
    "- Large amounts of experimentation time  \n",
    "\n",
    "FLAML minimizes these requirements by making intelligent, cost-aware decisions that reduce training time while maintaining strong performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1ea01f-4648-426d-8f93-95b62293b51c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.2 **Core Capabilities**\n",
    "\n",
    "#### **✔ Model Selection**\n",
    "\n",
    "FLAML automatically considers and evaluates multiple algorithm families, such as:\n",
    "\n",
    "> LightGBM <br>\n",
    "> XGBoost <br>\n",
    "> Random Forest / Extra Trees <br>\n",
    "> Linear models <br>\n",
    "> Specialized forecasting models <br>\n",
    "\n",
    "It dynamically decides **which models to try and when to stop**, based on performance and cost signals.\n",
    "\n",
    "#### **✔ Hyperparameter Optimization**\n",
    "\n",
    "FLAML performs **cost-aware hyperparameter search**, optimizing for:\n",
    "\n",
    "> Expected performance <br> \n",
    "> Training cost  <br>\n",
    "> Model complexity  <br>\n",
    "> Inference time  <br>\n",
    "\n",
    "This avoids expensive grid/random searches and focuses computation where it matters most.\n",
    "\n",
    "\n",
    "#### **✔ Budget-Constrained Optimization**\n",
    "\n",
    "Users can enforce strict resource constraints, including:\n",
    "\n",
    "> Time budget  <br>\n",
    "> Memory budget <br>\n",
    "> Maximum number of trials<br>\n",
    "> Evaluation metric (accuracy, AUC, MAE, F1, etc.)  <br>\n",
    "\n",
    "FLAML seeks the best possible model **within those limits**, rather than trying to maximize performance at all costs.\n",
    "\n",
    "\n",
    "#### **✔ Supported Tasks**\n",
    "\n",
    "FLAML works seamlessly across diverse ML problems:\n",
    "\n",
    "> **Classification**  <br>\n",
    "> **Regression**  <br>\n",
    "> **Ranking**  <br>\n",
    "> **NLP tasks** (with transformers)  <br>\n",
    "> **Time-series forecasting**  <br>\n",
    "\n",
    "Its flexibility makes it suitable for both structured data and modern deep-learning workflows.\n",
    "\n",
    "\n",
    "#### **✔ Flexible Configuration Options**\n",
    "\n",
    "Advanced users can customize FLAML extensively:\n",
    "\n",
    "> **Estimator list**: restrict or curate which algorithms FLAML tries <br> \n",
    "> **Search space**: define or override hyperparameter ranges  <br>\n",
    "> **Custom metrics**: optimize for domain-specific objectives  <br>\n",
    "> **Custom learners**: integrate your own models into FLAML’s search engine <br> \n",
    "\n",
    "These options let FLAML function as a fully tunable component of larger pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaed1513-5b51-44b9-830e-1d6a0a3156c6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.3 **Why FLAML Matters?**\n",
    "\n",
    "FLAML is designed to be:\n",
    "\n",
    "- **Lightweight** — minimal overhead compared to other AutoML frameworks  \n",
    "- **Fast** — often outperforms Optuna, Hyperopt, and Ray Tune in speed  \n",
    "- **Resource-efficient** — runs well on CPUs and low-cost environments  \n",
    "- **Interpretable** — clear logs, trial histories, and model summaries  \n",
    "- **Pipeline-friendly** — easy integration with scikit-learn and custom workflows  \n",
    "\n",
    "These qualities make FLAML a practical choice for **real-world, budget-conscious machine learning**, from experiments to deployment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6425974-bd18-486c-8678-4257198d819f",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.4 **Understanding FLAML Outputs**\n",
    "FLAML provides several useful attributes after training:\n",
    "\n",
    "- **`best_estimator`** – the algorithm FLAML found to perform best.  \n",
    "- **`best_config`** – the hyperparameter configuration of the best model.  \n",
    "- **`best_loss`** – the lowest achieved value of the metric (for classification accuracy, this is 1 - accuracy).  \n",
    "- **`best_model`** – the trained model object (e.g., a scikit-learn estimator).  \n",
    "- **`leaderboard`** – a pandas DataFrame of all tried models and their scores.  \n",
    "- **`time_taken`** – total time used in the search.  \n",
    "- **`search_state`** – internal details of the search process (advanced usage).  \n",
    "\n",
    "These outputs help us inspect and understand what FLAML did under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37709e8",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## 4. **Example 1 : Task - Classification** (Iris Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3549e7e5",
   "metadata": {},
   "source": [
    "The Iris dataset is a classic dataset in machine learning used for **classification** tasks. In this example, we will use FLAML to automatically find a good model for classifying Iris flowers, all within a short time budget.\n",
    "\n",
    "### What You’ll Learn Here\n",
    "- How to load a dataset and split it into training and testing sets.  \n",
    "- How to set up a FLAML AutoML instance with a time budget and metric.  \n",
    "- How to train and tune models automatically using FLAML.  \n",
    "- How to evaluate the best model and interpret its outputs.\n",
    "\n",
    "### Steps:\n",
    "1. Load the Iris data and split into train/test.\n",
    "2. Create an `AutoML` instance and specify a time budget and metric.\n",
    "3. Call `fit()` to let FLAML train and tune models.\n",
    "4. Evaluate the best model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5990fe5b-c232-4941-9c33-62b7ca951585",
   "metadata": {},
   "source": [
    "---\n",
    "### Code Example: Using FLAML for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71835129-239f-4500-b7b9-287e7da2d363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best estimator: lrl1\n",
      "Best hyperparameters: {'C': np.float64(1.0)}\n",
      "Best loss (metric): 0.025\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Import Relevant Libraries\n",
    "import warnings\n",
    "from flaml import AutoML\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Suppress sklearn warnings (optionally)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load dataset and split\n",
    "X_clf, y_clf = load_iris(return_X_y=True)\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(\n",
    "    X_clf, y_clf, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Set up AutoML with a time budget (seconds) and optimization metric\n",
    "automl = AutoML(log_file_name=\"\", verbose=0)  # Disable logging and info messages (optionally)\n",
    "\n",
    "automl_settings = {\n",
    "    \"time_budget\": 20,            # seconds\n",
    "    \"metric\": \"accuracy\",         # optimize for accuracy\n",
    "    \"task\": \"classification\",     # task type\n",
    "    # \"estimator_list\": [\"lgbm\", \"rf\", \"xgboost\"],  # optional: restrict to specific models\n",
    "}\n",
    "\n",
    "# Fit the model (log_file_name=\"\" disables logging for this run too)\n",
    "automl.fit(X_train=X_train_clf, y_train=y_train_clf, log_file_name=\"\", **automl_settings)\n",
    "\n",
    "# Predictions on test\n",
    "preds = automl.predict(X_test_clf)\n",
    "\n",
    "# Outputs\n",
    "print(\"\\nBest estimator:\", automl.best_estimator)\n",
    "print(\"Best hyperparameters:\", automl.best_config)\n",
    "print(\"Best loss (metric):\", automl.best_loss)\n",
    "print(\"Test accuracy:\", accuracy_score(y_test_clf, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7453bb47-99e8-4e12-ab58-6691bfa20865",
   "metadata": {},
   "source": [
    "---\n",
    "### Output Explanation\n",
    "\n",
    "- **Best estimator:** The model FLAML found to perform best on the training data (here, logistic regression with L1 regularization).\n",
    "- **Best hyperparameters:** The optimal hyperparameter configuration for the chosen model. In this case, the regularization strength `C` is 1.0.\n",
    "- **Best loss (metric):** The value of the loss function corresponding to the best model. Lower values indicate better performance.\n",
    "- **Test accuracy:** How well the selected model performs on unseen test data. A value of 1.0 indicates perfect classification for this split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a0455f-c2ae-4add-9510-275bd2cb8a67",
   "metadata": {},
   "source": [
    "---\n",
    "### Insights for Beginners\n",
    "\n",
    "- **Why use FLAML for classification?** FLAML automatically selects the best classification algorithm (like logistic regression, random forest, or XGBoost) and tunes hyperparameters, saving you from manually testing multiple models.\n",
    "- **Time budget matters:** With a short time budget, FLAML finds reasonably good classifiers quickly. Increasing the budget can allow FLAML to explore more models and hyperparameter combinations, potentially improving accuracy.\n",
    "- **Understanding model choices:** For classification tasks, FLAML may choose simple linear models (like logistic regression) for small datasets or tree-based models (like random forest or XGBoost) for more complex patterns. Reviewing `automl.best_estimator` helps you understand which type of model suits your data.\n",
    "- **Evaluating predictions:** Always check metrics like accuracy, precision, recall, or F1-score depending on your classification problem. FLAML optimizes a chosen metric (`accuracy` here), but you can adapt it for imbalanced datasets.\n",
    "- **Practical tip:** Start with small classification datasets like Iris to get familiar with FLAML’s workflow. Observe which models and hyperparameters are selected to gain intuition for more complex classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c0b839",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## 5. **Example 2 : Task - Regression** (California Housing Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cb3af8",
   "metadata": {},
   "source": [
    "The California Housing dataset is a widely used dataset for regression tasks, where the goal is to predict house prices based on various features. In this example, we will use FLAML to automatically select and tune a regression model within a short time budget.\n",
    "\n",
    "This will show how FLAML handles a larger dataset and a different metric.\n",
    "\n",
    "### What You’ll Learn Here\n",
    "- How to load a regression dataset and split it into training and testing sets.  \n",
    "- How to set up a FLAML AutoML instance for regression tasks.  \n",
    "- How to train and tune models automatically using FLAML.  \n",
    "- How to evaluate the best model using an appropriate regression metric (RMSE).  \n",
    "\n",
    "### Steps\n",
    "1. Load the California Housing dataset and split into train/test sets.  \n",
    "2. Create an AutoML instance and specify a time budget and regression metric.  \n",
    "3. Call `fit()` to let FLAML train and tune models.  \n",
    "4. Evaluate the best model on the test set using RMSE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21832b40-548a-46cf-953f-b20089c58eaa",
   "metadata": {},
   "source": [
    "---\n",
    "### Code Example: Using FLAML for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feef9016-7332-43e6-aff5-61c4e8e81b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best estimator (regression): xgb_limitdepth\n",
      "Best config (regression): {'n_estimators': 740, 'max_depth': 9, 'min_child_weight': np.float64(24.510233543504107), 'learning_rate': np.float64(0.04052344076603214), 'subsample': np.float64(0.8809985595678514), 'colsample_bylevel': np.float64(0.8490633393816673), 'colsample_bytree': np.float64(0.8053272322153723), 'reg_alpha': np.float64(0.006254798766353445), 'reg_lambda': np.float64(0.0887439544402997)}\n",
      "Test RMSE: 0.43432197974277365\n"
     ]
    }
   ],
   "source": [
    "# Import Relevant Libraries\n",
    "from flaml import AutoML\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset and split\n",
    "data = fetch_california_housing()\n",
    "X_reg, y_reg = data.data, data.target\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Set up AutoML for regression\n",
    "automl_reg = AutoML(log_file_name=\"\", verbose=0)  # Disable logging and info messages (optionally)\n",
    "automl_reg.fit(\n",
    "    X_train=X_train_reg, \n",
    "    y_train=y_train_reg, \n",
    "    task=\"regression\", \n",
    "    time_budget=25, \n",
    "    metric=\"rmse\"\n",
    ")\n",
    "\n",
    "# Predictions and evaluation\n",
    "preds_reg = automl_reg.predict(X_test_reg)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_reg, preds_reg))\n",
    "\n",
    "# Outputs\n",
    "print(\"\\nBest estimator (regression):\", automl_reg.best_estimator)\n",
    "print(\"Best config (regression):\", automl_reg.best_config)\n",
    "print(\"Test RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b4b850-8f39-4313-94f0-6daa5a03a280",
   "metadata": {},
   "source": [
    "---\n",
    "### Output Explanation\n",
    "\n",
    "- **Best estimator:** `xgb_limitdepth` — FLAML selected this XGBoost variant with a depth limit as the most effective model for this regression task.  \n",
    "- **Best config:** The optimal hyperparameters found by FLAML, including number of trees (`n_estimators`), tree depth (`max_depth`), learning rate, subsampling ratios, column sampling ratios, and regularization parameters (`reg_alpha` and `reg_lambda`). These settings define the model structure and training behavior.  \n",
    "- **Test RMSE:** `0.4489` — The Root Mean Squared Error on the test set, indicating how far the predicted house prices are from the actual values on average. Lower RMSE means better prediction accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65286551-3958-48fd-9722-7a7694dac3e5",
   "metadata": {},
   "source": [
    "### Insights for Beginners\n",
    "\n",
    "- **Why FLAML picked `xgb_limitdepth`:** For this dataset, a tree-based model with depth constraints balances bias and variance well, which is often effective for regression tasks with non-linear feature relationships.  \n",
    "- **Hyperparameter impact:** Parameters like `max_depth` and `min_child_weight` control tree complexity, while `learning_rate` and `n_estimators` affect training dynamics. Subsampling (`subsample`, `colsample_bytree`) helps prevent overfitting.  \n",
    "- **Interpreting RMSE:** An RMSE of ~0.45 means that, on average, predicted house prices differ from actual prices by roughly 0.45 units (in normalized scale). Use domain knowledge to assess if this is acceptable.  \n",
    "- **Practical tip:** Experimenting with time budgets and allowed models can further improve performance. Reviewing `best_config` helps you understand which hyperparameters FLAML considers optimal for your data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4590bb07-a48a-4ba9-8b8a-97dc308e12d6",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## 6. **Example 3 : Task - Time Series Forecasting** (Synthetic Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572569e8-7092-44e9-b6dc-a7c0ad34fb80",
   "metadata": {},
   "source": [
    "FLAML also supports time series forecasting tasks, handling:\n",
    "- Rolling or expanding windows for training  \n",
    "- Seasonal periods and lags (with the `period` parameter)  \n",
    "- Selecting appropriate models for forecasting (e.g., Prophet, ARIMA, or tree-based models)  \n",
    "\n",
    "In this example, we'll create a synthetic univariate daily time series with seasonality and noise, and use FLAML to forecast future values.\n",
    "\n",
    "### What You’ll Learn Here\n",
    "- How to generate a synthetic time series with seasonality and noise.  \n",
    "- How to split the data into training and testing sets.  \n",
    "- How to set up FLAML for time series forecasting.  \n",
    "- How to forecast future values and evaluate results.  \n",
    "\n",
    "### Steps\n",
    "1. Create a synthetic daily time series with a sine wave and added noise.  \n",
    "2. Split the data into training and test sets.  \n",
    "3. Set up a FLAML AutoML instance for time series forecasting with a specified `period`.  \n",
    "4. Train the model and forecast future values.  \n",
    "5. Inspect the first few predicted values.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076f766d-16cd-4841-bc89-83cb661120ef",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Code Example: Using FLAML for Time Series Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e7a1a31-fd82-4fb7-8c7d-063da1aee09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forecast for first 5 test dates:\n",
      "150    0.488949\n",
      "151    0.364290\n",
      "152    0.222492\n",
      "153    0.056701\n",
      "154    0.018077\n",
      "Name: value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Import Relevant Libraries\n",
    "import logging\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flaml import AutoML\n",
    "\n",
    "# Suppress sklearn warnings (optionally)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Suppress all logging (optionally)\n",
    "logging.disable(logging.INFO)\n",
    "\n",
    "# Create a synthetic time series (sine wave with noise)\n",
    "dates = pd.date_range(\"2020-01-01\", periods=200, freq=\"D\")\n",
    "values = np.sin(np.arange(200) / 10) + np.random.normal(0, 0.2, 200)\n",
    "data_ts = pd.DataFrame({\"date\": dates, \"value\": values})\n",
    "\n",
    "# Split into train and test\n",
    "train_ts = data_ts.iloc[:150]\n",
    "test_ts = data_ts.iloc[150:]\n",
    "\n",
    "# Set up AutoML for forecasting\n",
    "automl_ts = AutoML(log_file_name=\"\", verbose=0)  # Disable logging and info messages (optionally)\n",
    "automl_ts.fit(\n",
    "    X_train=train_ts[[\"date\"]],   # dates as features\n",
    "    y_train=train_ts[\"value\"],    # values to forecast\n",
    "    task=\"ts_forecast\",\n",
    "    time_budget=30,\n",
    "    period=7,                     # assuming weekly seasonality for daily data\n",
    ")\n",
    "\n",
    "# Forecast on the test dates\n",
    "forecast_values = automl_ts.predict(test_ts[[\"date\"]])\n",
    "print(\"\\nForecast for first 5 test dates:\", forecast_values[:5], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db742820-e827-499b-adcf-0acfd5c6fea7",
   "metadata": {},
   "source": [
    "---\n",
    "### Output Explanation\n",
    "\n",
    "- **Forecast values:** Predicted values for the test period. For example, the first few forecasts may look like 0.49, 0.36, 0.22, 0.06, 0.02 (approximate values). Note that these numbers will **change slightly with each run** because the synthetic data includes random noise.  \n",
    "- **Period parameter:** The `period=7` indicates weekly seasonality, which helps FLAML consider repeating patterns in the data.  \n",
    "- **Metric:** By default, FLAML uses MAPE (Mean Absolute Percentage Error) for time series tasks.  \n",
    "- **Model choice:** FLAML automatically selects suitable forecasting models (Prophet, ARIMA, LightGBM, etc.) based on availability, the dataset, and the time budget."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c0fda6-4368-4d0e-875b-a537e214c924",
   "metadata": {},
   "source": [
    "---\n",
    "### Insights for Beginners\n",
    "\n",
    "- **Why FLAML for forecasting?** It automates both model selection and hyperparameter tuning, reducing manual effort and experimentation in time series tasks.  \n",
    "- **Importance of period:** Providing a seasonal period helps FLAML capture regular patterns and improves forecast accuracy.  \n",
    "- **Synthetic data:** Since we added random noise to the sine wave, the forecasts will vary slightly with each run. This is expected and simulates real-world variability.  \n",
    "- **Practical tip:** Visualize the forecasts against actual values to understand trends and deviations. Adjust `period` or increase `time_budget` for potentially better predictions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d290657-1a92-4fb1-9ae1-6fea78f3d779",
   "metadata": {},
   "source": [
    "**Next steps:** You can save the trained AutoML object for reuse, allowing you to forecast new time periods without retraining. See the next section for an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4682eb6-f268-486c-83e5-92b3df2b45ef",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## 7. **Model Persistence: Saving and Loading AutoML Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac85bc1",
   "metadata": {},
   "source": [
    "After training a model with FLAML, you might want to **reuse it later without retraining**. FLAML allows you to save the **entire AutoML object**, which includes:\n",
    "\n",
    "- The best model (`best_model`)\n",
    "- Hyperparameters (`best_config`)\n",
    "- All search results and internal state\n",
    "\n",
    "This makes it easy to **persist your work** and quickly reload it for future predictions across various tasks like **classification, regression, and time series tasks**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952e7beb-053f-4fae-b926-5df4a78c302b",
   "metadata": {},
   "source": [
    "---\n",
    "### Code Example: To Save and Load Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f29da66-56fb-4546-80d6-94489c220dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded classification model test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Import Relevant Libraries\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Save the AutoML object\n",
    "with open(\"automl_clf.pkl\", \"wb\") as f:\n",
    "    pickle.dump(automl, f)\n",
    "\n",
    "# Load the AutoML object back\n",
    "with open(\"automl_clf.pkl\", \"rb\") as f:\n",
    "    automl_clf_loaded = pickle.load(f)\n",
    "\n",
    "# Verify the loaded model works\n",
    "clf_preds = automl_clf_loaded.predict(X_test_clf)\n",
    "print(\"\\nLoaded classification model test accuracy:\", accuracy_score(y_test_clf, clf_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e473f07-7b52-4dd7-bead-215ae06e161c",
   "metadata": {},
   "source": [
    "**Expected Output (classification):**  \n",
    "The test accuracy should be close to the original model’s accuracy (e.g., 1.0 for the Iris dataset), but might slightly vary on different runs if the dataset is small or models have randomness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13a27e6-a7bb-4efc-8166-4adddefa74fa",
   "metadata": {},
   "source": [
    "---\n",
    "### Output Explanation\n",
    "\n",
    "- **Pickle for persistence:** Python’s `pickle` library serializes the AutoML object to disk.  \n",
    "- **Includes everything:** Saving preserves the trained model, best hyperparameters, and FLAML search history.  \n",
    "- **Reload and reuse:** You can load the object anytime to make predictions without retraining.  \n",
    "- **Verify outputs:** Always check predictions to ensure the loaded model works as expected.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a5e71c-4793-4a15-b026-a286d710cea0",
   "metadata": {},
   "source": [
    "---\n",
    "### Insights for Beginners\n",
    "\n",
    "- **Why save the AutoML object?** Retraining can take time, especially for large datasets or complex models. Saving lets you reuse the model instantly.  \n",
    "- **Best practice:** Include versioning or date in filenames (e.g., `automl_clf_2025.pkl`) to track experiments.  \n",
    "- **Other tasks:** The same approach works for **regression** or **time series forecasting** models—just use the respective trained AutoML object.  \n",
    "- **Caution:** Pickle is Python-specific and not safe for untrusted sources. Only load objects you trust.  \n",
    "- **Small dataset note:** For small datasets like Iris, results are usually stable, but slight variations can occur due to random initialization or internal model randomness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f5c3ba-1f94-49f1-bbff-958d98f38344",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## 8. **Integrating FLAML into a Machine Learning Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89134d4",
   "metadata": {},
   "source": [
    "FLAML can be embedded inside a **scikit-learn pipeline**, just like any other estimator. This allows you to combine FLAML's **model selection** with preprocessing or feature engineering steps, ensuring transformations are applied consistently during training and prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925dcbc6-f64b-4896-97fc-f84a1b81c7a8",
   "metadata": {},
   "source": [
    "---\n",
    "### Code Example: Regression Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bcccf0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pipeline regression model test RMSE: 0.4576929514126948\n"
     ]
    }
   ],
   "source": [
    "# Import Relevant Libraries\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from flaml import AutoML\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Create a pipeline with a scaler and AutoML\n",
    "reg_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"automl\", AutoML(log_file_name=\"\", verbose=0))\n",
    "])\n",
    "\n",
    "# Fit the pipeline on regression data\n",
    "reg_pipeline.fit(\n",
    "    X_train_reg, \n",
    "    y_train_reg, \n",
    "    automl__task=\"regression\", \n",
    "    automl__time_budget=15, \n",
    "    automl__metric=\"rmse\"\n",
    ")\n",
    "\n",
    "# Predict and evaluate\n",
    "reg_preds = reg_pipeline.predict(X_test_reg)\n",
    "print(\"\\nPipeline regression model test RMSE:\", np.sqrt(mean_squared_error(y_test_reg, reg_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc27e009-9d40-42ab-b451-03461e4d4072",
   "metadata": {},
   "source": [
    "**Expected Output (regression):**  \n",
    "The RMSE should be close to the value obtained when running AutoML directly (e.g., ~0.45), but it may slightly vary due to internal randomness in the AutoML search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b5c5d1",
   "metadata": {},
   "source": [
    "---\n",
    "### Notes / Insights\n",
    "\n",
    "- **Step parameter syntax:** Use `stepName__param` (e.g., `automl__time_budget`) to pass arguments to the AutoML step in a pipeline.\n",
    "- **Consistency:** Any preprocessing (like scaling) is applied automatically to both training and prediction data.\n",
    "- **Task flexibility:** You can use the same pipeline structure for **classification**, **regression**, and **time series forecasting**.\n",
    "- **Randomness note:** RMSE or predictions may vary slightly between runs due to randomness in model initialization or search.\n",
    "- **Practical tip:** Pipelines are ideal for end-to-end workflows, combining feature transformations, AutoML search, and predictions in a single object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a130f4",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## 9. **Best Practices & Recommendations**\n",
    "\n",
    "**1. FLAML’s strength is *cost-aware* search:** Unlike brute-force hyperparameter tuning, FLAML intelligently balances performance gain against computation cost. This makes the search extremely efficient, often finding good models faster and with less resources.\n",
    "\n",
    "**2. Great for quick prototyping:** FLAML is ideal when you need a strong baseline or a quick solution. It removes a lot of manual tuning, allowing you to get reasonable models with minimal effort.\n",
    "\n",
    "**3. Not a drop-in replacement for expert tuning:** For mission-critical applications or when chasing the last bit of performance, human expertise in feature engineering and tuning can still outperform AutoML. FLAML gives you a strong start, but domain knowledge remains important.\n",
    "\n",
    "**4. Ideal use cases:** FLAML shines for students and practitioners who want to accelerate experiments, for automated ML in pipelines or MLOps, and for problems where time or compute is limited.\n",
    "\n",
    "**5. Continued learning:** Using FLAML is also a learning opportunity. By inspecting `best_config` and `best_estimator`, you can glean which models and hyperparameters work well for your data, informing your future manual model tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962253c2-9865-4b8a-9e4d-5c2753647a9e",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. **Summary and Learning Outcomes**\n",
    "\n",
    "In this notebook, we introduced FLAML and demonstrated how it automates the machine learning workflow:\n",
    "\n",
    "* **AutoML concept:** FLAML selects models and tunes hyperparameters using a cost-aware approach.\n",
    "* **Hands-on examples:** We applied FLAML to classification (Iris dataset), regression (California Housing), and time series forecasting tasks, observing how it finds effective solutions with minimal guidance.\n",
    "* **Integration:** FLAML can be seamlessly embedded in pipelines with preprocessing or feature engineering steps, making it suitable for end-to-end ML workflows.\n",
    "* **Insights:** We discussed when FLAML is most useful and where manual expertise remains valuable.\n",
    "\n",
    "FLAML brings efficient AutoML to everyone. It is a powerful assistant for building models quickly and can save significant time in both learning environments and real-world applications. By leveraging FLAML, you can focus more on understanding the problem and the data, and less on the tedious tuning of models.\n",
    "\n",
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
