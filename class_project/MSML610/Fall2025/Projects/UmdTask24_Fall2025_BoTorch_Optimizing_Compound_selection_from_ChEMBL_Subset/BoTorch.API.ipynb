{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoTorch API Usage Demonstration\n",
    "\n",
    "This notebook demonstrates the use of both the **native BoTorch API** and our **wrapper layer** (`botorch_utils.py`) for multi-objective Bayesian optimization in drug discovery.\n",
    "\n",
    "## Learning Objectives\n",
    "1. Understand native BoTorch API calls\n",
    "2. Learn how the wrapper simplifies common workflows\n",
    "3. Compare direct vs. wrapper-based approaches\n",
    "\n",
    "## Notebook Structure\n",
    "- Part 1: Native BoTorch API Examples\n",
    "- Part 2: Wrapper Layer Examples\n",
    "- Part 3: Complete Workflow Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (if needed)\n",
    "# !pip install botorch gpytorch rdkit pandas numpy scikit-learn matplotlib seaborn\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Native BoTorch API\n",
    "\n",
    "We'll demonstrate core BoTorch functionality step-by-step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 SingleTaskGP - Gaussian Process Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.models import SingleTaskGP\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "# Generate synthetic training data\n",
    "torch.manual_seed(42)\n",
    "n_train = 50\n",
    "n_features = 5\n",
    "\n",
    "X_train = torch.randn(n_train, n_features, dtype=torch.float64)\n",
    "# True function: y = sum(X) + noise\n",
    "y_train = X_train.sum(dim=1, keepdim=True) + 0.1 * torch.randn(n_train, 1, dtype=torch.float64)\n",
    "\n",
    "print(f\"Training data shapes: X={X_train.shape}, y={y_train.shape}\")\n",
    "\n",
    "# Build GP model (native BoTorch)\n",
    "gp_model = SingleTaskGP(X_train, y_train)\n",
    "\n",
    "# Fit hyperparameters\n",
    "mll = ExactMarginalLogLikelihood(gp_model.likelihood, gp_model)\n",
    "fit_gpytorch_mll(mll)\n",
    "\n",
    "print(\"\\nâœ“ GP model trained with native BoTorch API\")\n",
    "print(f\"Model type: {type(gp_model).__name__}\")\n",
    "print(f\"Likelihood noise: {gp_model.likelihood.noise.item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test data\n",
    "X_test = torch.randn(20, n_features, dtype=torch.float64)\n",
    "y_test_true = X_test.sum(dim=1)\n",
    "\n",
    "# Make predictions (native BoTorch)\n",
    "gp_model.eval()\n",
    "with torch.no_grad():\n",
    "    posterior = gp_model.posterior(X_test)\n",
    "    mean = posterior.mean.squeeze(-1)\n",
    "    variance = posterior.variance.squeeze(-1)\n",
    "    std = variance.sqrt()\n",
    "\n",
    "# Compute RÂ²\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test_true.numpy(), mean.numpy())\n",
    "\n",
    "print(f\"Predictions made on {len(X_test)} test points\")\n",
    "print(f\"RÂ² score: {r2:.4f}\")\n",
    "print(f\"\\nFirst 5 predictions:\")\n",
    "for i in range(5):\n",
    "    print(f\"  True: {y_test_true[i].item():6.3f}, Pred: {mean[i].item():6.3f} Â± {std[i].item():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Pareto Front Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.utils.multi_objective.pareto import is_non_dominated\n",
    "\n",
    "# Generate multi-objective data\n",
    "# Objective 1: maximize (higher = better)\n",
    "# Objective 2: maximize -cost (i.e., minimize cost)\n",
    "torch.manual_seed(42)\n",
    "n_candidates = 100\n",
    "\n",
    "# Simulate potency and cost\n",
    "potency = torch.randn(n_candidates) * 2 + 7  # Mean ~7\n",
    "cost = torch.randn(n_candidates) * 0.2 + 0.4  # Mean ~0.4\n",
    "\n",
    "# Stack objectives (both for maximization)\n",
    "objectives = torch.stack([potency, -cost], dim=-1)\n",
    "\n",
    "# Identify Pareto front (native BoTorch)\n",
    "pareto_mask = is_non_dominated(objectives)\n",
    "pareto_indices = torch.where(pareto_mask)[0]\n",
    "\n",
    "print(f\"Total candidates: {n_candidates}\")\n",
    "print(f\"Pareto-optimal: {len(pareto_indices)} ({100*len(pareto_indices)/n_candidates:.1f}%)\")\n",
    "print(f\"\\nTop 5 Pareto-optimal compounds (by potency):\")\n",
    "pareto_potency = potency[pareto_indices]\n",
    "pareto_cost = cost[pareto_indices]\n",
    "sorted_indices = torch.argsort(pareto_potency, descending=True)[:5]\n",
    "for i in sorted_indices:\n",
    "    idx = pareto_indices[i]\n",
    "    print(f\"  Compound {idx.item():3d}: Potency={potency[idx].item():.3f}, Cost={cost[idx].item():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Wrapper Layer API\n",
    "\n",
    "Now we'll demonstrate the same functionality using our simplified wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import wrapper utilities\n",
    "from botorch_utils import (\n",
    "    ChemDataProcessor,\n",
    "    GPSurrogateModel,\n",
    "    MultiObjectiveOptimizer,\n",
    "    StrategyComparator\n",
    ")\n",
    "\n",
    "print(\"âœ“ Wrapper modules imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 GPSurrogateModel - Simplified GP Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same training data as before\n",
    "X_train_np = X_train.numpy()\n",
    "y_train_np = y_train.numpy().flatten()\n",
    "X_test_np = X_test.numpy()\n",
    "\n",
    "# Create and train model using wrapper\n",
    "gp_wrapper = GPSurrogateModel(\n",
    "    feature_cols=[f'feature_{i}' for i in range(n_features)],\n",
    "    target_col='target',\n",
    "    standardize=True\n",
    ")\n",
    "\n",
    "gp_wrapper.fit(X_train_np, y_train_np)\n",
    "\n",
    "# Make predictions\n",
    "predictions, std_devs = gp_wrapper.predict(X_test_np, return_std=True)\n",
    "\n",
    "# Validate\n",
    "metrics = gp_wrapper.validate(X_test_np, y_test_true.numpy())\n",
    "\n",
    "print(f\"\\nâœ“ Model trained and validated using wrapper\")\n",
    "print(f\"RÂ² score: {metrics['r2']:.4f}\")\n",
    "print(f\"RMSE: {metrics['rmse']:.4f}\")\n",
    "print(f\"MAE: {metrics['mae']:.4f}\")\n",
    "\n",
    "# Compare: much cleaner than native API!\n",
    "print(\"\\nðŸ’¡ Wrapper benefits:\")\n",
    "print(\"  - Automatic standardization\")\n",
    "print(\"  - NumPy interface (no manual tensor conversion)\")\n",
    "print(\"  - Built-in validation metrics\")\n",
    "print(\"  - Cleaner API (3 lines vs 8+ lines)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 MultiObjectiveOptimizer - Simplified Multi-Objective BO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic multi-objective data\n",
    "np.random.seed(42)\n",
    "n_samples = 200\n",
    "X_multi = np.random.randn(n_samples, 8)  # 8 features\n",
    "\n",
    "# Objective 1: Potency (maximize)\n",
    "y_potency = X_multi[:, :4].sum(axis=1) + np.random.randn(n_samples) * 0.5 + 7\n",
    "\n",
    "# Objective 2: Cost (minimize)\n",
    "y_cost = np.abs(X_multi[:, 4:].sum(axis=1)) * 0.1 + np.random.randn(n_samples) * 0.1 + 0.4\n",
    "\n",
    "# Stack objectives\n",
    "y_objectives = np.column_stack([y_potency, y_cost])\n",
    "\n",
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_mo, X_test_mo, y_train_mo, y_test_mo = train_test_split(\n",
    "    X_multi, y_objectives, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Create multi-objective optimizer (wrapper)\n",
    "mo_optimizer = MultiObjectiveOptimizer(\n",
    "    objective_names=['potency', 'cost'],\n",
    "    maximize=[True, False]  # maximize potency, minimize cost\n",
    ")\n",
    "\n",
    "# Fit models\n",
    "mo_optimizer.fit_models(X_train_mo, y_train_mo)\n",
    "\n",
    "# Identify Pareto front\n",
    "pareto_idx, pareto_obj = mo_optimizer.identify_pareto_front(X_test_mo)\n",
    "\n",
    "print(f\"\\nâœ“ Multi-objective optimization complete\")\n",
    "print(f\"Found {len(pareto_idx)} Pareto-optimal solutions\")\n",
    "print(f\"\\nTop 3 by potency:\")\n",
    "ranked_idx = mo_optimizer.rank_by_objective(pareto_idx, pareto_obj, objective_idx=0)\n",
    "for i in range(min(3, len(ranked_idx))):\n",
    "    idx = ranked_idx[i]\n",
    "    print(f\"  Potency={pareto_obj[np.where(pareto_idx==idx)[0][0], 0]:.3f}, \"\n",
    "          f\"Cost={pareto_obj[np.where(pareto_idx==idx)[0][0], 1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 ChemDataProcessor - Molecular Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small synthetic molecular dataset\n",
    "synthetic_smiles = [\n",
    "    'CCO',  # Ethanol\n",
    "    'CC(C)O',  # Isopropanol\n",
    "    'c1ccccc1',  # Benzene\n",
    "    'CC(=O)O',  # Acetic acid\n",
    "    'CCN',  # Ethylamine\n",
    "]\n",
    "\n",
    "synthetic_ic50 = [1000, 500, 2000, 800, 300]  # nM\n",
    "\n",
    "df_synthetic = pd.DataFrame({\n",
    "    'canonical_smiles': synthetic_smiles,\n",
    "    'standard_value': synthetic_ic50,\n",
    "    'standard_type': ['IC50'] * len(synthetic_smiles),\n",
    "    'standard_relation': ['='] * len(synthetic_smiles)\n",
    "})\n",
    "\n",
    "# Initialize processor\n",
    "processor = ChemDataProcessor(cost_metric_weights={'mw': 0.5, 'sa': 0.5})\n",
    "\n",
    "# Process data (would normally load from file)\n",
    "# df_clean = processor.load_and_clean_data('data.csv', {})\n",
    "# For demo, we'll use synthetic data\n",
    "df_synthetic['IC50_nM'] = df_synthetic['standard_value']\n",
    "df_synthetic['pIC50'] = -np.log10(df_synthetic['IC50_nM'] * 1e-9)\n",
    "\n",
    "# Calculate descriptors\n",
    "df_with_desc = processor.calculate_descriptors(df_synthetic)\n",
    "\n",
    "# Compute cost metric\n",
    "df_final = processor.compute_cost_metric(df_with_desc)\n",
    "\n",
    "print(\"\\nâœ“ Molecular data processed\")\n",
    "print(\"\\nResults:\")\n",
    "print(df_final[['canonical_smiles', 'pIC50', 'mol_weight', 'sa_score', 'cost_metric']].to_string(index=False))\n",
    "\n",
    "print(\"\\nðŸ’¡ Wrapper automatically handled:\")\n",
    "print(\"  - SMILES validation\")\n",
    "print(\"  - Descriptor calculation (10+ properties)\")\n",
    "print(\"  - Cost metric computation\")\n",
    "print(\"  - Error handling for invalid molecules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Complete Workflow Comparison\n",
    "\n",
    "Let's compare a complete workflow using both approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Native BoTorch Workflow (Manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"NATIVE BOTORCH WORKFLOW\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Step 1: Prepare data manually\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_mo)\n",
    "X_test_scaled = scaler.transform(X_test_mo)\n",
    "\n",
    "# Step 2: Convert to tensors\n",
    "X_train_torch = torch.tensor(X_train_scaled, dtype=torch.float64)\n",
    "y1_train_torch = torch.tensor(y_train_mo[:, 0:1], dtype=torch.float64)\n",
    "y2_train_torch = torch.tensor(-y_train_mo[:, 1:2], dtype=torch.float64)  # Negate for maximization\n",
    "X_test_torch = torch.tensor(X_test_scaled, dtype=torch.float64)\n",
    "\n",
    "# Step 3: Build GP models\n",
    "gp1 = SingleTaskGP(X_train_torch, y1_train_torch)\n",
    "gp2 = SingleTaskGP(X_train_torch, y2_train_torch)\n",
    "\n",
    "# Step 4: Fit hyperparameters\n",
    "mll1 = ExactMarginalLogLikelihood(gp1.likelihood, gp1)\n",
    "fit_gpytorch_mll(mll1)\n",
    "mll2 = ExactMarginalLogLikelihood(gp2.likelihood, gp2)\n",
    "fit_gpytorch_mll(mll2)\n",
    "\n",
    "# Step 5: Make predictions\n",
    "gp1.eval()\n",
    "gp2.eval()\n",
    "with torch.no_grad():\n",
    "    pred1 = gp1.posterior(X_test_torch).mean.squeeze(-1)\n",
    "    pred2 = gp2.posterior(X_test_torch).mean.squeeze(-1)\n",
    "\n",
    "# Step 6: Identify Pareto front\n",
    "objectives_torch = torch.stack([pred1, pred2], dim=-1)\n",
    "pareto_mask_native = is_non_dominated(objectives_torch)\n",
    "pareto_idx_native = torch.where(pareto_mask_native)[0]\n",
    "\n",
    "print(f\"\\nNative BoTorch: {len(pareto_idx_native)} Pareto-optimal compounds\")\n",
    "print(f\"Lines of code: ~25+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Wrapper Workflow (Simplified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"WRAPPER WORKFLOW\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Complete workflow in 5 lines!\n",
    "optimizer_wrapper = MultiObjectiveOptimizer(\n",
    "    objective_names=['potency', 'cost'],\n",
    "    maximize=[True, False]\n",
    ")\n",
    "optimizer_wrapper.fit_models(X_train_mo, y_train_mo)\n",
    "pareto_idx_wrapper, pareto_obj_wrapper = optimizer_wrapper.identify_pareto_front(X_test_mo)\n",
    "\n",
    "print(f\"\\nWrapper: {len(pareto_idx_wrapper)} Pareto-optimal compounds\")\n",
    "print(f\"Lines of code: ~5\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Native BoTorch: ~25+ lines, manual everything\")\n",
    "print(f\"Wrapper:        ~5 lines, automatic everything\")\n",
    "print(f\"\\nâœ“ Both approaches find the same solutions!\")\n",
    "print(f\"âœ“ Wrapper is 5x shorter and much more readable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Native BoTorch API\n",
    "**Pros:**\n",
    "- Full control over all parameters\n",
    "- Access to advanced features\n",
    "- Maximum flexibility\n",
    "\n",
    "**Cons:**\n",
    "- Verbose (lots of boilerplate)\n",
    "- Manual data conversions required\n",
    "- Easy to make mistakes\n",
    "- Steep learning curve\n",
    "\n",
    "### Wrapper Layer\n",
    "**Pros:**\n",
    "- Clean, concise code\n",
    "- Automatic standardization\n",
    "- NumPy interface (no tensor conversions)\n",
    "- Built-in validation\n",
    "- Error handling\n",
    "- Domain-specific utilities (molecular descriptors, etc.)\n",
    "\n",
    "**Cons:**\n",
    "- Less control over low-level details\n",
    "- May not expose all BoTorch features\n",
    "\n",
    "### Recommendation\n",
    "- **Use wrapper** for standard workflows (90% of cases)\n",
    "- **Use native API** when you need advanced features or custom behavior\n",
    "- **Mix both**: Wrapper for setup, then access `model.get_model()` for advanced operations\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. Try the wrapper on your own data\n",
    "2. Customize cost metric weights\n",
    "3. Add custom selection strategies\n",
    "4. Implement active learning loops\n",
    "\n",
    "See `BoTorch.API.md` for complete documentation!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
