{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bf38876",
   "metadata": {},
   "source": [
    "Single-point forecast using the shared `predict_sales` helper\n",
    "\n",
    "In this step I’m just checking that the shared helper functions from `GraphQL_utils.py` work end-to-end.\n",
    "\n",
    "1. I call `load_trained_model_and_features()` which:\n",
    "   * loads the saved RandomForest model,\n",
    "   * rebuilds the full lagged feature table from the raw Kaggle CSVs,\n",
    "   * returns the exact `feature_cols` the model expects.\n",
    "\n",
    "2. I pick one real combination from the data:\n",
    "   * `date_block_num = 1`\n",
    "   * `shop_id = 0`\n",
    "   * `item_id = 30`\n",
    "\n",
    "3. I call the **shared** `predict_sales(...)` helper, passing:\n",
    "   * the model,\n",
    "   * the full lagged table,\n",
    "   * the feature column list,\n",
    "   * and that (shop, item, month) combo.\n",
    "\n",
    "The output I got here is:\n",
    "\n",
    "- **Sample prediction ≈ 2.39 units**\n",
    "\n",
    "This is the same helper that the GraphQL API uses internally, so this cell is basically\n",
    "a quick “does our end-to-end forecasting pipeline actually work?” check before we wrap\n",
    "it behind the API and Docker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83fb1e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lagged shape: (1609124, 10)\n",
      "First feature cols: ['shop_id', 'item_id', 'avg_item_price', 'year', 'month', 'lag_1', 'lag_2', 'lag_3']\n",
      "Testing combo: 1 0 30\n",
      "Sample prediction: 2.393372841806763\n"
     ]
    }
   ],
   "source": [
    "from GraphQL_utils import load_trained_model_and_features, predict_sales\n",
    "\n",
    "# Load model + full lagged feature table\n",
    "model, lagged, feature_cols = load_trained_model_and_features()\n",
    "print(\"Lagged shape:\", lagged.shape)\n",
    "print(\"First feature cols:\", feature_cols[:10])\n",
    "\n",
    "# Take one real (date_block_num, shop_id, item_id) combo\n",
    "sample = lagged[[\"date_block_num\", \"shop_id\", \"item_id\"]].iloc[0]\n",
    "test_block = int(sample[\"date_block_num\"])\n",
    "test_shop  = int(sample[\"shop_id\"])\n",
    "test_item  = int(sample[\"item_id\"])\n",
    "\n",
    "print(\"Testing combo:\", test_block, test_shop, test_item)\n",
    "\n",
    "pred = predict_sales(\n",
    "    model=model,\n",
    "    lagged=lagged,\n",
    "    feature_cols=feature_cols,\n",
    "    shop_id=test_shop,\n",
    "    item_id=test_item,\n",
    "    date_block_num=test_block,\n",
    ")\n",
    "print(\"Sample prediction:\", pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134ec6a2",
   "metadata": {},
   "source": [
    "Install GraphQL / API dependencies\n",
    "\n",
    "In this snippet I install the extra packages needed for the GraphQL and FastAPI parts of the project into the current Jupyter environment\n",
    "I use sys.executable so that pip runs against the same Python that this notebook kernel is using.\n",
    "\n",
    "In practice we just need to run this the first time (or in a fresh environment). After that the packages are already installed and this snippet can be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12a6631c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Ds_Project\\venv\\python.exe\n",
      "Requirement already satisfied: graphene==3.3 in d:\\ds_project\\venv\\lib\\site-packages (3.3)\n",
      "Requirement already satisfied: fastapi in d:\\ds_project\\venv\\lib\\site-packages (0.124.4)\n",
      "Requirement already satisfied: starlette-graphene3 in d:\\ds_project\\venv\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in d:\\ds_project\\venv\\lib\\site-packages (from graphene==3.3) (3.2.7)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in d:\\ds_project\\venv\\lib\\site-packages (from graphene==3.3) (3.2.0)\n",
      "Requirement already satisfied: aniso8601<10,>=8 in d:\\ds_project\\venv\\lib\\site-packages (from graphene==3.3) (9.0.1)\n",
      "Requirement already satisfied: starlette<0.51.0,>=0.40.0 in d:\\ds_project\\venv\\lib\\site-packages (from fastapi) (0.50.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in d:\\ds_project\\venv\\lib\\site-packages (from fastapi) (2.12.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\ds_project\\venv\\lib\\site-packages (from fastapi) (4.15.0)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in d:\\ds_project\\venv\\lib\\site-packages (from fastapi) (0.0.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\ds_project\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in d:\\ds_project\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\ds_project\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.2)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in d:\\ds_project\\venv\\lib\\site-packages (from starlette<0.51.0,>=0.40.0->fastapi) (4.12.0)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\ds_project\\venv\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.51.0,>=0.40.0->fastapi) (3.11)\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "import sys\n",
    "print(sys.executable)\n",
    "!\"{sys.executable}\" -m pip install graphene==3.3 fastapi starlette-graphene3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95d341a",
   "metadata": {},
   "source": [
    "Import GraphQL library for in-notebook tests\n",
    "\n",
    "Here I import graphene, which I use to define a small GraphQL schema directly inside the notebook.\n",
    "\n",
    "This lets me test the predictSales query in memory with schema.execute(...), without actually starting a web server. The “real” HTTP API runs from GraphQL_API.py, but this import is enough for local schema experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1aecc28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "import graphene\n",
    "from fastapi import FastAPI\n",
    "from starlette_graphene3 import GraphQLApp, make_graphiql_handler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab6327c",
   "metadata": {},
   "source": [
    "Import helper to load the trained model + features\n",
    "\n",
    "This snippet imports the main helper function from GraphQL_utils.py:\n",
    "\n",
    "load_trained_model_and_features()\n",
    "\n",
    "That function hides all the messy details and it loads the trained Randomforst model from disk, rebuilds the monthly + lagged tables using the same logic as the training notebook and returns everything already merged together.\n",
    "\n",
    "The notebook doesn’t need to manually rebuild the pipeline as it just calls this helper once and gets the model, the lagged DataFrame, and the list of feature columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea8245f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "import GraphQL_utils\n",
    "from importlib import reload\n",
    "reload(GraphQL_utils)\n",
    "\n",
    "from GraphQL_utils import (\n",
    "    load_trained_model_and_features,\n",
    "    build_base_training_table,\n",
    "    make_lagged_features,\n",
    "    make_train_val_sets,\n",
    "    train_baseline_model,\n",
    "    evaluate_model,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49570994",
   "metadata": {},
   "source": [
    "Load trained model, lagged table, and feature list\n",
    "\n",
    "Here I actually call load_trained_model_and_features() and unpack the result into ->\n",
    "\n",
    "model –> the trained RandomForest regressor\n",
    "\n",
    "lagged –> the full lagged training table (with lags, calendar features, etc.)\n",
    "\n",
    "feature_cols –> the exact list of feature columns, in the order used during training\n",
    "\n",
    "I've also print a bit of information (like the shape of lagged and the feature column names) so I can quickly confirm that everything loaded correctly and matches what I saw in the training notebook.\n",
    "\n",
    "This is the main “setup” step for the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f06f923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model and features\n",
      "Lagged shape: (1609124, 10)\n",
      "Feature cols: ['shop_id', 'item_id', 'avg_item_price', 'year', 'month', 'lag_1', 'lag_2', 'lag_3']\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "from GraphQL_utils import load_trained_model_and_features\n",
    "\n",
    "model, lagged, feature_cols = load_trained_model_and_features()\n",
    "\n",
    "print(\"Loaded model and features\")\n",
    "print(\"Lagged shape:\", lagged.shape)\n",
    "print(\"Feature cols:\", feature_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2859640",
   "metadata": {},
   "source": [
    "Peek at valid (month, shop, item) combinations\n",
    "\n",
    "In this snippet I just inspect the first few rows of the lagged table, but only the date_block_num, shop_id, and item_id columns.\n",
    "\n",
    "The goal is to see some real combinations that actually exist in the data. That makes it easier to pick a valid (shop_id, item_id, date_block_num) for testing, and avoids errors like “no data found for this combination” later when I query the model or the GraphQL schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e26ab7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63224</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63225</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63226</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date_block_num  shop_id  item_id\n",
       "63224               1        0       30\n",
       "63225               1        0       31\n",
       "0                   0        0       32\n",
       "63226               1        0       32\n",
       "1                   0        0       33"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5\n",
    "# Look at some combinations we can use for testing\n",
    "lagged[[\"date_block_num\", \"shop_id\", \"item_id\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69881d63",
   "metadata": {},
   "source": [
    "Helpers to build feature rows and predict sales\n",
    "\n",
    "This snippet defines two important helper functions that I've reused in both the notebook and the API:\n",
    "\n",
    "build_feature_row(shop_id, item_id, date_block_num)\n",
    "\n",
    "Filters the lagged DataFrame to find the row that matches the requested (shop_id, item_id, date_block_num).\n",
    "\n",
    "If no row is found, it raises a clear ValueError so I know the combination is invalid.\n",
    "\n",
    "If rows exist, it takes the first one and builds a 1-row DataFrame containing only feature_cols, in the exact same order the model was trained on.\n",
    "\n",
    "predict_sales(shop_id, item_id, date_block_num)\n",
    "\n",
    "Calls build_feature_row() to build the feature matrix X for that specific combination.\n",
    "\n",
    "Passes X into the trained RandomForest model with model.predict(X).\n",
    "\n",
    "Returns the predicted monthly sales (item_cnt_month) as a plain Python float.\n",
    "\n",
    "Together, these helpers give me path to go from a human-friendly query (shop, item, month) to a model ready feature vector and final numeric prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ca2e644",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "def build_feature_row(shop_id: int, item_id: int, date_block_num: int):\n",
    "    \"\"\"\n",
    "    Find the matching row in `lagged` and return a one-row DataFrame\n",
    "    with the correct feature columns and order.\n",
    "    \"\"\"\n",
    "    # Filter the lagged table\n",
    "    mask = (\n",
    "        (lagged[\"shop_id\"] == shop_id) &\n",
    "        (lagged[\"item_id\"] == item_id) &\n",
    "        (lagged[\"date_block_num\"] == date_block_num)\n",
    "    )\n",
    "    rows = lagged.loc[mask]\n",
    "\n",
    "    if rows.empty:\n",
    "        raise ValueError(\n",
    "            f\"No data found for shop_id={shop_id}, item_id={item_id}, \"\n",
    "            f\"date_block_num={date_block_num}\"\n",
    "        )\n",
    "\n",
    "    # If there are multiple rows, just take the first one\n",
    "    row = rows.iloc[[0]]  # keep it as DataFrame with one row\n",
    "\n",
    "    # Keep only the feature columns, in the same order as training\n",
    "    X = row[feature_cols].copy()\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def predict_sales(shop_id: int, item_id: int, date_block_num: int) -> float:\n",
    "    \"\"\"\n",
    "    Use the trained RandomForest model to predict item_cnt_month\n",
    "    for a given (shop, item, date_block_num).\n",
    "    \"\"\"\n",
    "    X = build_feature_row(shop_id, item_id, date_block_num)\n",
    "    y_pred = model.predict(X)[0]\n",
    "\n",
    "    # Convert numpy scalar to plain float\n",
    "    return float(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1c5ce6",
   "metadata": {},
   "source": [
    "Pick a real (month, shop, item) for testing\n",
    "\n",
    "Here I pick one real example from the lagged table:\n",
    "\n",
    "I take the first row of lagged and keep only date_block_num, shop_id, and item_id,\n",
    "\n",
    "then I print that mini-series so I can see exactly which month, shop, and item I’m about to use.\n",
    "\n",
    "This guarantees I’m using a combination that actually exists in the data, which keeps the later tests simple and avoids “no data found” errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85c28506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_block_num     1\n",
      "shop_id            0\n",
      "item_id           30\n",
      "Name: 63224, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "# Step 1: pick a real (date_block_num, shop_id, item_id) that exists\n",
    "sample = lagged[[\"date_block_num\", \"shop_id\", \"item_id\"]].iloc[0]\n",
    "print(sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41d4dc2",
   "metadata": {},
   "source": [
    "Sanity-check the predict_sales helper\n",
    "\n",
    "Using the sample from snippet 7.\n",
    "\n",
    "Pull out test_date_block, test_shop_id, and test_item_id from the sample row.\n",
    "\n",
    "Print those values so I can see which combination I’m testing.\n",
    "\n",
    "Call pred = predict_sales(test_shop_id, test_item_id, test_date_block).\n",
    "\n",
    "Print the predicted item_cnt_month value.\n",
    "\n",
    "This is a basic end-to-end sanity check: it confirms that the model, the lagged table, and the feature-building logic are all wired together correctly before I involve GraphQL or HTTP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff67f608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using combo: date_block_num = 1 shop_id = 0 item_id = 30\n",
      "Predicted item_cnt_month: 3.419104059723947\n"
     ]
    }
   ],
   "source": [
    "#8\n",
    "# Step 2: use that sample row to test our prediction function\n",
    "\n",
    "test_date_block = int(sample[\"date_block_num\"])\n",
    "test_shop_id    = int(sample[\"shop_id\"])\n",
    "test_item_id    = int(sample[\"item_id\"])\n",
    "\n",
    "print(\"Using combo:\",\n",
    "      \"date_block_num =\", test_date_block,\n",
    "      \"shop_id =\", test_shop_id,\n",
    "      \"item_id =\", test_item_id)\n",
    "\n",
    "pred = predict_sales(test_shop_id, test_item_id, test_date_block)\n",
    "print(\"Predicted item_cnt_month:\", pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd24247a",
   "metadata": {},
   "source": [
    "Define the GraphQL schema for in-notebook use\n",
    "\n",
    "This snippet defines a small GraphQL schema using graphene so I can test queries directly inside the notebook:\n",
    "\n",
    "SalesPredictionType describes the shape of a prediction object, with fields:\n",
    "\n",
    "shop_id\n",
    "\n",
    "item_id\n",
    "\n",
    "date_block_num\n",
    "\n",
    "prediction\n",
    "\n",
    "Query defines a single field called predict_sales (which appears as predictSales to GraphQL clients).\n",
    "It takes three arguments:\n",
    "\n",
    "shop_id (Int, required)\n",
    "\n",
    "item_id (Int, required)\n",
    "\n",
    "date_block_num (Int, required)\n",
    "\n",
    "The resolver resolve_predict_sales:\n",
    "\n",
    "calls the predict_sales(...) helper from snippet 6,\n",
    "\n",
    "and returns a SalesPredictionType object with all fields filled in.\n",
    "\n",
    "Finally, I build schema = graphene.Schema(query=Query), which lets me run queries like schema.execute(query_string) to test the GraphQL layer entirely in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f42a4009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphQL schema ready.\n"
     ]
    }
   ],
   "source": [
    "#9\n",
    "# ---- GraphQL schema (uses our predict_sales helper) ----\n",
    "\n",
    "class SalesPredictionType(graphene.ObjectType):\n",
    "    shop_id = graphene.Int()\n",
    "    item_id = graphene.Int()\n",
    "    date_block_num = graphene.Int()\n",
    "    prediction = graphene.Float()\n",
    "\n",
    "\n",
    "class Query(graphene.ObjectType):\n",
    "    # Graphene will expose this as `predictSales` in the GraphQL schema\n",
    "    predict_sales = graphene.Field(\n",
    "        SalesPredictionType,\n",
    "        shop_id=graphene.Int(required=True),\n",
    "        item_id=graphene.Int(required=True),\n",
    "        date_block_num=graphene.Int(required=True),\n",
    "    )\n",
    "\n",
    "    def resolve_predict_sales(self, info, shop_id, item_id, date_block_num):\n",
    "        # Call our model helper\n",
    "        y = predict_sales(shop_id, item_id, date_block_num)\n",
    "        return SalesPredictionType(\n",
    "            shop_id=shop_id,\n",
    "            item_id=item_id,\n",
    "            date_block_num=date_block_num,\n",
    "            prediction=float(y),\n",
    "        )\n",
    "\n",
    "\n",
    "schema = graphene.Schema(query=Query)\n",
    "print(\"GraphQL schema ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2103c69",
   "metadata": {},
   "source": [
    "Run a GraphQL query directly against the schema\n",
    "\n",
    "In this snippet I build a GraphQL query string that calls:\n",
    "\n",
    "predictSales(shopId: ..., itemId: ..., dateBlockNum: ...)\n",
    "\n",
    "\n",
    "and asks for:\n",
    "\n",
    "shopId\n",
    "\n",
    "itemId\n",
    "\n",
    "dateBlockNum\n",
    "\n",
    "prediction\n",
    "\n",
    "I then run:\n",
    "\n",
    "result = schema.execute(query)\n",
    "\n",
    "\n",
    "This executes the query fully in memory using the schema from snippet 9 and the predict_sales helper from snippet 6.\n",
    "\n",
    "Printing result.data lets me see the same structure I would get from the real HTTP API, but without needing to start a web server. It’s a nice way to confirm that the schema and resolver logic are working correctly.\n",
    "\n",
    "(Separately, I install the requests library in another cell so I can call the real HTTP endpoint in the next snippet.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c7a3727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictSales': {'shopId': 0, 'itemId': 30, 'dateBlockNum': 1, 'prediction': 3.4191040597239457}}\n"
     ]
    }
   ],
   "source": [
    "#10\n",
    "query = \"\"\"\n",
    "{\n",
    "  predictSales(shopId: 0, itemId: 30, dateBlockNum: 1) {\n",
    "    shopId\n",
    "    itemId\n",
    "    dateBlockNum\n",
    "    prediction\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "result = schema.execute(query)\n",
    "print(result.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "395001c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.4-cp312-cp312-win_amd64.whl.metadata (38 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\ds_project\\venv\\lib\\site-packages (from requests) (3.11)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp312-cp312-win_amd64.whl (107 kB)\n",
      "Downloading urllib3-2.6.2-py3-none-any.whl (131 kB)\n",
      "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Installing collected packages: urllib3, charset_normalizer, certifi, requests\n",
      "\n",
      "   ---------------------------------------- 0/4 [urllib3]\n",
      "   ---------- ----------------------------- 1/4 [charset_normalizer]\n",
      "   -------------------- ------------------- 2/4 [certifi]\n",
      "   ------------------------------ --------- 3/4 [requests]\n",
      "   ---------------------------------------- 4/4 [requests]\n",
      "\n",
      "Successfully installed certifi-2025.11.12 charset_normalizer-3.4.4 requests-2.32.5 urllib3-2.6.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip install requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f0c52d",
   "metadata": {},
   "source": [
    "Call the running HTTP GraphQL API (Docker / uvicorn)\n",
    "\n",
    "This is the final end-to-end test: here I act as a real client and call the running GraphQL API over HTTP.\n",
    "\n",
    "Assumptions:\n",
    "\n",
    "The API server is already running, either:\n",
    "\n",
    "via Docker:\n",
    "docker run --rm -p 8000:8000 ecommerce-graphql\n",
    "\n",
    "or via uvicorn directly:\n",
    "uvicorn GraphQL_API:app --reload --port 8000\n",
    "\n",
    "In the snippet I:\n",
    "\n",
    "Set url = \"http://127.0.0.1:8000/graphql\", which is where the server listens.\n",
    "\n",
    "Build the same GraphQL query string as in snippet 11.\n",
    "\n",
    "Use requests.post(url, json={\"query\": query}) to send the query as JSON.\n",
    "\n",
    "Print the HTTP status code (should be 200 if everything is OK).\n",
    "\n",
    "Pretty-print the JSON response with json.dumps(response.json(), indent=2).\n",
    "\n",
    "The prediction field in this JSON is the final model output coming from the Dockerized FastAPI + GraphQL service, which is exactly what the project is meant to demonstrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef60d314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{\n",
      "  \"data\": {\n",
      "    \"predictSales\": {\n",
      "      \"shopId\": 0,\n",
      "      \"itemId\": 30,\n",
      "      \"dateBlockNum\": 1,\n",
      "      \"prediction\": 3.4191040597239457\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#11\n",
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"http://127.0.0.1:8000/graphql\"\n",
    "\n",
    "query = \"\"\"\n",
    "{\n",
    "  predictSales(shopId: 0, itemId: 30, dateBlockNum: 1) {\n",
    "    shopId\n",
    "    itemId\n",
    "    dateBlockNum\n",
    "    prediction\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "response = requests.post(url, json={\"query\": query})\n",
    "print(response.status_code)\n",
    "print(json.dumps(response.json(), indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
