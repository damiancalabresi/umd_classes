{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SBERT Example â€” End-to-End Sentiment Classification\n",
    "\n",
    "This notebook demonstrates an end-to-end example using the SBERT project API:\n",
    "\n",
    "1. Load configuration, cleaned data, and precomputed SBERT embeddings.\n",
    "2. Train a simple classifier (logistic regression) on the embeddings.\n",
    "3. Evaluate sentiment prediction performance on a held-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from src.SBERT_utils import load_config, load_clean_data, load_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (4846, 384)\n",
      "Labels shape: (4846,)\n",
      "Label distribution:\n",
      "  0: 604\n",
      "  1: 2879\n",
      "  2: 1363\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load embeddings and labels from the files produced by preprocess.py and sbert_embed.py\n",
    "X = np.load(\"data/processed/sbert_embeddings.npy\")\n",
    "y = np.load(\"data/processed/labels.npy\")\n",
    "\n",
    "print(\"Embeddings shape:\", X.shape)\n",
    "print(\"Labels shape:\", y.shape)\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print(\"Label distribution:\")\n",
    "for u, c in zip(unique, counts):\n",
    "    print(f\"  {u}: {c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 3876\n",
      "Test size: 970\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y,\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape[0])\n",
    "print(\"Test size:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority class in training set: 1\n",
      "Baseline accuracy (always predict 1): 0.5938\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# majority-class baseline on the test set\n",
    "majority_label = np.bincount(y_train).argmax()\n",
    "baseline_acc = (y_test == majority_label).mean()\n",
    "\n",
    "print(f\"Majority class in training set: {majority_label}\")\n",
    "print(f\"Baseline accuracy (always predict {majority_label}): {baseline_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    multi_class=\"multinomial\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Model trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7629\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6777    0.6777    0.6777       121\n",
      "           1     0.7955    0.8646    0.8286       576\n",
      "           2     0.7175    0.5861    0.6452       273\n",
      "\n",
      "    accuracy                         0.7629       970\n",
      "   macro avg     0.7302    0.7094    0.7172       970\n",
      "weighted avg     0.7589    0.7629    0.7582       970\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 82  29  10]\n",
      " [ 25 498  53]\n",
      " [ 14  99 160]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test accuracy: {acc:.4f}\")\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold CV accuracy scores: [0.75051546 0.7131063  0.74303406 0.75541796 0.7378741 ]\n",
      "Mean accuracy: 0.7399895736916579 +/- 0.014732848628755952\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(\n",
    "    clf,\n",
    "    X,\n",
    "    y,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "print(\"5-fold CV accuracy scores:\", scores)\n",
    "print(\"Mean accuracy:\", scores.mean(), \"+/-\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBERT + LogisticRegression test accuracy: 0.7628865979381443\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "sbert_test_acc = accuracy_score(y_test, y_pred)\n",
    "print(\"SBERT + LogisticRegression test accuracy:\", sbert_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Baseline: TF-IDF + Logistic Regression\n",
    "\n",
    "To understand the value of SBERT embeddings, we compare against a classic baseline:\n",
    "a TF-IDF bag-of-words representation of the same sentences, trained with the\n",
    "same classifier (Logistic Regression) and the same train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4846, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  sentiment  sentiment_int\n",
       "0  According to Gran , the company has no plans t...          1              1\n",
       "1  Technopolis plans to develop in stages an area...          1              1\n",
       "2  The international electronic industry company ...          0              0\n",
       "3  With the new production plant the company woul...          2              2\n",
       "4  According to the company 's updated strategy f...          2              2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.SBERT_utils import load_config, load_clean_data, load_embeddings\n",
    "\n",
    "cfg = load_config(\"config.yaml\")\n",
    "df = load_clean_data(cfg)\n",
    "\n",
    "# Add integer labels if not present\n",
    "df[\"sentiment_int\"] = df[\"sentiment\"].astype(int)\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4846, 15452)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Use the same cleaned dataframe and labels\n",
    "texts = df[\"sentence\"].astype(str).tolist()\n",
    "y_baseline = df[\"sentiment_int\"].values\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2\n",
    ")\n",
    "\n",
    "X_tfidf = tfidf.fit_transform(texts)\n",
    "X_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train/test split (same parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF train size: 3876\n",
      "TF-IDF test size: 970\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(\n",
    "    X_tfidf,\n",
    "    y_baseline,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_baseline,\n",
    ")\n",
    "\n",
    "print(\"TF-IDF train size:\", X_train_tfidf.shape[0])\n",
    "print(\"TF-IDF test size:\", X_test_tfidf.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression on TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF + LogisticRegression test accuracy: 0.7608247422680412\n",
      "\n",
      "TF-IDF classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.69      0.66       121\n",
      "           1       0.82      0.84      0.83       576\n",
      "           2       0.68      0.62      0.65       273\n",
      "\n",
      "    accuracy                           0.76       970\n",
      "   macro avg       0.72      0.72      0.71       970\n",
      "weighted avg       0.76      0.76      0.76       970\n",
      "\n",
      "\n",
      "TF-IDF confusion matrix:\n",
      "[[ 83  27  11]\n",
      " [ 23 486  67]\n",
      " [ 23  81 169]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "logreg_tfidf = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    n_jobs=-1,\n",
    "    class_weight=\"balanced\",\n",
    ")\n",
    "\n",
    "logreg_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "y_pred_tfidf = logreg_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "tfidf_test_acc = accuracy_score(y_test_tfidf, y_pred_tfidf)\n",
    "\n",
    "print(\"TF-IDF + LogisticRegression test accuracy:\", tfidf_test_acc)\n",
    "print(\"\\nTF-IDF classification report:\")\n",
    "print(classification_report(y_test_tfidf, y_pred_tfidf))\n",
    "\n",
    "print(\"\\nTF-IDF confusion matrix:\")\n",
    "print(confusion_matrix(y_test_tfidf, y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBERT + LogisticRegression test accuracy: 0.7628865979381443\n",
      "TF-IDF + LogisticRegression test accuracy: 0.7608247422680412\n",
      "\n",
      "SBERT improvement over TF-IDF: 0.0021 absolute accuracy\n"
     ]
    }
   ],
   "source": [
    "print(\"SBERT + LogisticRegression test accuracy:\", sbert_test_acc)\n",
    "print(\"TF-IDF + LogisticRegression test accuracy:\", tfidf_test_acc)\n",
    "\n",
    "improvement = sbert_test_acc - tfidf_test_acc\n",
    "print(f\"\\nSBERT improvement over TF-IDF: {improvement:.4f} absolute accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Better classifiers on frozen SBERT embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Hyperparameter tuning for SBERT + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 2.0}\n",
      "Tuned SBERT + LogisticRegression test accuracy: 0.7587628865979381\n",
      "\n",
      "Tuned SBERT + LogReg classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.87      0.71       121\n",
      "           1       0.87      0.76      0.81       576\n",
      "           2       0.66      0.70      0.68       273\n",
      "\n",
      "    accuracy                           0.76       970\n",
      "   macro avg       0.71      0.78      0.74       970\n",
      "weighted avg       0.78      0.76      0.76       970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Base model (same as before, but we'll tune C)\n",
    "base_logreg = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,\n",
    "    multi_class=\"auto\",\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"C\": [0.1, 0.5, 1.0, 2.0, 5.0],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=base_logreg,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_logreg = grid.best_estimator_\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "\n",
    "y_pred_best = best_logreg.predict(X_test)\n",
    "best_logreg_acc = accuracy_score(y_test, y_pred_best)\n",
    "print(\"Tuned SBERT + LogisticRegression test accuracy:\", best_logreg_acc)\n",
    "print(\"\\nTuned SBERT + LogReg classification report:\")\n",
    "print(classification_report(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearSVC on SBERT embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBERT + LinearSVC test accuracy: 0.7721649484536083\n",
      "\n",
      "SBERT + LinearSVC classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.83      0.72       121\n",
      "           1       0.85      0.81      0.83       576\n",
      "           2       0.69      0.67      0.68       273\n",
      "\n",
      "    accuracy                           0.77       970\n",
      "   macro avg       0.73      0.77      0.74       970\n",
      "weighted avg       0.78      0.77      0.77       970\n",
      "\n",
      "\n",
      "SBERT + LinearSVC confusion matrix:\n",
      "[[100  13   8]\n",
      " [ 36 467  73]\n",
      " [ 20  71 182]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "svm_clf = LinearSVC(\n",
    "    C=1.0,\n",
    "    class_weight=\"balanced\",\n",
    ")\n",
    "\n",
    "svm_clf.fit(X_train, y_train)\n",
    "y_pred_svm = svm_clf.predict(X_test)\n",
    "\n",
    "svm_acc = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"SBERT + LinearSVC test accuracy:\", svm_acc)\n",
    "print(\"\\nSBERT + LinearSVC classification report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "print(\"\\nSBERT + LinearSVC confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frozen SBERT + base LogReg accuracy: 0.7628865979381443\n",
      "Frozen SBERT + tuned LogReg accuracy: 0.7587628865979381\n",
      "Frozen SBERT + LinearSVC accuracy: 0.7721649484536083\n"
     ]
    }
   ],
   "source": [
    "print(\"Frozen SBERT + base LogReg accuracy:\", sbert_test_acc)\n",
    "print(\"Frozen SBERT + tuned LogReg accuracy:\", best_logreg_acc)\n",
    "print(\"Frozen SBERT + LinearSVC accuracy:\", svm_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fine-tuning SBERT for Financial Sentiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare train/validation splits for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4846, 3)\n",
      "                                            sentence  sentiment  sentiment_int\n",
      "0  According to Gran , the company has no plans t...          1              1\n",
      "1  Technopolis plans to develop in stages an area...          1              1\n",
      "2  The international electronic industry company ...          0              0\n",
      "3  With the new production plant the company woul...          2              2\n",
      "4  According to the company 's updated strategy f...          2              2\n",
      "Num labels: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3876, 970)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Re-use the cleaned dataframe\n",
    "# df should be the same as in the TF-IDF section\n",
    "print(df.shape)\n",
    "print(df.head())\n",
    "\n",
    "texts = df[\"sentence\"].astype(str).tolist()\n",
    "labels = df[\"sentiment_int\"].astype(int).tolist()\n",
    "num_labels = len(sorted(set(labels)))\n",
    "print(\"Num labels:\", num_labels)\n",
    "\n",
    "X_train_text, X_val_text, y_train_label, y_val_label = train_test_split(\n",
    "    texts,\n",
    "    labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=labels,\n",
    ")\n",
    "\n",
    "len(X_train_text), len(X_val_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizer + PyTorch Dataset/DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "class FinanceSentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "train_dataset = FinanceSentimentDataset(X_train_text, y_train_label, tokenizer)\n",
    "val_dataset   = FinanceSentimentDataset(X_val_text,   y_val_label,   tokenizer)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and train the classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L6-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 step 100/243 loss=0.8696\n",
      "Epoch 1 step 200/243 loss=0.4249\n",
      "Epoch 1 average training loss: 0.7622\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "num_epochs = 1  # keep small, this is just a demo\n",
    "log_every = 100\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if (step + 1) % log_every == 0:\n",
    "            print(f\"Epoch {epoch+1} step {step+1}/{len(train_loader)} \"\n",
    "                  f\"loss={loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1} average training loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned SBERT (end-to-end) validation accuracy: 0.790721649484536\n",
      "\n",
      "Fine-tuned SBERT classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.81      0.73       121\n",
      "           1       0.81      0.91      0.86       576\n",
      "           2       0.82      0.52      0.64       273\n",
      "\n",
      "    accuracy                           0.79       970\n",
      "   macro avg       0.77      0.75      0.74       970\n",
      "weighted avg       0.80      0.79      0.78       970\n",
      "\n",
      "\n",
      "Fine-tuned SBERT confusion matrix:\n",
      "[[ 98  19   4]\n",
      " [ 23 526  27]\n",
      " [ 27 103 143]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        labels = batch[\"labels\"].numpy()\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "finetuned_acc = accuracy_score(all_labels, all_preds)\n",
    "print(\"Fine-tuned SBERT (end-to-end) validation accuracy:\", finetuned_acc)\n",
    "print(\"\\nFine-tuned SBERT classification report:\")\n",
    "print(classification_report(all_labels, all_preds))\n",
    "print(\"\\nFine-tuned SBERT confusion matrix:\")\n",
    "print(confusion_matrix(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frozen SBERT + base LogReg accuracy: 0.7628865979381443\n",
      "Frozen SBERT + tuned LogReg accuracy: 0.7587628865979381\n",
      "Frozen SBERT + LinearSVC accuracy: 0.7721649484536083\n",
      "TF-IDF + LogReg accuracy: 0.7608247422680412\n",
      "Fine-tuned SBERT (end-to-end) accuracy (val set): 0.790721649484536\n"
     ]
    }
   ],
   "source": [
    "print(\"Frozen SBERT + base LogReg accuracy:\", sbert_test_acc)\n",
    "print(\"Frozen SBERT + tuned LogReg accuracy:\", best_logreg_acc)\n",
    "print(\"Frozen SBERT + LinearSVC accuracy:\", svm_acc)\n",
    "print(\"TF-IDF + LogReg accuracy:\", tfidf_test_acc)\n",
    "print(\"Fine-tuned SBERT (end-to-end) accuracy (val set):\", finetuned_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_env)",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
