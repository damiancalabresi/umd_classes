{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DeepSpeed API - Minimal Demonstration\n",
        "\n",
        "This notebook provides a minimal demonstration of DeepSpeed APIs for distributed training.\n",
        "\n",
        "## Overview\n",
        "\n",
        "We'll cover:\n",
        "1. DeepSpeed configuration creation\n",
        "2. Model initialization with DeepSpeed\n",
        "3. ZeRO optimization stages\n",
        "4. Basic usage patterns\n",
        "\n",
        "For complete examples, see `DeepSpeed_FSDP.example_experiments.ipynb`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import json\n",
        "import torch\n",
        "import deepspeed\n",
        "from transformers import ViTForImageClassification\n",
        "\n",
        "# Import utility functions\n",
        "from DeepSpeed_FSDP_utils import (\n",
        "    load_vit_model,\n",
        "    create_deepspeed_config,\n",
        "    save_deepspeed_config,\n",
        "    initialize_deepspeed_model,\n",
        "    get_gpu_memory_stats\n",
        ")\n",
        "\n",
        "print(\"[OK] Imports successful!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Creating DeepSpeed Configurations\n",
        "\n",
        "DeepSpeed uses JSON configuration files to specify optimization settings. We'll create configs for different ZeRO stages.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create ZeRO Stage 2 configuration\n",
        "config_stage2 = create_deepspeed_config(\n",
        "    zero_stage=2,\n",
        "    micro_batch_size=8,\n",
        "    gradient_accumulation_steps=4,\n",
        "    offload_optimizer=False,\n",
        "    use_bf16=True,\n",
        "    learning_rate=1e-4,\n",
        "    weight_decay=0.01\n",
        ")\n",
        "\n",
        "print(\"ZeRO Stage 2 Configuration:\")\n",
        "print(json.dumps(config_stage2, indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create ZeRO Stage 3 configuration (maximum memory optimization)\n",
        "config_stage3 = create_deepspeed_config(\n",
        "    zero_stage=3,\n",
        "    micro_batch_size=8,\n",
        "    gradient_accumulation_steps=4,\n",
        "    offload_optimizer=False,\n",
        "    offload_param=False,\n",
        "    use_bf16=True,\n",
        "    learning_rate=1e-4,\n",
        "    weight_decay=0.01\n",
        ")\n",
        "\n",
        "print(\"ZeRO Stage 3 Configuration:\")\n",
        "print(json.dumps(config_stage3, indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save configurations to files\n",
        "save_deepspeed_config(config_stage2, \"deepspeed_config_stage2.json\")\n",
        "save_deepspeed_config(config_stage3, \"deepspeed_config_stage3.json\")\n",
        "\n",
        "print(\"[OK] Configurations saved!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Loading Vision Transformer Model\n",
        "\n",
        "We'll load a pre-trained ViT model and prepare it for DeepSpeed training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load ViT model (using smaller base model for demonstration)\n",
        "model = load_vit_model(\n",
        "    model_name=\"google/vit-base-patch16-224\",\n",
        "    num_labels=101,  # Food-101 has 101 classes\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    enable_gradient_checkpointing=True\n",
        ")\n",
        "\n",
        "print(f\"[OK] Model loaded: {type(model)}\")\n",
        "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Initializing DeepSpeed Engine\n",
        "\n",
        "DeepSpeed wraps the model and provides distributed training capabilities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Note: DeepSpeed initialization requires distributed environment\n",
        "# This is a demonstration - actual initialization happens in training scripts\n",
        "\n",
        "print(\"DeepSpeed initialization pattern:\")\n",
        "print(\"\"\"\n",
        "# In distributed training script:\n",
        "import deepspeed\n",
        "\n",
        "# Initialize distributed\n",
        "deepspeed.init_distributed()\n",
        "\n",
        "# Initialize DeepSpeed engine\n",
        "model_engine, optimizer, lr_scheduler = initialize_deepspeed_model(\n",
        "    model=model,\n",
        "    config_path=\"deepspeed_config_stage3.json\"\n",
        ")\n",
        "\n",
        "# The model_engine has additional methods:\n",
        "# - model_engine.backward(loss)\n",
        "# - model_engine.step()\n",
        "# - model_engine.device\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Understanding ZeRO Stages\n",
        "\n",
        "Different ZeRO stages provide different levels of memory optimization:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Compare different ZeRO stages\n",
        "stages = {\n",
        "    \"Stage 0\": \"No optimization (baseline DDP)\",\n",
        "    \"Stage 1\": \"Partitions optimizer states (~4x memory reduction)\",\n",
        "    \"Stage 2\": \"Partitions optimizer states + gradients (~8x reduction)\",\n",
        "    \"Stage 3\": \"Partitions optimizer states + gradients + parameters (max reduction)\"\n",
        "}\n",
        "\n",
        "print(\"ZeRO Optimization Stages:\")\n",
        "for stage, description in stages.items():\n",
        "    print(f\"  {stage}: {description}\")\n",
        "\n",
        "# Show configuration differences\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Configuration Comparison:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "configs = {\n",
        "    \"Stage 2\": config_stage2,\n",
        "    \"Stage 3\": config_stage3\n",
        "}\n",
        "\n",
        "for name, config in configs.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"  ZeRO Stage: {config['zero_optimization']['stage']}\")\n",
        "    print(f\"  Micro Batch Size: {config['train_micro_batch_size_per_gpu']}\")\n",
        "    print(f\"  Gradient Accumulation: {config['gradient_accumulation_steps']}\")\n",
        "    print(f\"  BF16 Enabled: {config.get('bf16', {}).get('enabled', False)}\")\n",
        "    if 'offload_optimizer' in config['zero_optimization']:\n",
        "        print(f\"  CPU Offload Optimizer: True\")\n",
        "    if 'offload_param' in config['zero_optimization']:\n",
        "        print(f\"  CPU Offload Parameters: True\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. GPU Memory Statistics\n",
        "\n",
        "Monitor GPU memory usage to understand DeepSpeed's memory optimization:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU memory stats\n",
        "if torch.cuda.is_available():\n",
        "    memory_stats = get_gpu_memory_stats(device_id=0)\n",
        "    print(\"GPU Memory Statistics:\")\n",
        "    for key, value in memory_stats.items():\n",
        "        print(f\"  {key}: {value:.2f} GB\")\n",
        "else:\n",
        "    print(\"CUDA not available\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Training Pattern with DeepSpeed\n",
        "\n",
        "Here's the typical training loop pattern with DeepSpeed:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\"\"\n",
        "# Typical DeepSpeed Training Loop:\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Set epoch for distributed sampler\n",
        "    if hasattr(train_loader.sampler, 'set_epoch'):\n",
        "        train_loader.sampler.set_epoch(epoch)\n",
        "    \n",
        "    # Training\n",
        "    model_engine.train()\n",
        "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(model_engine.device)\n",
        "        labels = labels.to(model_engine.device)\n",
        "        \n",
        "        # Forward pass\n",
        "        loss = model_engine(images, labels=labels).loss\n",
        "        \n",
        "        # Backward pass (handles gradient accumulation)\n",
        "        model_engine.backward(loss)\n",
        "        model_engine.step()\n",
        "    \n",
        "    # Validation\n",
        "    accuracy, metrics = evaluate_deepspeed(\n",
        "        model_engine=model_engine,\n",
        "        val_loader=val_loader,\n",
        "        rank=rank\n",
        "    )\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrated:\n",
        "1. Creating DeepSpeed configurations for different ZeRO stages\n",
        "2. Loading Vision Transformer models\n",
        "3. Understanding DeepSpeed initialization\n",
        "4. Comparing ZeRO optimization stages\n",
        "5. Monitoring GPU memory usage\n",
        "6. Training loop patterns\n",
        "\n",
        "For a complete working example with all experiments, see `DeepSpeed_FSDP.example_experiments.ipynb`.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
