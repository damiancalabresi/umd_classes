{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewAZzlObaczz"
   },
   "source": [
    "# Efficient Adaptation and Analysis of Vision Transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:21:09.526226Z",
     "iopub.status.busy": "2025-12-06T22:21:09.525933Z",
     "iopub.status.idle": "2025-12-06T22:21:13.254830Z",
     "shell.execute_reply": "2025-12-06T22:21:13.253950Z",
     "shell.execute_reply.started": "2025-12-06T22:21:09.526176Z"
    },
    "id": "OWw0nugHYljv",
    "outputId": "5781753e-d176-4918-d986-212db18a493d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported torch and sys\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "print(\"Imported torch and sys\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:21:13.256987Z",
     "iopub.status.busy": "2025-12-06T22:21:13.256663Z",
     "iopub.status.idle": "2025-12-06T22:21:13.486271Z",
     "shell.execute_reply": "2025-12-06T22:21:13.485372Z",
     "shell.execute_reply.started": "2025-12-06T22:21:13.256968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Dec  6 22:21:13 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   43C    P0             26W /   70W |     105MiB /  15360MiB |      4%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n",
      "| N/A   45C    P8              9W /   70W |       3MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:21:13.493256Z",
     "iopub.status.busy": "2025-12-06T22:21:13.492977Z",
     "iopub.status.idle": "2025-12-06T22:21:27.141041Z",
     "shell.execute_reply": "2025-12-06T22:21:27.140260Z",
     "shell.execute_reply.started": "2025-12-06T22:21:13.493202Z"
    },
    "id": "NjqlSFcRPKAh",
    "outputId": "cca1cf44-0298-4c43-89ab-139524b54045"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading wandb screts to log into W&B!\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb\n",
    "# !wandb login\n",
    "\n",
    "import wandb\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# Get the secret value\n",
    "user_secrets = UserSecretsClient()\n",
    "wandb_api_key = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
    "\n",
    "# Log in using the key\n",
    "wandb.login(key=wandb_api_key)\n",
    "\n",
    "print(\"Loading wandb screts to log into W&B!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17dCZxUzMhMD"
   },
   "source": [
    "#### Downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:21:27.142516Z",
     "iopub.status.busy": "2025-12-06T22:21:27.141945Z",
     "iopub.status.idle": "2025-12-06T22:25:23.305935Z",
     "shell.execute_reply": "2025-12-06T22:25:23.305192Z",
     "shell.execute_reply.started": "2025-12-06T22:21:27.142493Z"
    },
    "id": "770b94b9",
    "outputId": "e94348d5-140e-415e-8d6e-2a1f0294d362"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.00G/5.00G [02:51<00:00, 29.2MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food-101 dataset imported successfully.\n",
      "Training set size: 75750\n",
      "Test set size: 25250\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "# You'll likely want to resize to 224x224 and use ImageNet stats for ViT\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# Load the Food-101 training dataset\n",
    "# Food-101 uses 'split=\"train\"' for training\n",
    "trainset = torchvision.datasets.Food101(root='./data', split=\"train\",\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "# Load the Food-101 test (validation) dataset\n",
    "# Food-101 uses 'split=\"test\"' for testing\n",
    "testset = torchvision.datasets.Food101(root='./data', split=\"test\",\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "print(\"Food-101 dataset imported successfully.\")\n",
    "print(f\"Training set size: {len(trainset)}\")\n",
    "print(f\"Test set size: {len(testset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VZywhoZLYll_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmiQ12PxMvRG"
   },
   "source": [
    "#### Resizing the data for ViT model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:25:23.307156Z",
     "iopub.status.busy": "2025-12-06T22:25:23.306697Z",
     "iopub.status.idle": "2025-12-06T22:25:23.313560Z",
     "shell.execute_reply": "2025-12-06T22:25:23.312880Z",
     "shell.execute_reply.started": "2025-12-06T22:25:23.307134Z"
    },
    "id": "b6edb525",
    "outputId": "9469118b-a692-4a84-87e2-f87f137c01be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation complete. Transforms applied to datasets.\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define transforms for training and validation/testing\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Upsample to ViT resolution\n",
    "    transforms.RandomHorizontalFlip(), # Example data augmentation\n",
    "    transforms.RandomCrop(224, padding=4), # Example data augmentation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # Upsample to ViT resolution\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Apply the transforms to the datasets\n",
    "trainset.transform = train_transform\n",
    "testset.transform = test_transform\n",
    "\n",
    "print(\"Data preparation complete. Transforms applied to datasets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ceO7JH5qYloQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGUdLT2ZM1H7"
   },
   "source": [
    "#### Loading the VIT and freezing the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:29:42.386767Z",
     "iopub.status.busy": "2025-12-06T22:29:42.386472Z",
     "iopub.status.idle": "2025-12-06T22:30:11.597692Z",
     "shell.execute_reply": "2025-12-06T22:30:11.596872Z",
     "shell.execute_reply.started": "2025-12-06T22:29:42.386747Z"
    },
    "id": "42daad35",
    "outputId": "8ac2af14-f18e-4ed4-ee03-f09fa763ef85"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-06 22:29:47.900245: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765060188.057582      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1765060188.102737      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed4ee8aad41482a91a8d0e557b10ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/503 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1df05c88104347c1948c4071cbb2dbc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.53G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-huge-patch14-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained ViT-Huge model loaded.\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTForImageClassification\n",
    "\n",
    "# Load a pre-trained ViT-Huge model\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    'google/vit-huge-patch14-224-in21k',  # Model name for ViT-Huge\n",
    "    num_labels=101,                       # Updated for 101 classes in Food-101\n",
    "    ignore_mismatched_sizes=True          # Allows replacing the classifier head\n",
    ")\n",
    "\n",
    "print(\"Pre-trained ViT-Huge model loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdk8zKbOMxTF"
   },
   "source": [
    "# Here we decide if we want to train full model or some"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:30:11.599615Z",
     "iopub.status.busy": "2025-12-06T22:30:11.599076Z",
     "iopub.status.idle": "2025-12-06T22:30:11.605102Z",
     "shell.execute_reply": "2025-12-06T22:30:11.604263Z",
     "shell.execute_reply.started": "2025-12-06T22:30:11.599593Z"
    },
    "id": "d67efd05",
    "outputId": "d7755864-7f6d-4b13-aa23-b83a30af12d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 630894181\n"
     ]
    }
   ],
   "source": [
    "# Print the number of trainable parameters\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Number of trainable parameters: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:30:11.606390Z",
     "iopub.status.busy": "2025-12-06T22:30:11.606091Z",
     "iopub.status.idle": "2025-12-06T22:30:11.627255Z",
     "shell.execute_reply": "2025-12-06T22:30:11.626681Z",
     "shell.execute_reply.started": "2025-12-06T22:30:11.606365Z"
    },
    "id": "BYxoz80n3_hV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTForImageClassification(\n",
       "  (vit): ViTModel(\n",
       "    (embeddings): ViTEmbeddings(\n",
       "      (patch_embeddings): ViTPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ViTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-31): 32 x ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((1280,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1280, out_features=101, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AjEPQofQ3_W-"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cqQBFTAwqlTV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X0Gsft8sl6yy"
   },
   "source": [
    "## Step 1: Create the DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:30:11.629150Z",
     "iopub.status.busy": "2025-12-06T22:30:11.628897Z",
     "iopub.status.idle": "2025-12-06T22:30:11.638872Z",
     "shell.execute_reply": "2025-12-06T22:30:11.638074Z",
     "shell.execute_reply.started": "2025-12-06T22:30:11.629123Z"
    },
    "id": "ht7eS4piYl13",
    "outputId": "e6307b33-1296-4cd2-9387-53968a2d7e8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders created.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(trainset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(testset, batch_size=16, shuffle=False)\n",
    "\n",
    "print(\"DataLoaders created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIEb8JphmELT"
   },
   "source": [
    "## Step 2: Enable Gradient Checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:30:11.639618Z",
     "iopub.status.busy": "2025-12-06T22:30:11.639411Z",
     "iopub.status.idle": "2025-12-06T22:30:11.651542Z",
     "shell.execute_reply": "2025-12-06T22:30:11.650658Z",
     "shell.execute_reply.started": "2025-12-06T22:30:11.639599Z"
    },
    "id": "pV14uvsLmASg",
    "outputId": "6f434640-10c4-405d-c9bc-566cdd20be95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient checkpointing enabled.\n"
     ]
    }
   ],
   "source": [
    "# Enable gradient checkpointing\n",
    "model.gradient_checkpointing_enable()\n",
    "print(\"Gradient checkpointing enabled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFW9w8YcmQBv"
   },
   "source": [
    "## Step 3: Initialize DeepSpeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:30:11.652667Z",
     "iopub.status.busy": "2025-12-06T22:30:11.652408Z",
     "iopub.status.idle": "2025-12-06T22:30:21.779021Z",
     "shell.execute_reply": "2025-12-06T22:30:21.777933Z",
     "shell.execute_reply.started": "2025-12-06T22:30:11.652646Z"
    },
    "id": "n8ZDhNyPmaMs",
    "outputId": "f51fc9d7-34f9-4b36-c0df-bd3adebe3f69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mpi4py\n",
      "  Downloading mpi4py-4.1.1-cp311-cp311-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (16 kB)\n",
      "Downloading mpi4py-4.1.1-cp311-cp311-manylinux1_x86_64.manylinux_2_5_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpi4py\n",
      "Successfully installed mpi4py-4.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mpi4py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:30:21.781046Z",
     "iopub.status.busy": "2025-12-06T22:30:21.780829Z",
     "iopub.status.idle": "2025-12-06T22:32:04.777766Z",
     "shell.execute_reply": "2025-12-06T22:32:04.776610Z",
     "shell.execute_reply.started": "2025-12-06T22:30:21.781017Z"
    },
    "id": "vzppX2gFQS2I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deepspeed\n",
      "  Downloading deepspeed-0.18.2.tar.gz (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m988.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from deepspeed) (0.8.1)\n",
      "Collecting hjson (from deepspeed)\n",
      "  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from deepspeed) (1.1.2)\n",
      "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from deepspeed) (1.13.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deepspeed) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from deepspeed) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from deepspeed) (7.1.3)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from deepspeed) (9.0.0)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from deepspeed) (2.12.4)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from deepspeed) (2.6.0+cu124)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from deepspeed) (4.67.1)\n",
      "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.11/dist-packages (from deepspeed) (12.575.51)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed) (0.4.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->deepspeed) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->deepspeed) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->deepspeed) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->deepspeed) (2025.3.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->deepspeed) (2022.3.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->deepspeed) (2.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (3.20.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (2025.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->deepspeed)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->deepspeed)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->deepspeed)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->deepspeed)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->deepspeed)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->deepspeed)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->deepspeed)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->deepspeed)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->deepspeed)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->deepspeed)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->deepspeed) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->deepspeed) (3.0.3)\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->deepspeed) (2025.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->deepspeed) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->deepspeed) (2022.3.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->deepspeed) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->deepspeed) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->deepspeed) (2024.2.0)\n",
      "Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: deepspeed\n",
      "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for deepspeed: filename=deepspeed-0.18.2-py3-none-any.whl size=1763306 sha256=e8963023553e9187630251f78db56370244910dd7b42f4b614c413d1f3018006\n",
      "  Stored in directory: /root/.cache/pip/wheels/80/2b/fe/f2625302f25976b9828a27d3d2567bdc1d587a1ff0ab42c8a9\n",
      "Successfully built deepspeed\n",
      "Installing collected packages: hjson, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, deepspeed\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed deepspeed-0.18.2 hjson-3.1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install deepspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:32:04.779818Z",
     "iopub.status.busy": "2025-12-06T22:32:04.779398Z",
     "iopub.status.idle": "2025-12-06T22:32:14.209325Z",
     "shell.execute_reply": "2025-12-06T22:32:14.208474Z",
     "shell.execute_reply.started": "2025-12-06T22:32:04.779770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  libaio-dev\n",
      "0 upgraded, 1 newly installed, 0 to remove and 165 not upgraded.\n",
      "Need to get 21.2 kB of archives.\n",
      "After this operation, 71.7 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libaio-dev amd64 0.3.112-13build1 [21.2 kB]\n",
      "Fetched 21.2 kB in 0s (193 kB/s)      \n",
      "Selecting previously unselected package libaio-dev:amd64.\n",
      "(Reading database ... 128639 files and directories currently installed.)\n",
      "Preparing to unpack .../libaio-dev_0.3.112-13build1_amd64.deb ...\n",
      "Unpacking libaio-dev:amd64 (0.3.112-13build1) ...\n",
      "Setting up libaio-dev:amd64 (0.3.112-13build1) ...\n",
      "Processing triggers for man-db (2.10.2-1) ...\n"
     ]
    }
   ],
   "source": [
    "!apt-get install -y libaio-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LNPoEyLIZfVe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xEZCI7Qy2krh"
   },
   "source": [
    "## Script for Standard Full Fine-Tune Using DDP, running on 2 T4 gpus batch size = 16 per gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:36:03.844717Z",
     "iopub.status.busy": "2025-12-06T22:36:03.844379Z",
     "iopub.status.idle": "2025-12-06T22:36:03.853308Z",
     "shell.execute_reply": "2025-12-06T22:36:03.852398Z",
     "shell.execute_reply.started": "2025-12-06T22:36:03.844693Z"
    },
    "id": "96vZr6BJKqnK",
    "outputId": "aeb14b93-b3fd-43ea-ad87-a6173de1083b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train_standard_ddp_vit_huge_bs16.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_standard_ddp_vit_huge_bs16.py\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor\n",
    "import warnings\n",
    "import wandb\n",
    "import os\n",
    "import time\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import torch.profiler \n",
    "os.makedirs(\"./profiling_traces\", exist_ok=True)\n",
    "\n",
    "# --- 1. Setup & Helper Functions ---\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(\"--- Initializing Standard DDP ---\")\n",
    "\n",
    "rank = int(os.environ['RANK'])\n",
    "local_rank = int(os.environ['LOCAL_RANK'])\n",
    "world_size = int(os.environ['WORLD_SIZE'])\n",
    "\n",
    "dist.init_process_group(backend='nccl')\n",
    "torch.cuda.set_device(local_rank)\n",
    "device = torch.device(f\"cuda:{local_rank}\")\n",
    "\n",
    "def inspect_model_sharding(model, name_tag):\n",
    "    \"\"\"Checks if parameters are sharded (Expected: NO for DDP)\"\"\"\n",
    "    if rank == 0:\n",
    "        print(f\"\\n[Rank {rank}] --- INSPECTING SHARDING ({name_tag}) ---\")\n",
    "        # Unwrap DDP to get to the actual model parameters\n",
    "        actual_model = model.module if hasattr(model, \"module\") else model\n",
    "        \n",
    "        count = 0\n",
    "        for name, param in actual_model.named_parameters():\n",
    "            print(f\"Param: {name}\")\n",
    "            # In DDP, Physical Shape should equal Logical Shape (Full Layer)\n",
    "            print(f\"  Physical Shape: {param.shape} (Elements: {param.numel():,})\")\n",
    "            print(f\"  Status:         REPLICATED (Full Copy)\")\n",
    "            print(\"-\" * 40)\n",
    "            count += 1\n",
    "            if count >= 2: break\n",
    "        print(\"----------------------------------\\n\")\n",
    "\n",
    "# --- 2. Data & Model ---\n",
    "if rank == 0: print(\"Setting up Data & Model...\")\n",
    "processor = ViTImageProcessor.from_pretrained('google/vit-huge-patch14-224-in21k')\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(224, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=processor.image_mean, std=processor.image_std)\n",
    "])\n",
    "\n",
    "if rank == 0:\n",
    "    trainset = torchvision.datasets.Food101(root='./data', split=\"train\", download=True, transform=train_transform)\n",
    "dist.barrier()\n",
    "if rank != 0:\n",
    "    trainset = torchvision.datasets.Food101(root='./data', split=\"train\", download=False, transform=train_transform)\n",
    "\n",
    "train_sampler = DistributedSampler(trainset, num_replicas=world_size, rank=rank, shuffle=True)\n",
    "train_loader = DataLoader(trainset, batch_size=16, sampler=train_sampler, num_workers=2, pin_memory=True)\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-huge-patch14-224-in21k', num_labels=101, ignore_mismatched_sizes=True)\n",
    "model.gradient_checkpointing_enable()\n",
    "model.to(device)\n",
    "model = DDP(model, device_ids=[local_rank], output_device=local_rank)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "scaler = GradScaler(enabled=True)\n",
    "\n",
    "# --- 3. Logging & Inspection ---\n",
    "if rank == 0:\n",
    "    wandb.init(\n",
    "        project=\"Distributed ViT training systems-Latest_run\",\n",
    "        name=\"Standard-DDP-ViT-Huge-Food101-2xT4-Batch-size-16-per-gpu\",\n",
    "        config={\"model\": \"vit-huge\", \"mode\": \"DDP\"}\n",
    "    )\n",
    "\n",
    "# PRO CHECK: This output will prove that DDP duplicates the full model on every GPU\n",
    "inspect_model_sharding(model, \"Standard DDP\")\n",
    "\n",
    "# --- 4. Training Loop with Labels ---\n",
    "print(f\"[Rank {rank}] Starting training...\")\n",
    "\n",
    "for i, batch in enumerate(train_loader):\n",
    "    # Stop early to save time (we just need traces and logs)\n",
    "    if i >= 6: break\n",
    "    \n",
    "    # LABEL 0: Top Level Step\n",
    "    with torch.profiler.record_function(f\"## Training Step {i} ##\"):\n",
    "        inputs, labels = batch\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # LABEL 1: Forward\n",
    "        with torch.profiler.record_function(\"## Forward Pass ##\"):\n",
    "            with autocast(enabled=True):\n",
    "                outputs = model(inputs, labels=labels)\n",
    "                loss = outputs.loss\n",
    "\n",
    "        # LABEL 2: Backward\n",
    "        with torch.profiler.record_function(\"## Backward Pass ##\"):\n",
    "            # This is where it usually crashes (OOM)\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "        # LABEL 3: Optimizer\n",
    "        with torch.profiler.record_function(\"## Optimizer Step ##\"):\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "        # --- PRO LOGGING ---\n",
    "        if rank == 0:\n",
    "            mem = torch.cuda.memory_allocated() / 1e9\n",
    "            max_mem = torch.cuda.max_memory_allocated() / 1e9\n",
    "            wandb.log({\n",
    "                \"loss\": loss.item(),\n",
    "                \"System/Memory_Allocated_GB\": mem,\n",
    "                \"System/Max_Memory_GB\": max_mem\n",
    "            })\n",
    "            print(f\"Step {i}: Loss={loss.item():.4f} | Mem={mem:.2f}GB\")\n",
    "\n",
    "dist.destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:36:06.324165Z",
     "iopub.status.busy": "2025-12-06T22:36:06.323896Z",
     "iopub.status.idle": "2025-12-06T22:36:41.341228Z",
     "shell.execute_reply": "2025-12-06T22:36:41.340476Z",
     "shell.execute_reply.started": "2025-12-06T22:36:06.324147Z"
    },
    "id": "mt88h9CcKqpF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "pylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "cudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msiddpath\u001b[0m (\u001b[33msiddpath-university-of-maryland\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "W1206 22:36:17.537000 323 torch/distributed/run.py:792] \n",
      "W1206 22:36:17.537000 323 torch/distributed/run.py:792] *****************************************\n",
      "W1206 22:36:17.537000 323 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W1206 22:36:17.537000 323 torch/distributed/run.py:792] *****************************************\n",
      "2025-12-06 22:36:22.749146: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-06 22:36:22.749311: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765060582.770911     326 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765060582.771440     325 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1765060582.779285     325 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "E0000 00:00:1765060582.780280     326 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "AttributeErrorAttributeError: : 'MessageFactory' object has no attribute 'GetPrototype''MessageFactory' object has no attribute 'GetPrototype'\n",
      "\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "--- Initializing Standard DDP ---\n",
      "--- Initializing Standard DDP ---\n",
      "Setting up Data & Model...\n",
      "preprocessor_config.json: 100%|████████████████| 160/160 [00:00<00:00, 1.03MB/s]\n",
      "[rank1]:[W1206 22:36:30.688911118 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank0]:[W1206 22:36:31.019079276 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-huge-patch14-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-huge-patch14-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[Rank 1] Starting training...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msiddpath\u001b[0m (\u001b[33msiddpath-university-of-maryland\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20251206_223633-qklwu5l1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mStandard-DDP-ViT-Huge-Food101-2xT4-Batch-size-16-per-gpu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/siddpath-university-of-maryland/Distributed%20ViT%20training%20systems-Latest_run\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/siddpath-university-of-maryland/Distributed%20ViT%20training%20systems-Latest_run/runs/qklwu5l1\u001b[0m\n",
      "\n",
      "[Rank 0] --- INSPECTING SHARDING (Standard DDP) ---\n",
      "Param: vit.embeddings.cls_token\n",
      "  Physical Shape: torch.Size([1, 1, 1280]) (Elements: 1,280)\n",
      "  Status:         REPLICATED (Full Copy)\n",
      "----------------------------------------\n",
      "Param: vit.embeddings.position_embeddings\n",
      "  Physical Shape: torch.Size([1, 257, 1280]) (Elements: 328,960)\n",
      "  Status:         REPLICATED (Full Copy)\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "\n",
      "[Rank 0] Starting training...\n",
      "Traceback (most recent call last):\n",
      "[rank1]: Traceback (most recent call last):\n",
      "[rank1]:   File \"/kaggle/working/train_standard_ddp_vit_huge_bs16.py\", line 114, in <module>\n",
      "[rank1]:     scaler.step(optimizer)\n",
      "[rank1]:   File \"/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\", line 457, in step\n",
      "[rank1]:     retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)\n",
      "[rank1]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank1]:   File \"/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\", line 352, in _maybe_opt_step\n",
      "[rank1]:     retval = optimizer.step(*args, **kwargs)\n",
      "[rank1]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank1]:   File \"/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\", line 493, in wrapper\n",
      "[rank1]:     out = func(*args, **kwargs)\n",
      "[rank1]:           ^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank1]:   File \"/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\", line 91, in _use_grad\n",
      "[rank1]:     ret = func(self, *args, **kwargs)\n",
      "[rank1]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank1]:   File \"/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\", line 243, in step\n",
      "[rank1]:     adamw(\n",
      "[rank1]:   File \"/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\", line 154, in maybe_fallback\n",
      "[rank1]:     return func(*args, **kwargs)\n",
      "[rank1]:            ^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank1]:   File \"/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\", line 875, in adamw\n",
      "[rank1]:     func(\n",
      "[rank1]:   File \"/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\", line 699, in _multi_tensor_adamw\n",
      "[rank1]:     exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)\n",
      "[rank1]:                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank1]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 1 has a total capacity of 14.74 GiB of which 6.19 MiB is free. Process 9129 has 14.73 GiB memory in use. Of the allocated memory 12.80 GiB is allocated by PyTorch, and 1.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "  File \"/kaggle/working/train_standard_ddp_vit_huge_bs16.py\", line 114, in <module>\n",
      "    scaler.step(optimizer)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\", line 457, in step\n",
      "    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\", line 352, in _maybe_opt_step\n",
      "    retval = optimizer.step(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\", line 493, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\", line 91, in _use_grad\n",
      "    ret = func(self, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\", line 243, in step\n",
      "    adamw(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\", line 154, in maybe_fallback\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\", line 875, in adamw\n",
      "    func(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\", line 699, in _multi_tensor_adamw\n",
      "    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 8.19 MiB is free. Process 3159 has 102.00 MiB memory in use. Process 9128 has 14.63 GiB memory in use. Of the allocated memory 12.65 GiB is allocated by PyTorch, and 1.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "[rank0]: Traceback (most recent call last):\n",
      "[rank0]:   File \"/kaggle/working/train_standard_ddp_vit_huge_bs16.py\", line 114, in <module>\n",
      "[rank0]:     scaler.step(optimizer)\n",
      "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\", line 457, in step\n",
      "[rank0]:     retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)\n",
      "[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\", line 352, in _maybe_opt_step\n",
      "[rank0]:     retval = optimizer.step(*args, **kwargs)\n",
      "[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\", line 493, in wrapper\n",
      "[rank0]:     out = func(*args, **kwargs)\n",
      "[rank0]:           ^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\", line 91, in _use_grad\n",
      "[rank0]:     ret = func(self, *args, **kwargs)\n",
      "[rank0]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\", line 243, in step\n",
      "[rank0]:     adamw(\n",
      "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\", line 154, in maybe_fallback\n",
      "[rank0]:     return func(*args, **kwargs)\n",
      "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\", line 875, in adamw\n",
      "[rank0]:     func(\n",
      "[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\", line 699, in _multi_tensor_adamw\n",
      "[rank0]:     exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)\n",
      "[rank0]:                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 8.19 MiB is free. Process 3159 has 102.00 MiB memory in use. Process 9128 has 14.63 GiB memory in use. Of the allocated memory 12.65 GiB is allocated by PyTorch, and 1.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mStandard-DDP-ViT-Huge-Food101-2xT4-Batch-size-16-per-gpu\u001b[0m at: \u001b[34mhttps://wandb.ai/siddpath-university-of-maryland/Distributed%20ViT%20training%20systems-Latest_run/runs/qklwu5l1\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20251206_223633-qklwu5l1/logs\u001b[0m\n",
      "[rank0]:[W1206 22:36:39.524524304 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "W1206 22:36:40.713000 323 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 325 closing signal SIGTERM\n",
      "E1206 22:36:40.927000 323 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 1 (pid: 326) of binary: /usr/bin/python3\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/torchrun\", line 10, in <module>\n",
      "    sys.exit(main())\n",
      "             ^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 355, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/run.py\", line 918, in main\n",
      "    run(args)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/run.py\", line 909, in run\n",
      "    elastic_launch(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launcher/api.py\", line 138, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launcher/api.py\", line 269, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "train_standard_ddp_vit_huge_bs16.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2025-12-06_22:36:40\n",
      "  host      : f7503e1b6be5\n",
      "  rank      : 1 (local_rank: 1)\n",
      "  exitcode  : 1 (pid: 326)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 1. Install/Login\n",
    "!pip install -q transformers datasets peft deepspeed wandb scikit-learn seaborn tensorboard\n",
    "!wandb login\n",
    "\n",
    "# 2. Launch the DDP script\n",
    "# !torchrun --nproc_per_node=2 train_standard_ddp.py\n",
    "!torchrun --nproc_per_node=2 --master_port 29501 train_standard_ddp_vit_huge_bs16.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script for DeepSpeed Full Fine-Tune, running on 2 T4 gpus stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:37:11.355273Z",
     "iopub.status.busy": "2025-12-06T22:37:11.354281Z",
     "iopub.status.idle": "2025-12-06T22:37:11.361172Z",
     "shell.execute_reply": "2025-12-06T22:37:11.360552Z",
     "shell.execute_reply.started": "2025-12-06T22:37:11.355199Z"
    },
    "id": "5cra_sOM5y6L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing deepspeed_config_stage2_vit_huge_bs16.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile deepspeed_config_stage2_vit_huge_bs16.json\n",
    "{\n",
    "    \"fp16\": {\n",
    "        \"enabled\": true,\n",
    "        \"loss_scale\": 0,\n",
    "        \"loss_scale_window\": 1000\n",
    "    },\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": 5e-5,\n",
    "            \"betas\": [0.9, 0.999],\n",
    "            \"eps\": 1e-8,\n",
    "            \"weight_decay\": 3e-7\n",
    "        }\n",
    "    },\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 2,\n",
    "        \"allgather_partitions\": true,\n",
    "        \"allgather_bucket_size\": 5e8,\n",
    "        \"reduce_scatter\": true,\n",
    "        \"reduce_bucket_size\": 5e8,\n",
    "        \"overlap_comm\": true,\n",
    "        \"contiguous_gradients\": true\n",
    "    },\n",
    "    \"train_batch_size\": 32,\n",
    "    \"train_micro_batch_size_per_gpu\": 16,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"gradient_clipping\": 1.0,\n",
    "    \"steps_per_print\": 1,\n",
    "    \"wall_clock_breakdown\": false,\n",
    "    \"flops_profiler\": {\n",
    "        \"enabled\": false\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:37:13.653549Z",
     "iopub.status.busy": "2025-12-06T22:37:13.653021Z",
     "iopub.status.idle": "2025-12-06T22:37:13.661351Z",
     "shell.execute_reply": "2025-12-06T22:37:13.660630Z",
     "shell.execute_reply.started": "2025-12-06T22:37:13.653525Z"
    },
    "id": "pZv-PgHx5y9B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train_deepspeed_stage2_vit_huge_bs16.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_deepspeed_stage2_vit_huge_bs16.py\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor\n",
    "import deepspeed\n",
    "import warnings\n",
    "import wandb\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import torch.profiler\n",
    "import json\n",
    "import glob\n",
    "\n",
    "# --- TRACE DIRECTORY SETUP ---\n",
    "TRACE_DIR = \"./pytorch_traces/deepspeed_stage2_trace\"\n",
    "MERGED_TRACE_FILE = \"./pytorch_traces/deepspeed_stage2_trace/merged_multi_gpu_trace.json\"\n",
    "\n",
    "# Cleanup old runs to avoid confusion (only rank 0)\n",
    "if int(os.environ.get('RANK', 0)) == 0:\n",
    "    if os.path.exists(TRACE_DIR):\n",
    "        try: \n",
    "            shutil.rmtree(TRACE_DIR)\n",
    "        except: \n",
    "            pass\n",
    "    os.makedirs(TRACE_DIR, exist_ok=True)\n",
    "    if os.path.exists(MERGED_TRACE_FILE):\n",
    "        os.remove(MERGED_TRACE_FILE)\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(\"--- Initializing DEEPSPEED ZeRO Stage 2 (Multi-GPU Profiling) ---\")\n",
    "\n",
    "# --- 1. Setup ---\n",
    "local_rank = int(os.environ.get('LOCAL_RANK', 0))\n",
    "rank = int(os.environ.get('RANK', 0))\n",
    "world_size = int(os.environ.get('WORLD_SIZE', 1))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(local_rank)\n",
    "    print(f\"[Rank {rank}] Initializing process on GPU {local_rank}...\")\n",
    "else:\n",
    "    print(f\"[Rank {rank}] WARNING: No CUDA available, running on CPU\")\n",
    "\n",
    "# --- W&B Setup ---\n",
    "if rank == 0:\n",
    "    wandb.init(\n",
    "        project=\"Distributed ViT training systems-Latest_run\", \n",
    "        name=\"DeepSpeed-Stage2-ViT-Huge-Food101-2xT4-MBS16-GAS1-Batch-size-16-per-gpu\",\n",
    "        config={\n",
    "            \"optimization\": \"Stage 2\",\n",
    "            \"num_gpus\": world_size,\n",
    "            \"profiling\": \"Rank 0 & 1 (Merged)\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "# --- 2. Model Setup ---\n",
    "if rank == 0: print(\"Loading pre-trained ViT-Huge model...\")\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    'google/vit-huge-patch14-224-in21k', \n",
    "    num_labels=101, \n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "# --- 3. DeepSpeed Init ---\n",
    "if rank == 0: print(\"Initializing DeepSpeed...\")\n",
    "model_engine, optimizer, _, _ = deepspeed.initialize(\n",
    "    model=model, \n",
    "    model_parameters=model.parameters(), \n",
    "    config_params='deepspeed_config_stage2_vit_huge_bs16.json'\n",
    ")\n",
    "\n",
    "# --- 4. Data Prep ---\n",
    "if rank == 0: print(\"Setting up data...\")\n",
    "processor = ViTImageProcessor.from_pretrained('google/vit-huge-patch14-224-in21k')\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(224, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=processor.image_mean, std=processor.image_std)\n",
    "])\n",
    "\n",
    "if rank == 0:\n",
    "    trainset = torchvision.datasets.Food101(root='./data', split=\"train\", download=True, transform=train_transform)\n",
    "\n",
    "if world_size > 1: dist.barrier()\n",
    "    \n",
    "if rank != 0:\n",
    "    trainset = torchvision.datasets.Food101(root='./data', split=\"train\", download=False, transform=train_transform)\n",
    "\n",
    "MICRO_BATCH_SIZE = 16\n",
    "train_sampler = DistributedSampler(trainset, num_replicas=world_size, rank=rank, shuffle=True)\n",
    "train_loader = DataLoader(trainset, batch_size=MICRO_BATCH_SIZE, sampler=train_sampler, num_workers=2, pin_memory=True)\n",
    "\n",
    "# --- ROBUST MERGE FUNCTION ---\n",
    "def merge_traces_logic():\n",
    "    \"\"\"Merge all rank traces into a single file for Perfetto (Handles String PIDs)\"\"\"\n",
    "    print(f\"\\n[Rank 0] Merging traces from all ranks...\")\n",
    "    trace_files = sorted(glob.glob(os.path.join(TRACE_DIR, \"*.pt.trace.json\")))\n",
    "    \n",
    "    if not trace_files:\n",
    "        print(\"  WARNING: No trace files found yet!\")\n",
    "        return\n",
    "    \n",
    "    merged_events = []\n",
    "    metadata = {}\n",
    "    \n",
    "    for idx, trace_file in enumerate(trace_files):\n",
    "        try:\n",
    "            with open(trace_file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            if isinstance(data, dict):\n",
    "                events = data.get(\"traceEvents\", [])\n",
    "                if idx == 0: metadata = {k: v for k, v in data.items() if k != \"traceEvents\"}\n",
    "            else:\n",
    "                events = data\n",
    "            \n",
    "            # --- ROBUST PID/TID OFFSETTING ---\n",
    "            for event in events:\n",
    "                # 1. Safely Offset PID\n",
    "                if \"pid\" in event:\n",
    "                    try:\n",
    "                        event[\"pid\"] = int(event[\"pid\"]) + (idx * 100000)\n",
    "                    except ValueError:\n",
    "                        event[\"pid\"] = f\"{event['pid']}_{idx}\"\n",
    "\n",
    "                # 2. Safely Offset TID\n",
    "                if \"tid\" in event:\n",
    "                    try:\n",
    "                        event[\"tid\"] = int(event[\"tid\"]) + (idx * 100000)\n",
    "                    except ValueError:\n",
    "                        event[\"tid\"] = f\"{event['tid']}_{idx}\"\n",
    "                \n",
    "                # 3. Rename\n",
    "                if \"name\" in event and isinstance(event[\"name\"], str):\n",
    "                    if not event[\"name\"].startswith(\"[GPU\"):\n",
    "                        event[\"name\"] = f\"[GPU {idx}] {event['name']}\"\n",
    "            \n",
    "            merged_events.extend(events)\n",
    "            print(f\"    Added {len(events)} events from GPU {idx}\")\n",
    "        except Exception as e:\n",
    "            print(f\"    Warning: Could not read {trace_file}: {e}\")\n",
    "\n",
    "    merged_trace = metadata.copy()\n",
    "    merged_trace[\"traceEvents\"] = merged_events\n",
    "    \n",
    "    with open(MERGED_TRACE_FILE, 'w') as f:\n",
    "        json.dump(merged_trace, f)\n",
    "    \n",
    "    print(f\"\\n  MERGE COMPLETE!\")\n",
    "    print(f\"  Saved to: {MERGED_TRACE_FILE}\")\n",
    "    print(f\" Upload this file to https://ui.perfetto.dev/\\n\")\n",
    "\n",
    "# --- Training Configuration ---\n",
    "device = model_engine.device\n",
    "num_epochs = 1\n",
    "start_time = time.time()\n",
    "PROFILING_STEPS = 0\n",
    "\n",
    "if rank == 0: \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"--- STARTING TRAINING WITH PROFILING ---\")\n",
    "    print(f\"  - Profiling: ALL ranks (first {PROFILING_STEPS} steps)\")\n",
    "    print(f\"  - Training: Continues FULLY after profiling\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "try:\n",
    "    # --- PROFILER INITIALIZATION (ALL RANKS) ---\n",
    "    prof = torch.profiler.profile(\n",
    "        activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "        schedule=torch.profiler.schedule(wait=1, warmup=2, active=5, repeat=1),\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler(TRACE_DIR),\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=True,\n",
    "        with_flops=True\n",
    "    )\n",
    "    # prof.start()\n",
    "    \n",
    "    model_engine.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_sampler.set_epoch(epoch)\n",
    "        epoch_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for i, batch in enumerate(train_loader):\n",
    "            \n",
    "            # --- Profiling Window ---\n",
    "            is_profiling = (i < PROFILING_STEPS)\n",
    "            prof_context = None\n",
    "            \n",
    "            if is_profiling:\n",
    "                prof_context = torch.profiler.record_function(f\"## [GPU {rank}] Step {i} ##\")\n",
    "                prof_context.__enter__()\n",
    "            \n",
    "            inputs, labels = batch\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward\n",
    "            if is_profiling:\n",
    "                with torch.profiler.record_function(f\"## [GPU {rank}] FWD ##\"):\n",
    "                    outputs = model_engine(inputs, labels=labels)\n",
    "                    loss = outputs.loss\n",
    "            else:\n",
    "                outputs = model_engine(inputs, labels=labels)\n",
    "                loss = outputs.loss\n",
    "\n",
    "            # Backward\n",
    "            if is_profiling:\n",
    "                with torch.profiler.record_function(f\"## [GPU {rank}] BWD ##\"):\n",
    "                    model_engine.backward(loss)\n",
    "            else:\n",
    "                model_engine.backward(loss)\n",
    "\n",
    "            # Step\n",
    "            if is_profiling:\n",
    "                with torch.profiler.record_function(f\"## [GPU {rank}] OPT ##\"):\n",
    "                    model_engine.step()\n",
    "            else:\n",
    "                model_engine.step()\n",
    "\n",
    "            # Metrics\n",
    "            loss_val = loss.item()\n",
    "            epoch_loss += loss_val\n",
    "            num_batches += 1\n",
    "\n",
    "            if rank == 0:\n",
    "                wandb.log({\"loss\": loss_val, \"step\": i})\n",
    "                if i % 10 == 0:\n",
    "                    print(f\"  [GPU {rank}] Epoch {epoch} | Step {i} | Loss: {loss_val:.4f}\")\n",
    "\n",
    "            # --- Profiler Stepping ---\n",
    "            if is_profiling:\n",
    "                prof.step()\n",
    "                if prof_context: prof_context.__exit__(None, None, None)\n",
    "            \n",
    "            # --- STOP & MERGE (But continue training) ---\n",
    "            if i == PROFILING_STEPS:\n",
    "                prof.stop() # Save trace files to disk\n",
    "                \n",
    "                # 1. Sync all ranks to ensure writing is done\n",
    "                if world_size > 1: dist.barrier()\n",
    "                \n",
    "                # 2. Rank 0 performs the merge immediately\n",
    "                if rank == 0:\n",
    "                    print(f\"\\n>>> Profiling complete. Merging traces while training continues... <<<\")\n",
    "                    merge_traces_logic()\n",
    "                    print(\">>> Resuming full training loop... <<<\\n\")\n",
    "\n",
    "    # End of Epoch\n",
    "    if rank == 0:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"TRAINING COMPLETE\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        wandb.finish()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[Rank {rank}] ERROR: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "finally:\n",
    "    if world_size > 1:\n",
    "        dist.barrier()\n",
    "        dist.destroy_process_group()\n",
    "    print(f\"--- [Rank {rank}] Done ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T22:37:18.650785Z",
     "iopub.status.busy": "2025-12-06T22:37:18.650136Z",
     "iopub.status.idle": "2025-12-07T00:08:16.647229Z",
     "shell.execute_reply": "2025-12-07T00:08:16.646282Z",
     "shell.execute_reply.started": "2025-12-06T22:37:18.650761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-06 22:37:27.136778: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765060647.159408     406 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1765060647.166145     406 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "[2025-12-06 22:37:32,429] [WARNING] [runner.py:232:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
      "[2025-12-06 22:37:32,430] [INFO] [runner.py:630:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None --log_level=info train_deepspeed_stage2_vit_huge_bs16.py\n",
      "2025-12-06 22:37:39.818770: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765060659.840955     458 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1765060659.847819     458 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "[2025-12-06 22:37:44,924] [INFO] [launch.py:155:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.22.3-1+cuda12.5\n",
      "[2025-12-06 22:37:44,924] [INFO] [launch.py:155:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.22.3-1\n",
      "[2025-12-06 22:37:44,924] [INFO] [launch.py:155:main] 0 NCCL_VERSION=2.22.3-1\n",
      "[2025-12-06 22:37:44,924] [INFO] [launch.py:155:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
      "[2025-12-06 22:37:44,924] [INFO] [launch.py:155:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.22.3-1+cuda12.5\n",
      "[2025-12-06 22:37:44,924] [INFO] [launch.py:155:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
      "[2025-12-06 22:37:44,924] [INFO] [launch.py:155:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.22.3-1\n",
      "[2025-12-06 22:37:44,924] [INFO] [launch.py:162:main] WORLD INFO DICT: {'localhost': [0, 1]}\n",
      "[2025-12-06 22:37:44,924] [INFO] [launch.py:168:main] nnodes=1, num_local_procs=2, node_rank=0\n",
      "[2025-12-06 22:37:44,924] [INFO] [launch.py:179:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1]})\n",
      "[2025-12-06 22:37:44,924] [INFO] [launch.py:180:main] dist_world_size=2\n",
      "[2025-12-06 22:37:44,924] [INFO] [launch.py:184:main] Setting CUDA_VISIBLE_DEVICES=0,1\n",
      "[2025-12-06 22:37:44,925] [INFO] [launch.py:272:main] process 510 spawned with command: ['/usr/bin/python3', '-u', 'train_deepspeed_stage2_vit_huge_bs16.py', '--local_rank=0']\n",
      "[2025-12-06 22:37:44,926] [INFO] [launch.py:272:main] process 511 spawned with command: ['/usr/bin/python3', '-u', 'train_deepspeed_stage2_vit_huge_bs16.py', '--local_rank=1']\n",
      "2025-12-06 22:37:50.251977: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-06 22:37:50.266145: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765060670.276027     511 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1765060670.283299     511 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765060670.288591     510 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1765060670.295479     510 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "--- Initializing DEEPSPEED ZeRO Stage 2 (Multi-GPU Profiling) ---\n",
      "[Rank 0] Initializing process on GPU 0...\n",
      "--- Initializing DEEPSPEED ZeRO Stage 2 (Multi-GPU Profiling) ---\n",
      "[Rank 1] Initializing process on GPU 1...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msiddpath\u001b[0m (\u001b[33msiddpath-university-of-maryland\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20251206_223800-w7cg0tv9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mDeepSpeed-Stage2-ViT-Huge-Food101-2xT4-MBS16-GAS1-Batch-size-16-per-gpu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/siddpath-university-of-maryland/Distributed%20ViT%20training%20systems-Latest_run\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/siddpath-university-of-maryland/Distributed%20ViT%20training%20systems-Latest_run/runs/w7cg0tv9\u001b[0m\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-huge-patch14-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Loading pre-trained ViT-Huge model...\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-huge-patch14-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Initializing DeepSpeed...\n",
      "[rank1]:[W1206 22:38:43.126163102 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "Setting up data...\n",
      "[rank0]:[W1206 22:38:44.286796340 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "\n",
      "======================================================================\n",
      "--- STARTING TRAINING WITH PROFILING ---\n",
      "  - Profiling: ALL ranks (first 0 steps)\n",
      "  - Training: Continues FULLY after profiling\n",
      "======================================================================\n",
      "\n",
      "  [GPU 0] Epoch 0 | Step 0 | Loss: 4.6250\n",
      "\n",
      ">>> Profiling complete. Merging traces while training continues... <<<\n",
      "\n",
      "[Rank 0] Merging traces from all ranks...\n",
      "  WARNING: No trace files found yet!\n",
      ">>> Resuming full training loop... <<<\n",
      "\n",
      "  [GPU 0] Epoch 0 | Step 10 | Loss: 4.6055\n",
      "  [GPU 0] Epoch 0 | Step 20 | Loss: 4.5820\n",
      "  [GPU 0] Epoch 0 | Step 30 | Loss: 4.5430\n",
      "  [GPU 0] Epoch 0 | Step 40 | Loss: 4.5273\n",
      "  [GPU 0] Epoch 0 | Step 50 | Loss: 4.4727\n",
      "  [GPU 0] Epoch 0 | Step 60 | Loss: 4.4922\n",
      "  [GPU 0] Epoch 0 | Step 70 | Loss: 4.4492\n",
      "  [GPU 0] Epoch 0 | Step 80 | Loss: 4.4219\n",
      "  [GPU 0] Epoch 0 | Step 90 | Loss: 4.3086\n",
      "  [GPU 0] Epoch 0 | Step 100 | Loss: 4.3047\n",
      "  [GPU 0] Epoch 0 | Step 110 | Loss: 4.3945\n",
      "  [GPU 0] Epoch 0 | Step 120 | Loss: 4.2812\n",
      "  [GPU 0] Epoch 0 | Step 130 | Loss: 4.2227\n",
      "  [GPU 0] Epoch 0 | Step 140 | Loss: 4.1562\n",
      "  [GPU 0] Epoch 0 | Step 150 | Loss: 4.0586\n",
      "  [GPU 0] Epoch 0 | Step 160 | Loss: 4.1523\n",
      "  [GPU 0] Epoch 0 | Step 170 | Loss: 3.9141\n",
      "  [GPU 0] Epoch 0 | Step 180 | Loss: 4.0234\n",
      "  [GPU 0] Epoch 0 | Step 190 | Loss: 3.9121\n",
      "  [GPU 0] Epoch 0 | Step 200 | Loss: 3.8223\n",
      "  [GPU 0] Epoch 0 | Step 210 | Loss: 3.9766\n",
      "  [GPU 0] Epoch 0 | Step 220 | Loss: 3.6953\n",
      "  [GPU 0] Epoch 0 | Step 230 | Loss: 3.6211\n",
      "  [GPU 0] Epoch 0 | Step 240 | Loss: 3.6309\n",
      "  [GPU 0] Epoch 0 | Step 250 | Loss: 3.4375\n",
      "  [GPU 0] Epoch 0 | Step 260 | Loss: 3.6094\n",
      "  [GPU 0] Epoch 0 | Step 270 | Loss: 3.6660\n",
      "  [GPU 0] Epoch 0 | Step 280 | Loss: 3.6680\n",
      "  [GPU 0] Epoch 0 | Step 290 | Loss: 3.4570\n",
      "  [GPU 0] Epoch 0 | Step 300 | Loss: 3.2832\n",
      "  [GPU 0] Epoch 0 | Step 310 | Loss: 3.2344\n",
      "  [GPU 0] Epoch 0 | Step 320 | Loss: 3.3438\n",
      "  [GPU 0] Epoch 0 | Step 330 | Loss: 3.1660\n",
      "  [GPU 0] Epoch 0 | Step 340 | Loss: 3.2695\n",
      "  [GPU 0] Epoch 0 | Step 350 | Loss: 3.2051\n",
      "  [GPU 0] Epoch 0 | Step 360 | Loss: 3.3555\n",
      "  [GPU 0] Epoch 0 | Step 370 | Loss: 2.9375\n",
      "  [GPU 0] Epoch 0 | Step 380 | Loss: 3.2266\n",
      "  [GPU 0] Epoch 0 | Step 390 | Loss: 2.9023\n",
      "  [GPU 0] Epoch 0 | Step 400 | Loss: 3.1152\n",
      "  [GPU 0] Epoch 0 | Step 410 | Loss: 3.1641\n",
      "  [GPU 0] Epoch 0 | Step 420 | Loss: 2.9883\n",
      "  [GPU 0] Epoch 0 | Step 430 | Loss: 2.9238\n",
      "  [GPU 0] Epoch 0 | Step 440 | Loss: 3.1367\n",
      "  [GPU 0] Epoch 0 | Step 450 | Loss: 2.9688\n",
      "  [GPU 0] Epoch 0 | Step 460 | Loss: 3.1387\n",
      "  [GPU 0] Epoch 0 | Step 470 | Loss: 2.8867\n",
      "  [GPU 0] Epoch 0 | Step 480 | Loss: 2.7266\n",
      "  [GPU 0] Epoch 0 | Step 490 | Loss: 3.1465\n",
      "  [GPU 0] Epoch 0 | Step 500 | Loss: 2.5879\n",
      "  [GPU 0] Epoch 0 | Step 510 | Loss: 2.8535\n",
      "  [GPU 0] Epoch 0 | Step 520 | Loss: 3.1445\n",
      "  [GPU 0] Epoch 0 | Step 530 | Loss: 2.6855\n",
      "  [GPU 0] Epoch 0 | Step 540 | Loss: 3.0664\n",
      "  [GPU 0] Epoch 0 | Step 550 | Loss: 2.6602\n",
      "  [GPU 0] Epoch 0 | Step 560 | Loss: 2.7285\n",
      "  [GPU 0] Epoch 0 | Step 570 | Loss: 2.8418\n",
      "  [GPU 0] Epoch 0 | Step 580 | Loss: 3.3027\n",
      "  [GPU 0] Epoch 0 | Step 590 | Loss: 2.5957\n",
      "  [GPU 0] Epoch 0 | Step 600 | Loss: 2.6211\n",
      "  [GPU 0] Epoch 0 | Step 610 | Loss: 2.4551\n",
      "  [GPU 0] Epoch 0 | Step 620 | Loss: 2.4395\n",
      "  [GPU 0] Epoch 0 | Step 630 | Loss: 2.9531\n",
      "  [GPU 0] Epoch 0 | Step 640 | Loss: 2.5918\n",
      "  [GPU 0] Epoch 0 | Step 650 | Loss: 2.6660\n",
      "  [GPU 0] Epoch 0 | Step 660 | Loss: 2.4395\n",
      "  [GPU 0] Epoch 0 | Step 670 | Loss: 1.9463\n",
      "  [GPU 0] Epoch 0 | Step 680 | Loss: 2.4531\n",
      "  [GPU 0] Epoch 0 | Step 690 | Loss: 1.8770\n",
      "  [GPU 0] Epoch 0 | Step 700 | Loss: 2.5898\n",
      "  [GPU 0] Epoch 0 | Step 710 | Loss: 2.0703\n",
      "  [GPU 0] Epoch 0 | Step 720 | Loss: 2.1133\n",
      "  [GPU 0] Epoch 0 | Step 730 | Loss: 2.3555\n",
      "  [GPU 0] Epoch 0 | Step 740 | Loss: 2.0273\n",
      "  [GPU 0] Epoch 0 | Step 750 | Loss: 2.2012\n",
      "  [GPU 0] Epoch 0 | Step 760 | Loss: 1.9873\n",
      "  [GPU 0] Epoch 0 | Step 770 | Loss: 2.1738\n",
      "  [GPU 0] Epoch 0 | Step 780 | Loss: 1.7402\n",
      "  [GPU 0] Epoch 0 | Step 790 | Loss: 2.5605\n",
      "  [GPU 0] Epoch 0 | Step 800 | Loss: 1.9492\n",
      "  [GPU 0] Epoch 0 | Step 810 | Loss: 1.9365\n",
      "  [GPU 0] Epoch 0 | Step 820 | Loss: 1.8975\n",
      "  [GPU 0] Epoch 0 | Step 830 | Loss: 2.3555\n",
      "  [GPU 0] Epoch 0 | Step 840 | Loss: 1.7441\n",
      "  [GPU 0] Epoch 0 | Step 850 | Loss: 2.3828\n",
      "  [GPU 0] Epoch 0 | Step 860 | Loss: 1.7441\n",
      "  [GPU 0] Epoch 0 | Step 870 | Loss: 1.5781\n",
      "  [GPU 0] Epoch 0 | Step 880 | Loss: 2.0820\n",
      "  [GPU 0] Epoch 0 | Step 890 | Loss: 2.1543\n",
      "  [GPU 0] Epoch 0 | Step 900 | Loss: 2.2637\n",
      "  [GPU 0] Epoch 0 | Step 910 | Loss: 2.2441\n",
      "  [GPU 0] Epoch 0 | Step 920 | Loss: 1.7109\n",
      "  [GPU 0] Epoch 0 | Step 930 | Loss: 1.8965\n",
      "  [GPU 0] Epoch 0 | Step 940 | Loss: 1.6133\n",
      "  [GPU 0] Epoch 0 | Step 950 | Loss: 1.5264\n",
      "  [GPU 0] Epoch 0 | Step 960 | Loss: 1.7148\n",
      "  [GPU 0] Epoch 0 | Step 970 | Loss: 1.5049\n",
      "  [GPU 0] Epoch 0 | Step 980 | Loss: 1.7578\n",
      "  [GPU 0] Epoch 0 | Step 990 | Loss: 2.1367\n",
      "  [GPU 0] Epoch 0 | Step 1000 | Loss: 1.3486\n",
      "  [GPU 0] Epoch 0 | Step 1010 | Loss: 2.1973\n",
      "  [GPU 0] Epoch 0 | Step 1020 | Loss: 2.0703\n",
      "  [GPU 0] Epoch 0 | Step 1030 | Loss: 1.3135\n",
      "  [GPU 0] Epoch 0 | Step 1040 | Loss: 1.8184\n",
      "  [GPU 0] Epoch 0 | Step 1050 | Loss: 1.7646\n",
      "  [GPU 0] Epoch 0 | Step 1060 | Loss: 1.1895\n",
      "  [GPU 0] Epoch 0 | Step 1070 | Loss: 1.7217\n",
      "  [GPU 0] Epoch 0 | Step 1080 | Loss: 1.6719\n",
      "  [GPU 0] Epoch 0 | Step 1090 | Loss: 1.8047\n",
      "  [GPU 0] Epoch 0 | Step 1100 | Loss: 1.3232\n",
      "  [GPU 0] Epoch 0 | Step 1110 | Loss: 1.4482\n",
      "  [GPU 0] Epoch 0 | Step 1120 | Loss: 2.0312\n",
      "  [GPU 0] Epoch 0 | Step 1130 | Loss: 1.7363\n",
      "  [GPU 0] Epoch 0 | Step 1140 | Loss: 1.3252\n",
      "  [GPU 0] Epoch 0 | Step 1150 | Loss: 1.7510\n",
      "  [GPU 0] Epoch 0 | Step 1160 | Loss: 1.4893\n",
      "  [GPU 0] Epoch 0 | Step 1170 | Loss: 1.2354\n",
      "  [GPU 0] Epoch 0 | Step 1180 | Loss: 1.5645\n",
      "  [GPU 0] Epoch 0 | Step 1190 | Loss: 1.3857\n",
      "  [GPU 0] Epoch 0 | Step 1200 | Loss: 1.4814\n",
      "  [GPU 0] Epoch 0 | Step 1210 | Loss: 2.0020\n",
      "  [GPU 0] Epoch 0 | Step 1220 | Loss: 1.6875\n",
      "  [GPU 0] Epoch 0 | Step 1230 | Loss: 1.4150\n",
      "  [GPU 0] Epoch 0 | Step 1240 | Loss: 1.1670\n",
      "  [GPU 0] Epoch 0 | Step 1250 | Loss: 2.2188\n",
      "  [GPU 0] Epoch 0 | Step 1260 | Loss: 1.2930\n",
      "  [GPU 0] Epoch 0 | Step 1270 | Loss: 1.6475\n",
      "  [GPU 0] Epoch 0 | Step 1280 | Loss: 1.6221\n",
      "  [GPU 0] Epoch 0 | Step 1290 | Loss: 1.3613\n",
      "  [GPU 0] Epoch 0 | Step 1300 | Loss: 1.6250\n",
      "  [GPU 0] Epoch 0 | Step 1310 | Loss: 1.2188\n",
      "  [GPU 0] Epoch 0 | Step 1320 | Loss: 1.8457\n",
      "  [GPU 0] Epoch 0 | Step 1330 | Loss: 1.6406\n",
      "  [GPU 0] Epoch 0 | Step 1340 | Loss: 1.5195\n",
      "  [GPU 0] Epoch 0 | Step 1350 | Loss: 1.8545\n",
      "  [GPU 0] Epoch 0 | Step 1360 | Loss: 1.2236\n",
      "  [GPU 0] Epoch 0 | Step 1370 | Loss: 1.0098\n",
      "  [GPU 0] Epoch 0 | Step 1380 | Loss: 1.1221\n",
      "  [GPU 0] Epoch 0 | Step 1390 | Loss: 0.9385\n",
      "  [GPU 0] Epoch 0 | Step 1400 | Loss: 1.5908\n",
      "  [GPU 0] Epoch 0 | Step 1410 | Loss: 1.0908\n",
      "  [GPU 0] Epoch 0 | Step 1420 | Loss: 1.4092\n",
      "  [GPU 0] Epoch 0 | Step 1430 | Loss: 1.0264\n",
      "  [GPU 0] Epoch 0 | Step 1440 | Loss: 1.1426\n",
      "  [GPU 0] Epoch 0 | Step 1450 | Loss: 1.3936\n",
      "  [GPU 0] Epoch 0 | Step 1460 | Loss: 1.3896\n",
      "  [GPU 0] Epoch 0 | Step 1470 | Loss: 0.7979\n",
      "  [GPU 0] Epoch 0 | Step 1480 | Loss: 1.0762\n",
      "  [GPU 0] Epoch 0 | Step 1490 | Loss: 1.4219\n",
      "  [GPU 0] Epoch 0 | Step 1500 | Loss: 1.8525\n",
      "  [GPU 0] Epoch 0 | Step 1510 | Loss: 1.6201\n",
      "  [GPU 0] Epoch 0 | Step 1520 | Loss: 1.2715\n",
      "  [GPU 0] Epoch 0 | Step 1530 | Loss: 1.5449\n",
      "  [GPU 0] Epoch 0 | Step 1540 | Loss: 1.1914\n",
      "  [GPU 0] Epoch 0 | Step 1550 | Loss: 1.2783\n",
      "  [GPU 0] Epoch 0 | Step 1560 | Loss: 1.3447\n",
      "  [GPU 0] Epoch 0 | Step 1570 | Loss: 1.5479\n",
      "  [GPU 0] Epoch 0 | Step 1580 | Loss: 1.3779\n",
      "  [GPU 0] Epoch 0 | Step 1590 | Loss: 1.0898\n",
      "  [GPU 0] Epoch 0 | Step 1600 | Loss: 0.9844\n",
      "  [GPU 0] Epoch 0 | Step 1610 | Loss: 0.9175\n",
      "  [GPU 0] Epoch 0 | Step 1620 | Loss: 1.4004\n",
      "  [GPU 0] Epoch 0 | Step 1630 | Loss: 1.8535\n",
      "  [GPU 0] Epoch 0 | Step 1640 | Loss: 1.0107\n",
      "  [GPU 0] Epoch 0 | Step 1650 | Loss: 0.7866\n",
      "  [GPU 0] Epoch 0 | Step 1660 | Loss: 0.8042\n",
      "  [GPU 0] Epoch 0 | Step 1670 | Loss: 1.0703\n",
      "  [GPU 0] Epoch 0 | Step 1680 | Loss: 0.6968\n",
      "  [GPU 0] Epoch 0 | Step 1690 | Loss: 0.8823\n",
      "  [GPU 0] Epoch 0 | Step 1700 | Loss: 1.4102\n",
      "  [GPU 0] Epoch 0 | Step 1710 | Loss: 0.7964\n",
      "  [GPU 0] Epoch 0 | Step 1720 | Loss: 0.6216\n",
      "  [GPU 0] Epoch 0 | Step 1730 | Loss: 0.9492\n",
      "  [GPU 0] Epoch 0 | Step 1740 | Loss: 1.4600\n",
      "  [GPU 0] Epoch 0 | Step 1750 | Loss: 1.1494\n",
      "  [GPU 0] Epoch 0 | Step 1760 | Loss: 1.0996\n",
      "  [GPU 0] Epoch 0 | Step 1770 | Loss: 1.4795\n",
      "  [GPU 0] Epoch 0 | Step 1780 | Loss: 1.2100\n",
      "  [GPU 0] Epoch 0 | Step 1790 | Loss: 1.4014\n",
      "  [GPU 0] Epoch 0 | Step 1800 | Loss: 1.5391\n",
      "  [GPU 0] Epoch 0 | Step 1810 | Loss: 0.9722\n",
      "  [GPU 0] Epoch 0 | Step 1820 | Loss: 1.5215\n",
      "  [GPU 0] Epoch 0 | Step 1830 | Loss: 0.7876\n",
      "  [GPU 0] Epoch 0 | Step 1840 | Loss: 2.2578\n",
      "  [GPU 0] Epoch 0 | Step 1850 | Loss: 1.4395\n",
      "  [GPU 0] Epoch 0 | Step 1860 | Loss: 0.3364\n",
      "  [GPU 0] Epoch 0 | Step 1870 | Loss: 0.9907\n",
      "  [GPU 0] Epoch 0 | Step 1880 | Loss: 1.1611\n",
      "  [GPU 0] Epoch 0 | Step 1890 | Loss: 0.6523\n",
      "  [GPU 0] Epoch 0 | Step 1900 | Loss: 0.5591\n",
      "  [GPU 0] Epoch 0 | Step 1910 | Loss: 0.9966\n",
      "  [GPU 0] Epoch 0 | Step 1920 | Loss: 1.0234\n",
      "  [GPU 0] Epoch 0 | Step 1930 | Loss: 0.8081\n",
      "  [GPU 0] Epoch 0 | Step 1940 | Loss: 0.7134\n",
      "  [GPU 0] Epoch 0 | Step 1950 | Loss: 0.4197\n",
      "  [GPU 0] Epoch 0 | Step 1960 | Loss: 0.5176\n",
      "  [GPU 0] Epoch 0 | Step 1970 | Loss: 1.1162\n",
      "  [GPU 0] Epoch 0 | Step 1980 | Loss: 0.7793\n",
      "  [GPU 0] Epoch 0 | Step 1990 | Loss: 1.4541\n",
      "  [GPU 0] Epoch 0 | Step 2000 | Loss: 0.7227\n",
      "  [GPU 0] Epoch 0 | Step 2010 | Loss: 0.4319\n",
      "  [GPU 0] Epoch 0 | Step 2020 | Loss: 1.1318\n",
      "  [GPU 0] Epoch 0 | Step 2030 | Loss: 0.5586\n",
      "  [GPU 0] Epoch 0 | Step 2040 | Loss: 0.8486\n",
      "  [GPU 0] Epoch 0 | Step 2050 | Loss: 0.5913\n",
      "  [GPU 0] Epoch 0 | Step 2060 | Loss: 1.0098\n",
      "  [GPU 0] Epoch 0 | Step 2070 | Loss: 0.8315\n",
      "  [GPU 0] Epoch 0 | Step 2080 | Loss: 1.2021\n",
      "  [GPU 0] Epoch 0 | Step 2090 | Loss: 1.9307\n",
      "  [GPU 0] Epoch 0 | Step 2100 | Loss: 0.7241\n",
      "  [GPU 0] Epoch 0 | Step 2110 | Loss: 0.8540\n",
      "  [GPU 0] Epoch 0 | Step 2120 | Loss: 1.0508\n",
      "  [GPU 0] Epoch 0 | Step 2130 | Loss: 0.7705\n",
      "  [GPU 0] Epoch 0 | Step 2140 | Loss: 0.5518\n",
      "  [GPU 0] Epoch 0 | Step 2150 | Loss: 0.9194\n",
      "  [GPU 0] Epoch 0 | Step 2160 | Loss: 0.8867\n",
      "  [GPU 0] Epoch 0 | Step 2170 | Loss: 0.8101\n",
      "  [GPU 0] Epoch 0 | Step 2180 | Loss: 0.7500\n",
      "  [GPU 0] Epoch 0 | Step 2190 | Loss: 0.9727\n",
      "  [GPU 0] Epoch 0 | Step 2200 | Loss: 0.9219\n",
      "  [GPU 0] Epoch 0 | Step 2210 | Loss: 1.0029\n",
      "  [GPU 0] Epoch 0 | Step 2220 | Loss: 1.1953\n",
      "  [GPU 0] Epoch 0 | Step 2230 | Loss: 1.3701\n",
      "  [GPU 0] Epoch 0 | Step 2240 | Loss: 1.2451\n",
      "  [GPU 0] Epoch 0 | Step 2250 | Loss: 1.2744\n",
      "  [GPU 0] Epoch 0 | Step 2260 | Loss: 0.8760\n",
      "  [GPU 0] Epoch 0 | Step 2270 | Loss: 0.6548\n",
      "  [GPU 0] Epoch 0 | Step 2280 | Loss: 0.4978\n",
      "  [GPU 0] Epoch 0 | Step 2290 | Loss: 0.6211\n",
      "  [GPU 0] Epoch 0 | Step 2300 | Loss: 0.8643\n",
      "  [GPU 0] Epoch 0 | Step 2310 | Loss: 0.6992\n",
      "  [GPU 0] Epoch 0 | Step 2320 | Loss: 0.7373\n",
      "  [GPU 0] Epoch 0 | Step 2330 | Loss: 0.7104\n",
      "  [GPU 0] Epoch 0 | Step 2340 | Loss: 0.5786\n",
      "  [GPU 0] Epoch 0 | Step 2350 | Loss: 0.8423\n",
      "  [GPU 0] Epoch 0 | Step 2360 | Loss: 1.3994\n",
      "\n",
      "======================================================================\n",
      "TRAINING COMPLETE\n",
      "======================================================================\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss ██▇▇▇▆▆▆▆▆▅▅▄▄▅▄▃▄▄▃▃▄▃▃▄▂▃▁▄▂▃▃▂▂▂▂▂▁▂▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: step ▁▁▁▁▁▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss 0.64307\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: step 2367\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mDeepSpeed-Stage2-ViT-Huge-Food101-2xT4-MBS16-GAS1-Batch-size-16-per-gpu\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/siddpath-university-of-maryland/Distributed%20ViT%20training%20systems-Latest_run/runs/w7cg0tv9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/siddpath-university-of-maryland/Distributed%20ViT%20training%20systems-Latest_run\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251206_223800-w7cg0tv9/logs\u001b[0m\n",
      "--- [Rank 0] Done ---\n",
      "--- [Rank 1] Done ---\n",
      "[2025-12-07 00:08:10,995] [INFO] [launch.py:367:main] Process 510 exits successfully.\n",
      "[2025-12-07 00:08:11,995] [INFO] [launch.py:367:main] Process 511 exits successfully.\n"
     ]
    }
   ],
   "source": [
    "!deepspeed --num_gpus=2 train_deepspeed_stage2_vit_huge_bs16.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T03:23:59.284992Z",
     "iopub.status.busy": "2025-12-03T03:23:59.284258Z",
     "iopub.status.idle": "2025-12-03T03:24:10.949971Z",
     "shell.execute_reply": "2025-12-03T03:24:10.949241Z",
     "shell.execute_reply.started": "2025-12-03T03:23:59.284965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/working/pytorch_traces/deepspeed_stage2_trace/ (stored 0%)\n",
      "  adding: kaggle/working/pytorch_traces/deepspeed_stage2_trace/merged_multi_gpu_trace.json (deflated 93%)\n",
      "  adding: kaggle/working/pytorch_traces/deepspeed_stage2_trace/e9b764cef546_490.1764732007835768228.pt.trace.json (deflated 93%)\n",
      "  adding: kaggle/working/pytorch_traces/deepspeed_stage2_trace/e9b764cef546_491.1764732007918481049.pt.trace.json (deflated 93%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system('zip -r deepspeed_stage2_trace.zip /kaggle/working/pytorch_traces/deepspeed_stage2_trace')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-03T03:48:04.097983Z",
     "iopub.status.busy": "2025-12-03T03:48:04.097621Z",
     "iopub.status.idle": "2025-12-03T03:48:04.431842Z",
     "shell.execute_reply": "2025-12-03T03:48:04.430941Z",
     "shell.execute_reply.started": "2025-12-03T03:48:04.097956Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path = Path('/kaggle/working/pytorch_traces/deepspeed_stage3_trace')\n",
    "\n",
    "if path.is_file():\n",
    "    path.unlink()  # Delete file\n",
    "elif path.is_dir():\n",
    "    import shutil\n",
    "    shutil.rmtree(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script for DeepSpeed Full Fine-Tune, running on 2 T4 gpus stage 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T00:08:16.649621Z",
     "iopub.status.busy": "2025-12-07T00:08:16.649252Z",
     "iopub.status.idle": "2025-12-07T00:08:16.655956Z",
     "shell.execute_reply": "2025-12-07T00:08:16.655201Z",
     "shell.execute_reply.started": "2025-12-07T00:08:16.649594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing deepspeed_config_stage3_vit_huge_bs16.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile deepspeed_config_stage3_vit_huge_bs16.json\n",
    "{\n",
    "    \"fp16\": {\n",
    "        \"enabled\": true,\n",
    "        \"loss_scale\": 0,\n",
    "        \"loss_scale_window\": 1000\n",
    "    },\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": 5e-5,\n",
    "            \"betas\": [0.9, 0.999],\n",
    "            \"eps\": 1e-8,\n",
    "            \"weight_decay\": 3e-7\n",
    "        }\n",
    "    },\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 3,\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"none\"\n",
    "        },\n",
    "        \"offload_param\": {\n",
    "            \"device\": \"none\"\n",
    "        },\n",
    "        \"overlap_comm\": true,\n",
    "        \"contiguous_gradients\": true,\n",
    "        \"stage3_max_live_parameters\": 1e9,\n",
    "        \"stage3_max_reuse_distance\": 1e9,\n",
    "        \"stage3_prefetch_bucket_size\": 5e7,\n",
    "        \"stage3_param_persistence_threshold\": 1e5,\n",
    "        \"reduce_bucket_size\": 5e8,\n",
    "        \"sub_group_size\": 1e9\n",
    "    },\n",
    "    \"train_batch_size\": 32,\n",
    "    \"train_micro_batch_size_per_gpu\": 16,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"gradient_clipping\": 1.0,\n",
    "    \"steps_per_print\": 1,\n",
    "    \"wall_clock_breakdown\": false,\n",
    "    \"flops_profiler\": {\n",
    "        \"enabled\": false\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T00:08:16.657041Z",
     "iopub.status.busy": "2025-12-07T00:08:16.656853Z",
     "iopub.status.idle": "2025-12-07T00:08:16.674686Z",
     "shell.execute_reply": "2025-12-07T00:08:16.673894Z",
     "shell.execute_reply.started": "2025-12-07T00:08:16.657026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train_deepspeed_stage3_vit_huge_bs16.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_deepspeed_stage3_vit_huge_bs16.py\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor\n",
    "import deepspeed\n",
    "import warnings\n",
    "import wandb\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import torch.profiler\n",
    "import json\n",
    "import glob\n",
    "\n",
    "# --- TRACE DIRECTORY SETUP ---\n",
    "TRACE_DIR = \"./pytorch_traces/deepspeed_stage3_trace\"\n",
    "MERGED_TRACE_FILE = \"./pytorch_traces/deepspeed_stage3_trace/merged_stage3_trace.json\"\n",
    "\n",
    "# Cleanup old runs to avoid confusion (only rank 0)\n",
    "if int(os.environ.get('RANK', 0)) == 0:\n",
    "    if os.path.exists(TRACE_DIR):\n",
    "        try: shutil.rmtree(TRACE_DIR)\n",
    "        except: pass\n",
    "    os.makedirs(TRACE_DIR, exist_ok=True)\n",
    "    if os.path.exists(MERGED_TRACE_FILE):\n",
    "        os.remove(MERGED_TRACE_FILE)\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(\"--- Initializing DEEPSPEED ZeRO Stage 3 (Multi-GPU Profiling) ---\")\n",
    "\n",
    "# --- 1. Setup ---\n",
    "local_rank = int(os.environ.get('LOCAL_RANK', 0))\n",
    "rank = int(os.environ.get('RANK', 0))\n",
    "world_size = int(os.environ.get('WORLD_SIZE', 1))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(local_rank)\n",
    "    print(f\"[Rank {rank}] Initializing process on GPU {local_rank}...\")\n",
    "else:\n",
    "    print(f\"[Rank {rank}] WARNING: No CUDA available, running on CPU\")\n",
    "\n",
    "# --- W&B Setup ---\n",
    "if rank == 0:\n",
    "    wandb.init(\n",
    "        project=\"Distributed ViT training systems-Latest_run\", \n",
    "        name=\"DeepSpeed-Stage3-ViT-Huge-Food101-2xT4-MBS16-GAS1-Batch-size-16-per-gpu\",\n",
    "        config={\n",
    "            \"optimization\": \"Stage 3\",\n",
    "            \"num_gpus\": world_size,\n",
    "            \"profiling\": \"Rank 0 & 1 (Merged)\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "# --- 2. Model Setup ---\n",
    "if rank == 0: print(\"Loading pre-trained ViT-Huge model...\")\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    'google/vit-huge-patch14-224-in21k', \n",
    "    num_labels=101, \n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "# --- 3. DeepSpeed Init ---\n",
    "if rank == 0: print(\"Initializing DeepSpeed...\")\n",
    "model_engine, optimizer, _, _ = deepspeed.initialize(\n",
    "    model=model, \n",
    "    model_parameters=model.parameters(), \n",
    "    config_params='deepspeed_config_stage3_vit_huge_bs16.json'\n",
    ")\n",
    "\n",
    "# --- 4. Data Prep ---\n",
    "if rank == 0: print(\"Setting up data...\")\n",
    "processor = ViTImageProcessor.from_pretrained('google/vit-huge-patch14-224-in21k')\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(224, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=processor.image_mean, std=processor.image_std)\n",
    "])\n",
    "\n",
    "if rank == 0:\n",
    "    trainset = torchvision.datasets.Food101(root='./data', split=\"train\", download=True, transform=train_transform)\n",
    "\n",
    "if world_size > 1: dist.barrier()\n",
    "    \n",
    "if rank != 0:\n",
    "    trainset = torchvision.datasets.Food101(root='./data', split=\"train\", download=False, transform=train_transform)\n",
    "\n",
    "MICRO_BATCH_SIZE = 16\n",
    "train_sampler = DistributedSampler(trainset, num_replicas=world_size, rank=rank, shuffle=True)\n",
    "train_loader = DataLoader(trainset, batch_size=MICRO_BATCH_SIZE, sampler=train_sampler, num_workers=2, pin_memory=True)\n",
    "\n",
    "# --- ROBUST MERGE FUNCTION ---\n",
    "def merge_traces_logic():\n",
    "    \"\"\"Merge all rank traces into a single file for Perfetto (Handles String PIDs)\"\"\"\n",
    "    print(f\"\\n[Rank 0] Merging traces from all ranks...\")\n",
    "    trace_files = sorted(glob.glob(os.path.join(TRACE_DIR, \"*.pt.trace.json\")))\n",
    "    \n",
    "    if not trace_files:\n",
    "        print(\"  WARNING: No trace files found yet!\")\n",
    "        return\n",
    "    \n",
    "    merged_events = []\n",
    "    metadata = {}\n",
    "    \n",
    "    for idx, trace_file in enumerate(trace_files):\n",
    "        try:\n",
    "            with open(trace_file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            if isinstance(data, dict):\n",
    "                events = data.get(\"traceEvents\", [])\n",
    "                if idx == 0: metadata = {k: v for k, v in data.items() if k != \"traceEvents\"}\n",
    "            else:\n",
    "                events = data\n",
    "            \n",
    "            # --- ROBUST PID/TID OFFSETTING ---\n",
    "            for event in events:\n",
    "                if \"pid\" in event:\n",
    "                    try: event[\"pid\"] = int(event[\"pid\"]) + (idx * 100000)\n",
    "                    except ValueError: event[\"pid\"] = f\"{event['pid']}_{idx}\"\n",
    "\n",
    "                if \"tid\" in event:\n",
    "                    try: event[\"tid\"] = int(event[\"tid\"]) + (idx * 100000)\n",
    "                    except ValueError: event[\"tid\"] = f\"{event['tid']}_{idx}\"\n",
    "                \n",
    "                if \"name\" in event and isinstance(event[\"name\"], str):\n",
    "                    if not event[\"name\"].startswith(\"[GPU\"):\n",
    "                        event[\"name\"] = f\"[GPU {idx}] {event['name']}\"\n",
    "            \n",
    "            merged_events.extend(events)\n",
    "            print(f\"    Added {len(events)} events from GPU {idx}\")\n",
    "        except Exception as e:\n",
    "            print(f\"    Warning: Could not read {trace_file}: {e}\")\n",
    "\n",
    "    merged_trace = metadata.copy()\n",
    "    merged_trace[\"traceEvents\"] = merged_events\n",
    "    \n",
    "    with open(MERGED_TRACE_FILE, 'w') as f:\n",
    "        json.dump(merged_trace, f)\n",
    "    \n",
    "    print(f\"\\n  MERGE COMPLETE!\")\n",
    "    print(f\"  Saved to: {MERGED_TRACE_FILE}\")\n",
    "    print(f\"  Upload this file to https://ui.perfetto.dev/\\n\")\n",
    "\n",
    "# --- Training Configuration ---\n",
    "device = model_engine.device\n",
    "num_epochs = 1\n",
    "start_time = time.time()\n",
    "PROFILING_STEPS = 0\n",
    "\n",
    "if rank == 0: \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"--- STARTING TRAINING WITH PROFILING ---\")\n",
    "    print(f\"  - Profiling: ALL ranks (first {PROFILING_STEPS} steps)\")\n",
    "    print(f\"  - Training: Continues FULLY after profiling\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "try:\n",
    "    # --- PROFILER INITIALIZATION (ALL RANKS) ---\n",
    "    prof = torch.profiler.profile(\n",
    "        activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "        schedule=torch.profiler.schedule(wait=1, warmup=2, active=5, repeat=1),\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler(TRACE_DIR),\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=True,\n",
    "        with_flops=True\n",
    "    )\n",
    "    # prof.start()\n",
    "    \n",
    "    model_engine.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_sampler.set_epoch(epoch)\n",
    "        epoch_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for i, batch in enumerate(train_loader):\n",
    "            \n",
    "            # --- Profiling Window ---\n",
    "            is_profiling = (i < PROFILING_STEPS)\n",
    "            prof_context = None\n",
    "            \n",
    "            if is_profiling:\n",
    "                prof_context = torch.profiler.record_function(f\"## [GPU {rank}] Step {i} ##\")\n",
    "                prof_context.__enter__()\n",
    "            \n",
    "            inputs, labels = batch\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward\n",
    "            if is_profiling:\n",
    "                with torch.profiler.record_function(f\"## [GPU {rank}] FWD ##\"):\n",
    "                    outputs = model_engine(inputs, labels=labels)\n",
    "                    loss = outputs.loss\n",
    "            else:\n",
    "                outputs = model_engine(inputs, labels=labels)\n",
    "                loss = outputs.loss\n",
    "\n",
    "            # Backward\n",
    "            if is_profiling:\n",
    "                with torch.profiler.record_function(f\"## [GPU {rank}] BWD ##\"):\n",
    "                    model_engine.backward(loss)\n",
    "            else:\n",
    "                model_engine.backward(loss)\n",
    "\n",
    "            # Step\n",
    "            if is_profiling:\n",
    "                with torch.profiler.record_function(f\"## [GPU {rank}] OPT ##\"):\n",
    "                    model_engine.step()\n",
    "            else:\n",
    "                model_engine.step()\n",
    "\n",
    "            # Metrics\n",
    "            loss_val = loss.item()\n",
    "            epoch_loss += loss_val\n",
    "            num_batches += 1\n",
    "\n",
    "            if rank == 0:\n",
    "                wandb.log({\"loss\": loss_val, \"step\": i})\n",
    "                if i % 10 == 0:\n",
    "                    print(f\"  [GPU {rank}] Epoch {epoch} | Step {i} | Loss: {loss_val:.4f}\")\n",
    "\n",
    "            # --- Profiler Stepping ---\n",
    "            if is_profiling:\n",
    "                prof.step()\n",
    "                if prof_context: prof_context.__exit__(None, None, None)\n",
    "            \n",
    "            # --- STOP & MERGE (But continue training) ---\n",
    "            if i == PROFILING_STEPS:\n",
    "                prof.stop() # Save trace files to disk\n",
    "                \n",
    "                # 1. Sync all ranks to ensure writing is done\n",
    "                if world_size > 1: dist.barrier()\n",
    "                \n",
    "                # 2. Rank 0 performs the merge immediately\n",
    "                if rank == 0:\n",
    "                    print(f\"\\n>>> Profiling complete. Merging traces while training continues... <<<\")\n",
    "                    merge_traces_logic()\n",
    "                    print(\">>> Resuming full training loop... <<<\\n\")\n",
    "\n",
    "    # End of Epoch\n",
    "    if rank == 0:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"TRAINING COMPLETE\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        wandb.finish()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[Rank {rank}] ERROR: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "finally:\n",
    "    if world_size > 1:\n",
    "        dist.barrier()\n",
    "        dist.destroy_process_group()\n",
    "    print(f\"--- [Rank {rank}] Done ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T00:08:16.676653Z",
     "iopub.status.busy": "2025-12-07T00:08:16.676373Z",
     "iopub.status.idle": "2025-12-07T01:24:09.832336Z",
     "shell.execute_reply": "2025-12-07T01:24:09.831243Z",
     "shell.execute_reply.started": "2025-12-07T00:08:16.676636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-07 00:08:24.907472: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765066104.932859     736 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1765066104.941369     736 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "[2025-12-07 00:08:30,277] [WARNING] [runner.py:232:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
      "[2025-12-07 00:08:30,278] [INFO] [runner.py:630:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None --log_level=info train_deepspeed_stage3_vit_huge_bs16.py\n",
      "2025-12-07 00:08:37.783337: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765066117.805319     788 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1765066117.812383     788 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "[2025-12-07 00:08:42,908] [INFO] [launch.py:155:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.22.3-1+cuda12.5\n",
      "[2025-12-07 00:08:42,908] [INFO] [launch.py:155:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.22.3-1\n",
      "[2025-12-07 00:08:42,908] [INFO] [launch.py:155:main] 0 NCCL_VERSION=2.22.3-1\n",
      "[2025-12-07 00:08:42,908] [INFO] [launch.py:155:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
      "[2025-12-07 00:08:42,908] [INFO] [launch.py:155:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.22.3-1+cuda12.5\n",
      "[2025-12-07 00:08:42,908] [INFO] [launch.py:155:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
      "[2025-12-07 00:08:42,908] [INFO] [launch.py:155:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.22.3-1\n",
      "[2025-12-07 00:08:42,908] [INFO] [launch.py:162:main] WORLD INFO DICT: {'localhost': [0, 1]}\n",
      "[2025-12-07 00:08:42,909] [INFO] [launch.py:168:main] nnodes=1, num_local_procs=2, node_rank=0\n",
      "[2025-12-07 00:08:42,909] [INFO] [launch.py:179:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1]})\n",
      "[2025-12-07 00:08:42,909] [INFO] [launch.py:180:main] dist_world_size=2\n",
      "[2025-12-07 00:08:42,909] [INFO] [launch.py:184:main] Setting CUDA_VISIBLE_DEVICES=0,1\n",
      "[2025-12-07 00:08:42,909] [INFO] [launch.py:272:main] process 840 spawned with command: ['/usr/bin/python3', '-u', 'train_deepspeed_stage3_vit_huge_bs16.py', '--local_rank=0']\n",
      "[2025-12-07 00:08:42,910] [INFO] [launch.py:272:main] process 841 spawned with command: ['/usr/bin/python3', '-u', 'train_deepspeed_stage3_vit_huge_bs16.py', '--local_rank=1']\n",
      "2025-12-07 00:08:48.254962: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-07 00:08:48.258268: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765066128.277557     840 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765066128.281102     841 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1765066128.285054     840 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "E0000 00:00:1765066128.287836     841 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "--- Initializing DEEPSPEED ZeRO Stage 3 (Multi-GPU Profiling) ---\n",
      "--- Initializing DEEPSPEED ZeRO Stage 3 (Multi-GPU Profiling) ---\n",
      "[Rank 0] Initializing process on GPU 0...\n",
      "[Rank 1] Initializing process on GPU 1...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msiddpath\u001b[0m (\u001b[33msiddpath-university-of-maryland\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20251207_000858-mvkio5ws\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mDeepSpeed-Stage3-ViT-Huge-Food101-2xT4-MBS16-GAS1-Batch-size-16-per-gpu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/siddpath-university-of-maryland/Distributed%20ViT%20training%20systems-Latest_run\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/siddpath-university-of-maryland/Distributed%20ViT%20training%20systems-Latest_run/runs/mvkio5ws\u001b[0m\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-huge-patch14-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Loading pre-trained ViT-Huge model...\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-huge-patch14-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Initializing DeepSpeed...\n",
      "Parameter Offload - Persistent parameters statistics: param_count = 325, numel = 537701\n",
      "Setting up data...\n",
      "\n",
      "======================================================================\n",
      "--- STARTING TRAINING WITH PROFILING ---\n",
      "  - Profiling: ALL ranks (first 0 steps)\n",
      "  - Training: Continues FULLY after profiling\n",
      "======================================================================\n",
      "\n",
      "  [GPU 0] Epoch 0 | Step 0 | Loss: 4.6055\n",
      "\n",
      ">>> Profiling complete. Merging traces while training continues... <<<\n",
      "\n",
      "[Rank 0] Merging traces from all ranks...\n",
      "  WARNING: No trace files found yet!\n",
      ">>> Resuming full training loop... <<<\n",
      "\n",
      "  [GPU 0] Epoch 0 | Step 10 | Loss: 4.5859\n",
      "  [GPU 0] Epoch 0 | Step 20 | Loss: 4.6211\n",
      "  [GPU 0] Epoch 0 | Step 30 | Loss: 4.5117\n",
      "  [GPU 0] Epoch 0 | Step 40 | Loss: 4.5312\n",
      "  [GPU 0] Epoch 0 | Step 50 | Loss: 4.5000\n",
      "  [GPU 0] Epoch 0 | Step 60 | Loss: 4.4688\n",
      "  [GPU 0] Epoch 0 | Step 70 | Loss: 4.4609\n",
      "  [GPU 0] Epoch 0 | Step 80 | Loss: 4.4141\n",
      "  [GPU 0] Epoch 0 | Step 90 | Loss: 4.3086\n",
      "  [GPU 0] Epoch 0 | Step 100 | Loss: 4.2891\n",
      "  [GPU 0] Epoch 0 | Step 110 | Loss: 4.3711\n",
      "  [GPU 0] Epoch 0 | Step 120 | Loss: 4.2773\n",
      "  [GPU 0] Epoch 0 | Step 130 | Loss: 4.2383\n",
      "  [GPU 0] Epoch 0 | Step 140 | Loss: 4.2148\n",
      "  [GPU 0] Epoch 0 | Step 150 | Loss: 4.0039\n",
      "  [GPU 0] Epoch 0 | Step 160 | Loss: 4.1328\n",
      "  [GPU 0] Epoch 0 | Step 170 | Loss: 3.8672\n",
      "  [GPU 0] Epoch 0 | Step 180 | Loss: 3.9688\n",
      "  [GPU 0] Epoch 0 | Step 190 | Loss: 3.9453\n",
      "  [GPU 0] Epoch 0 | Step 200 | Loss: 3.8184\n",
      "  [GPU 0] Epoch 0 | Step 210 | Loss: 3.8750\n",
      "  [GPU 0] Epoch 0 | Step 220 | Loss: 3.6816\n",
      "  [GPU 0] Epoch 0 | Step 230 | Loss: 3.6289\n",
      "  [GPU 0] Epoch 0 | Step 240 | Loss: 3.6445\n",
      "  [GPU 0] Epoch 0 | Step 250 | Loss: 3.3574\n",
      "  [GPU 0] Epoch 0 | Step 260 | Loss: 3.6523\n",
      "  [GPU 0] Epoch 0 | Step 270 | Loss: 3.6133\n",
      "  [GPU 0] Epoch 0 | Step 280 | Loss: 3.6777\n",
      "  [GPU 0] Epoch 0 | Step 290 | Loss: 3.4141\n",
      "  [GPU 0] Epoch 0 | Step 300 | Loss: 3.2188\n",
      "  [GPU 0] Epoch 0 | Step 310 | Loss: 3.2402\n",
      "  [GPU 0] Epoch 0 | Step 320 | Loss: 3.3789\n",
      "  [GPU 0] Epoch 0 | Step 330 | Loss: 3.0957\n",
      "  [GPU 0] Epoch 0 | Step 340 | Loss: 3.2402\n",
      "  [GPU 0] Epoch 0 | Step 350 | Loss: 3.2559\n",
      "  [GPU 0] Epoch 0 | Step 360 | Loss: 3.3691\n",
      "  [GPU 0] Epoch 0 | Step 370 | Loss: 3.0371\n",
      "  [GPU 0] Epoch 0 | Step 380 | Loss: 3.2207\n",
      "  [GPU 0] Epoch 0 | Step 390 | Loss: 2.8164\n",
      "  [GPU 0] Epoch 0 | Step 400 | Loss: 3.2695\n",
      "  [GPU 0] Epoch 0 | Step 410 | Loss: 3.1230\n",
      "  [GPU 0] Epoch 0 | Step 420 | Loss: 3.0488\n",
      "  [GPU 0] Epoch 0 | Step 430 | Loss: 2.9004\n",
      "  [GPU 0] Epoch 0 | Step 440 | Loss: 3.1426\n",
      "  [GPU 0] Epoch 0 | Step 450 | Loss: 2.7617\n",
      "  [GPU 0] Epoch 0 | Step 460 | Loss: 3.1309\n",
      "  [GPU 0] Epoch 0 | Step 470 | Loss: 2.8301\n",
      "  [GPU 0] Epoch 0 | Step 480 | Loss: 2.5723\n",
      "  [GPU 0] Epoch 0 | Step 490 | Loss: 3.0664\n",
      "  [GPU 0] Epoch 0 | Step 500 | Loss: 2.5977\n",
      "  [GPU 0] Epoch 0 | Step 510 | Loss: 2.8359\n",
      "  [GPU 0] Epoch 0 | Step 520 | Loss: 2.9766\n",
      "  [GPU 0] Epoch 0 | Step 530 | Loss: 2.6328\n",
      "  [GPU 0] Epoch 0 | Step 540 | Loss: 3.0684\n",
      "  [GPU 0] Epoch 0 | Step 550 | Loss: 2.8164\n",
      "  [GPU 0] Epoch 0 | Step 560 | Loss: 2.6035\n",
      "  [GPU 0] Epoch 0 | Step 570 | Loss: 2.7363\n",
      "  [GPU 0] Epoch 0 | Step 580 | Loss: 3.2402\n",
      "  [GPU 0] Epoch 0 | Step 590 | Loss: 2.5586\n",
      "  [GPU 0] Epoch 0 | Step 600 | Loss: 2.5293\n",
      "  [GPU 0] Epoch 0 | Step 610 | Loss: 2.4688\n",
      "  [GPU 0] Epoch 0 | Step 620 | Loss: 2.2949\n",
      "  [GPU 0] Epoch 0 | Step 630 | Loss: 3.0938\n",
      "  [GPU 0] Epoch 0 | Step 640 | Loss: 2.7109\n",
      "  [GPU 0] Epoch 0 | Step 650 | Loss: 2.5039\n",
      "  [GPU 0] Epoch 0 | Step 660 | Loss: 2.4570\n",
      "  [GPU 0] Epoch 0 | Step 670 | Loss: 2.0215\n",
      "  [GPU 0] Epoch 0 | Step 680 | Loss: 2.4746\n",
      "  [GPU 0] Epoch 0 | Step 690 | Loss: 1.9902\n",
      "  [GPU 0] Epoch 0 | Step 700 | Loss: 2.6816\n",
      "  [GPU 0] Epoch 0 | Step 710 | Loss: 2.0977\n",
      "  [GPU 0] Epoch 0 | Step 720 | Loss: 2.0117\n",
      "  [GPU 0] Epoch 0 | Step 730 | Loss: 2.3652\n",
      "  [GPU 0] Epoch 0 | Step 740 | Loss: 2.0254\n",
      "  [GPU 0] Epoch 0 | Step 750 | Loss: 2.1406\n",
      "  [GPU 0] Epoch 0 | Step 760 | Loss: 2.2188\n",
      "  [GPU 0] Epoch 0 | Step 770 | Loss: 1.8896\n",
      "  [GPU 0] Epoch 0 | Step 780 | Loss: 1.7197\n",
      "  [GPU 0] Epoch 0 | Step 790 | Loss: 2.5938\n",
      "  [GPU 0] Epoch 0 | Step 800 | Loss: 2.1113\n",
      "  [GPU 0] Epoch 0 | Step 810 | Loss: 2.0410\n",
      "  [GPU 0] Epoch 0 | Step 820 | Loss: 1.8984\n",
      "  [GPU 0] Epoch 0 | Step 830 | Loss: 2.3613\n",
      "  [GPU 0] Epoch 0 | Step 840 | Loss: 1.7646\n",
      "  [GPU 0] Epoch 0 | Step 850 | Loss: 2.2988\n",
      "  [GPU 0] Epoch 0 | Step 860 | Loss: 1.6992\n",
      "  [GPU 0] Epoch 0 | Step 870 | Loss: 1.5234\n",
      "  [GPU 0] Epoch 0 | Step 880 | Loss: 2.0898\n",
      "  [GPU 0] Epoch 0 | Step 890 | Loss: 2.1211\n",
      "  [GPU 0] Epoch 0 | Step 900 | Loss: 2.0859\n",
      "  [GPU 0] Epoch 0 | Step 910 | Loss: 2.2910\n",
      "  [GPU 0] Epoch 0 | Step 920 | Loss: 1.7305\n",
      "  [GPU 0] Epoch 0 | Step 930 | Loss: 1.7686\n",
      "  [GPU 0] Epoch 0 | Step 940 | Loss: 1.5586\n",
      "  [GPU 0] Epoch 0 | Step 950 | Loss: 1.6191\n",
      "  [GPU 0] Epoch 0 | Step 960 | Loss: 1.7646\n",
      "  [GPU 0] Epoch 0 | Step 970 | Loss: 1.5967\n",
      "  [GPU 0] Epoch 0 | Step 980 | Loss: 1.5889\n",
      "  [GPU 0] Epoch 0 | Step 990 | Loss: 2.1230\n",
      "  [GPU 0] Epoch 0 | Step 1000 | Loss: 1.3740\n",
      "  [GPU 0] Epoch 0 | Step 1010 | Loss: 2.2051\n",
      "  [GPU 0] Epoch 0 | Step 1020 | Loss: 1.8369\n",
      "  [GPU 0] Epoch 0 | Step 1030 | Loss: 1.3965\n",
      "  [GPU 0] Epoch 0 | Step 1040 | Loss: 1.8311\n",
      "  [GPU 0] Epoch 0 | Step 1050 | Loss: 1.7490\n",
      "  [GPU 0] Epoch 0 | Step 1060 | Loss: 1.2354\n",
      "  [GPU 0] Epoch 0 | Step 1070 | Loss: 1.6113\n",
      "  [GPU 0] Epoch 0 | Step 1080 | Loss: 1.6016\n",
      "  [GPU 0] Epoch 0 | Step 1090 | Loss: 1.8633\n",
      "  [GPU 0] Epoch 0 | Step 1100 | Loss: 1.3369\n",
      "  [GPU 0] Epoch 0 | Step 1110 | Loss: 1.5674\n",
      "  [GPU 0] Epoch 0 | Step 1120 | Loss: 1.9678\n",
      "  [GPU 0] Epoch 0 | Step 1130 | Loss: 1.8984\n",
      "  [GPU 0] Epoch 0 | Step 1140 | Loss: 1.2666\n",
      "  [GPU 0] Epoch 0 | Step 1150 | Loss: 1.5898\n",
      "  [GPU 0] Epoch 0 | Step 1160 | Loss: 1.2637\n",
      "  [GPU 0] Epoch 0 | Step 1170 | Loss: 1.2666\n",
      "  [GPU 0] Epoch 0 | Step 1180 | Loss: 1.7305\n",
      "  [GPU 0] Epoch 0 | Step 1190 | Loss: 1.4053\n",
      "  [GPU 0] Epoch 0 | Step 1200 | Loss: 1.5381\n",
      "  [GPU 0] Epoch 0 | Step 1210 | Loss: 2.1816\n",
      "  [GPU 0] Epoch 0 | Step 1220 | Loss: 1.5537\n",
      "  [GPU 0] Epoch 0 | Step 1230 | Loss: 1.5342\n",
      "  [GPU 0] Epoch 0 | Step 1240 | Loss: 1.4189\n",
      "  [GPU 0] Epoch 0 | Step 1250 | Loss: 1.9062\n",
      "  [GPU 0] Epoch 0 | Step 1260 | Loss: 1.4834\n",
      "  [GPU 0] Epoch 0 | Step 1270 | Loss: 1.7158\n",
      "  [GPU 0] Epoch 0 | Step 1280 | Loss: 1.5928\n",
      "  [GPU 0] Epoch 0 | Step 1290 | Loss: 1.3398\n",
      "  [GPU 0] Epoch 0 | Step 1300 | Loss: 1.3359\n",
      "  [GPU 0] Epoch 0 | Step 1310 | Loss: 1.3408\n",
      "  [GPU 0] Epoch 0 | Step 1320 | Loss: 1.8145\n",
      "  [GPU 0] Epoch 0 | Step 1330 | Loss: 1.6855\n",
      "  [GPU 0] Epoch 0 | Step 1340 | Loss: 1.5977\n",
      "  [GPU 0] Epoch 0 | Step 1350 | Loss: 1.9990\n",
      "  [GPU 0] Epoch 0 | Step 1360 | Loss: 0.9497\n",
      "  [GPU 0] Epoch 0 | Step 1370 | Loss: 1.1084\n",
      "  [GPU 0] Epoch 0 | Step 1380 | Loss: 1.0352\n",
      "  [GPU 0] Epoch 0 | Step 1390 | Loss: 0.7891\n",
      "  [GPU 0] Epoch 0 | Step 1400 | Loss: 1.7217\n",
      "  [GPU 0] Epoch 0 | Step 1410 | Loss: 0.7578\n",
      "  [GPU 0] Epoch 0 | Step 1420 | Loss: 1.2910\n",
      "  [GPU 0] Epoch 0 | Step 1430 | Loss: 0.7627\n",
      "  [GPU 0] Epoch 0 | Step 1440 | Loss: 0.9238\n",
      "  [GPU 0] Epoch 0 | Step 1450 | Loss: 2.1309\n",
      "  [GPU 0] Epoch 0 | Step 1460 | Loss: 1.6826\n",
      "  [GPU 0] Epoch 0 | Step 1470 | Loss: 0.8706\n",
      "  [GPU 0] Epoch 0 | Step 1480 | Loss: 1.2754\n",
      "  [GPU 0] Epoch 0 | Step 1490 | Loss: 1.2422\n",
      "  [GPU 0] Epoch 0 | Step 1500 | Loss: 1.4072\n",
      "  [GPU 0] Epoch 0 | Step 1510 | Loss: 1.4648\n",
      "  [GPU 0] Epoch 0 | Step 1520 | Loss: 1.1328\n",
      "  [GPU 0] Epoch 0 | Step 1530 | Loss: 1.3857\n",
      "  [GPU 0] Epoch 0 | Step 1540 | Loss: 1.2041\n",
      "  [GPU 0] Epoch 0 | Step 1550 | Loss: 1.2852\n",
      "  [GPU 0] Epoch 0 | Step 1560 | Loss: 1.4199\n",
      "  [GPU 0] Epoch 0 | Step 1570 | Loss: 1.2959\n",
      "  [GPU 0] Epoch 0 | Step 1580 | Loss: 1.4229\n",
      "  [GPU 0] Epoch 0 | Step 1590 | Loss: 1.0527\n",
      "  [GPU 0] Epoch 0 | Step 1600 | Loss: 0.9316\n",
      "  [GPU 0] Epoch 0 | Step 1610 | Loss: 0.7939\n",
      "  [GPU 0] Epoch 0 | Step 1620 | Loss: 1.5898\n",
      "  [GPU 0] Epoch 0 | Step 1630 | Loss: 1.8271\n",
      "  [GPU 0] Epoch 0 | Step 1640 | Loss: 1.1318\n",
      "  [GPU 0] Epoch 0 | Step 1650 | Loss: 1.0078\n",
      "  [GPU 0] Epoch 0 | Step 1660 | Loss: 0.9868\n",
      "  [GPU 0] Epoch 0 | Step 1670 | Loss: 0.9409\n",
      "  [GPU 0] Epoch 0 | Step 1680 | Loss: 0.6719\n",
      "  [GPU 0] Epoch 0 | Step 1690 | Loss: 0.7739\n",
      "  [GPU 0] Epoch 0 | Step 1700 | Loss: 1.1143\n",
      "  [GPU 0] Epoch 0 | Step 1710 | Loss: 0.8359\n",
      "  [GPU 0] Epoch 0 | Step 1720 | Loss: 0.5503\n",
      "  [GPU 0] Epoch 0 | Step 1730 | Loss: 0.8442\n",
      "  [GPU 0] Epoch 0 | Step 1740 | Loss: 1.2480\n",
      "  [GPU 0] Epoch 0 | Step 1750 | Loss: 0.9971\n",
      "  [GPU 0] Epoch 0 | Step 1760 | Loss: 1.0654\n",
      "  [GPU 0] Epoch 0 | Step 1770 | Loss: 1.5830\n",
      "  [GPU 0] Epoch 0 | Step 1780 | Loss: 1.0811\n",
      "  [GPU 0] Epoch 0 | Step 1790 | Loss: 1.1367\n",
      "  [GPU 0] Epoch 0 | Step 1800 | Loss: 1.3662\n",
      "  [GPU 0] Epoch 0 | Step 1810 | Loss: 0.9609\n",
      "  [GPU 0] Epoch 0 | Step 1820 | Loss: 1.6650\n",
      "  [GPU 0] Epoch 0 | Step 1830 | Loss: 0.6621\n",
      "  [GPU 0] Epoch 0 | Step 1840 | Loss: 2.0391\n",
      "  [GPU 0] Epoch 0 | Step 1850 | Loss: 1.0996\n",
      "  [GPU 0] Epoch 0 | Step 1860 | Loss: 0.4109\n",
      "  [GPU 0] Epoch 0 | Step 1870 | Loss: 0.9507\n",
      "  [GPU 0] Epoch 0 | Step 1880 | Loss: 1.2012\n",
      "  [GPU 0] Epoch 0 | Step 1890 | Loss: 0.6836\n",
      "  [GPU 0] Epoch 0 | Step 1900 | Loss: 0.4675\n",
      "  [GPU 0] Epoch 0 | Step 1910 | Loss: 1.1650\n",
      "  [GPU 0] Epoch 0 | Step 1920 | Loss: 0.9375\n",
      "  [GPU 0] Epoch 0 | Step 1930 | Loss: 0.8071\n",
      "  [GPU 0] Epoch 0 | Step 1940 | Loss: 0.9824\n",
      "  [GPU 0] Epoch 0 | Step 1950 | Loss: 0.3660\n",
      "  [GPU 0] Epoch 0 | Step 1960 | Loss: 0.6421\n",
      "  [GPU 0] Epoch 0 | Step 1970 | Loss: 1.1738\n",
      "  [GPU 0] Epoch 0 | Step 1980 | Loss: 0.8525\n",
      "  [GPU 0] Epoch 0 | Step 1990 | Loss: 1.5117\n",
      "  [GPU 0] Epoch 0 | Step 2000 | Loss: 0.7461\n",
      "  [GPU 0] Epoch 0 | Step 2010 | Loss: 0.3743\n",
      "  [GPU 0] Epoch 0 | Step 2020 | Loss: 0.9712\n",
      "  [GPU 0] Epoch 0 | Step 2030 | Loss: 0.6118\n",
      "  [GPU 0] Epoch 0 | Step 2040 | Loss: 0.8174\n",
      "  [GPU 0] Epoch 0 | Step 2050 | Loss: 0.9380\n",
      "  [GPU 0] Epoch 0 | Step 2060 | Loss: 1.0967\n",
      "  [GPU 0] Epoch 0 | Step 2070 | Loss: 0.6709\n",
      "  [GPU 0] Epoch 0 | Step 2080 | Loss: 1.1826\n",
      "  [GPU 0] Epoch 0 | Step 2090 | Loss: 2.0742\n",
      "  [GPU 0] Epoch 0 | Step 2100 | Loss: 0.8301\n",
      "  [GPU 0] Epoch 0 | Step 2110 | Loss: 1.0674\n",
      "  [GPU 0] Epoch 0 | Step 2120 | Loss: 1.1475\n",
      "  [GPU 0] Epoch 0 | Step 2130 | Loss: 0.8721\n",
      "  [GPU 0] Epoch 0 | Step 2140 | Loss: 0.5220\n",
      "  [GPU 0] Epoch 0 | Step 2150 | Loss: 0.8306\n",
      "  [GPU 0] Epoch 0 | Step 2160 | Loss: 1.2314\n",
      "  [GPU 0] Epoch 0 | Step 2170 | Loss: 0.8057\n",
      "  [GPU 0] Epoch 0 | Step 2180 | Loss: 0.9512\n",
      "  [GPU 0] Epoch 0 | Step 2190 | Loss: 0.8911\n",
      "  [GPU 0] Epoch 0 | Step 2200 | Loss: 1.0332\n",
      "  [GPU 0] Epoch 0 | Step 2210 | Loss: 0.6343\n",
      "  [GPU 0] Epoch 0 | Step 2220 | Loss: 1.3125\n",
      "  [GPU 0] Epoch 0 | Step 2230 | Loss: 1.3154\n",
      "  [GPU 0] Epoch 0 | Step 2240 | Loss: 1.0186\n",
      "  [GPU 0] Epoch 0 | Step 2250 | Loss: 1.2969\n",
      "  [GPU 0] Epoch 0 | Step 2260 | Loss: 0.9126\n",
      "  [GPU 0] Epoch 0 | Step 2270 | Loss: 0.7622\n",
      "  [GPU 0] Epoch 0 | Step 2280 | Loss: 0.5811\n",
      "  [GPU 0] Epoch 0 | Step 2290 | Loss: 0.5620\n",
      "  [GPU 0] Epoch 0 | Step 2300 | Loss: 0.5532\n",
      "  [GPU 0] Epoch 0 | Step 2310 | Loss: 0.5337\n",
      "  [GPU 0] Epoch 0 | Step 2320 | Loss: 0.7788\n",
      "  [GPU 0] Epoch 0 | Step 2330 | Loss: 0.4114\n",
      "  [GPU 0] Epoch 0 | Step 2340 | Loss: 0.6118\n",
      "  [GPU 0] Epoch 0 | Step 2350 | Loss: 0.8774\n",
      "  [GPU 0] Epoch 0 | Step 2360 | Loss: 1.0986\n",
      "\n",
      "======================================================================\n",
      "TRAINING COMPLETE\n",
      "======================================================================\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss ██▇▇▆▆▆▅▅▄▄▃▃▃▃▃▂▃▃▂▃▂▂▃▂▂▃▂▂▂▁▂▂▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: step ▁▁▁▁▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss 0.62061\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: step 2367\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mDeepSpeed-Stage3-ViT-Huge-Food101-2xT4-MBS16-GAS1-Batch-size-16-per-gpu\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/siddpath-university-of-maryland/Distributed%20ViT%20training%20systems-Latest_run/runs/mvkio5ws\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/siddpath-university-of-maryland/Distributed%20ViT%20training%20systems-Latest_run\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251207_000858-mvkio5ws/logs\u001b[0m\n",
      "--- [Rank 0] Done ---\n",
      "--- [Rank 1] Done ---\n",
      "[2025-12-07 01:24:04,061] [INFO] [launch.py:367:main] Process 841 exits successfully.\n",
      "[2025-12-07 01:24:05,061] [INFO] [launch.py:367:main] Process 840 exits successfully.\n"
     ]
    }
   ],
   "source": [
    "!deepspeed --num_gpus=2 train_deepspeed_stage3_vit_huge_bs16.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script for DeepSpeed Full Fine-Tune, running on 2 T4 gpus stage 3 Zero ++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T01:24:09.833821Z",
     "iopub.status.busy": "2025-12-07T01:24:09.833537Z",
     "iopub.status.idle": "2025-12-07T01:24:09.839957Z",
     "shell.execute_reply": "2025-12-07T01:24:09.839258Z",
     "shell.execute_reply.started": "2025-12-07T01:24:09.833793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing deepspeed_config_zeropp.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile deepspeed_config_zeropp.json\n",
    "{\n",
    "    \"fp16\": {\n",
    "        \"enabled\": true,\n",
    "        \"loss_scale\": 0,\n",
    "        \"loss_scale_window\": 1000\n",
    "    },\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": 5e-5,\n",
    "            \"betas\": [0.9, 0.999],\n",
    "            \"eps\": 1e-8,\n",
    "            \"weight_decay\": 3e-7\n",
    "        }\n",
    "    },\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 3,\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"none\"\n",
    "        },\n",
    "        \"offload_param\": {\n",
    "            \"device\": \"none\"\n",
    "        },\n",
    "        \"overlap_comm\": true,\n",
    "        \"contiguous_gradients\": true,\n",
    "        \"sub_group_size\": 1e9,\n",
    "        \"reduce_bucket_size\": 5e8,\n",
    "        \"stage3_prefetch_bucket_size\": 5e7,\n",
    "        \"stage3_param_persistence_threshold\": 1e5,\n",
    "        \"stage3_max_live_parameters\": 1e9,\n",
    "        \"stage3_max_reuse_distance\": 1e9,\n",
    "        \"gather_16bit_weights_on_model_save\": true,\n",
    "        // --- ZeRO++ ---\n",
    "        \"zero_quantized_weights\": false,\n",
    "        \"zero_quantized_gradients\": true,\n",
    "        \"zero_hpz_partition_size\": 1\n",
    "    },\n",
    "    \"train_batch_size\": 32,\n",
    "    \"train_micro_batch_size_per_gpu\": 16,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"gradient_clipping\": 1.0,\n",
    "    \"steps_per_print\": 1,\n",
    "    \"wall_clock_breakdown\": false,\n",
    "    \"flops_profiler\": {\n",
    "        \"enabled\": false\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T01:24:09.841131Z",
     "iopub.status.busy": "2025-12-07T01:24:09.840914Z",
     "iopub.status.idle": "2025-12-07T01:24:09.857345Z",
     "shell.execute_reply": "2025-12-07T01:24:09.856632Z",
     "shell.execute_reply.started": "2025-12-07T01:24:09.841104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train_deepspeed_zeropp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_deepspeed_zeropp.py\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor\n",
    "import deepspeed\n",
    "import warnings\n",
    "import wandb\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import torch.profiler\n",
    "import json\n",
    "import glob\n",
    "\n",
    "# --- TRACE DIRECTORY SETUP ---\n",
    "TRACE_DIR = \"./pytorch_traces/deepspeed_zeropp_trace\"\n",
    "MERGED_TRACE_FILE = \"./pytorch_traces/deepspeed_zeropp_trace/merged_zeropp_trace.json\"\n",
    "\n",
    "# Cleanup old runs to avoid confusion (only rank 0)\n",
    "if int(os.environ.get('RANK', 0)) == 0:\n",
    "    if os.path.exists(TRACE_DIR):\n",
    "        try: shutil.rmtree(TRACE_DIR)\n",
    "        except: pass\n",
    "    os.makedirs(TRACE_DIR, exist_ok=True)\n",
    "    if os.path.exists(MERGED_TRACE_FILE):\n",
    "        os.remove(MERGED_TRACE_FILE)\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(\"--- Initializing DEEPSPEED ZeRO++ (Quantized Communication) ---\")\n",
    "\n",
    "# --- 1. Setup ---\n",
    "local_rank = int(os.environ.get('LOCAL_RANK', 0))\n",
    "rank = int(os.environ.get('RANK', 0))\n",
    "world_size = int(os.environ.get('WORLD_SIZE', 1))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(local_rank)\n",
    "    print(f\"[Rank {rank}] Initializing process on GPU {local_rank}...\")\n",
    "else:\n",
    "    print(f\"[Rank {rank}] WARNING: No CUDA available, running on CPU\")\n",
    "\n",
    "# --- W&B Setup ---\n",
    "if rank == 0:\n",
    "    wandb.init(\n",
    "        project=\"Distributed ViT training systems-Latest_run\", \n",
    "        name=\"DeepSpeed-ZeRO-PlusPlus-ViT-Huge-Food101-2xT4-MBS16-GAS1-Batch-size-16-per-gpu\",\n",
    "        config={\n",
    "            \"optimization\": \"ZeRO++\",\n",
    "            \"num_gpus\": world_size,\n",
    "            \"profiling\": \"Rank 0 & 1 (Merged)\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "# --- 2. Model Setup ---\n",
    "if rank == 0: print(\"Loading pre-trained ViT-Huge model...\")\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    'google/vit-huge-patch14-224-in21k', \n",
    "    num_labels=101, \n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "# --- 3. DeepSpeed Init ---\n",
    "if rank == 0: print(\"Initializing DeepSpeed with ZeRO++ Config...\")\n",
    "model_engine, optimizer, _, _ = deepspeed.initialize(\n",
    "    model=model, \n",
    "    model_parameters=model.parameters(), \n",
    "    config_params='deepspeed_config_zeropp.json'\n",
    ")\n",
    "\n",
    "# --- 4. Data Prep ---\n",
    "if rank == 0: print(\"Setting up data...\")\n",
    "processor = ViTImageProcessor.from_pretrained('google/vit-huge-patch14-224-in21k')\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(224, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=processor.image_mean, std=processor.image_std)\n",
    "])\n",
    "\n",
    "if rank == 0:\n",
    "    trainset = torchvision.datasets.Food101(root='./data', split=\"train\", download=True, transform=train_transform)\n",
    "\n",
    "if world_size > 1: dist.barrier()\n",
    "    \n",
    "if rank != 0:\n",
    "    trainset = torchvision.datasets.Food101(root='./data', split=\"train\", download=False, transform=train_transform)\n",
    "\n",
    "MICRO_BATCH_SIZE = 16\n",
    "train_sampler = DistributedSampler(trainset, num_replicas=world_size, rank=rank, shuffle=True)\n",
    "train_loader = DataLoader(trainset, batch_size=MICRO_BATCH_SIZE, sampler=train_sampler, num_workers=2, pin_memory=True)\n",
    "\n",
    "# --- ROBUST MERGE FUNCTION ---\n",
    "def merge_traces_logic():\n",
    "    \"\"\"Merge all rank traces into a single file for Perfetto (Handles String PIDs)\"\"\"\n",
    "    print(f\"\\n[Rank 0] Merging traces from all ranks...\")\n",
    "    trace_files = sorted(glob.glob(os.path.join(TRACE_DIR, \"*.pt.trace.json\")))\n",
    "    \n",
    "    if not trace_files:\n",
    "        print(\"  WARNING: No trace files found yet!\")\n",
    "        return\n",
    "    \n",
    "    merged_events = []\n",
    "    metadata = {}\n",
    "    \n",
    "    for idx, trace_file in enumerate(trace_files):\n",
    "        try:\n",
    "            with open(trace_file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            if isinstance(data, dict):\n",
    "                events = data.get(\"traceEvents\", [])\n",
    "                if idx == 0: metadata = {k: v for k, v in data.items() if k != \"traceEvents\"}\n",
    "            else:\n",
    "                events = data\n",
    "            \n",
    "            # --- ROBUST PID/TID OFFSETTING ---\n",
    "            for event in events:\n",
    "                if \"pid\" in event:\n",
    "                    try: event[\"pid\"] = int(event[\"pid\"]) + (idx * 100000)\n",
    "                    except ValueError: event[\"pid\"] = f\"{event['pid']}_{idx}\"\n",
    "\n",
    "                if \"tid\" in event:\n",
    "                    try: event[\"tid\"] = int(event[\"tid\"]) + (idx * 100000)\n",
    "                    except ValueError: event[\"tid\"] = f\"{event['tid']}_{idx}\"\n",
    "                \n",
    "                if \"name\" in event and isinstance(event[\"name\"], str):\n",
    "                    if not event[\"name\"].startswith(\"[GPU\"):\n",
    "                        event[\"name\"] = f\"[GPU {idx}] {event['name']}\"\n",
    "            \n",
    "            merged_events.extend(events)\n",
    "            print(f\"    Added {len(events)} events from GPU {idx}\")\n",
    "        except Exception as e:\n",
    "            print(f\"    Warning: Could not read {trace_file}: {e}\")\n",
    "\n",
    "    merged_trace = metadata.copy()\n",
    "    merged_trace[\"traceEvents\"] = merged_events\n",
    "    \n",
    "    with open(MERGED_TRACE_FILE, 'w') as f:\n",
    "        json.dump(merged_trace, f)\n",
    "    \n",
    "    print(f\"\\n MERGE COMPLETE!\")\n",
    "    print(f\" Saved to: {MERGED_TRACE_FILE}\")\n",
    "    print(f\" Upload this file to https://ui.perfetto.dev/\\n\")\n",
    "\n",
    "# --- Training Configuration ---\n",
    "device = model_engine.device\n",
    "num_epochs = 1\n",
    "start_time = time.time()\n",
    "PROFILING_STEPS = 0\n",
    "\n",
    "if rank == 0: \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"--- STARTING TRAINING WITH PROFILING ---\")\n",
    "    print(f\"  - Profiling: ALL ranks (first {PROFILING_STEPS} steps)\")\n",
    "    print(f\"  - Training: Continues FULLY after profiling\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "try:\n",
    "    # --- PROFILER INITIALIZATION (ALL RANKS) ---\n",
    "    prof = torch.profiler.profile(\n",
    "        activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "        schedule=torch.profiler.schedule(wait=1, warmup=2, active=5, repeat=1),\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler(TRACE_DIR),\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=True,\n",
    "        with_flops=True\n",
    "    )\n",
    "    # prof.start()\n",
    "    \n",
    "    model_engine.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_sampler.set_epoch(epoch)\n",
    "        epoch_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for i, batch in enumerate(train_loader):\n",
    "            \n",
    "            # --- Profiling Window ---\n",
    "            is_profiling = (i < PROFILING_STEPS)\n",
    "            prof_context = None\n",
    "            \n",
    "            if is_profiling:\n",
    "                prof_context = torch.profiler.record_function(f\"## [GPU {rank}] Step {i} ##\")\n",
    "                prof_context.__enter__()\n",
    "            \n",
    "            inputs, labels = batch\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward\n",
    "            if is_profiling:\n",
    "                with torch.profiler.record_function(f\"## [GPU {rank}] FWD ##\"):\n",
    "                    outputs = model_engine(inputs, labels=labels)\n",
    "                    loss = outputs.loss\n",
    "            else:\n",
    "                outputs = model_engine(inputs, labels=labels)\n",
    "                loss = outputs.loss\n",
    "\n",
    "            # Backward\n",
    "            if is_profiling:\n",
    "                with torch.profiler.record_function(f\"## [GPU {rank}] BWD ##\"):\n",
    "                    model_engine.backward(loss)\n",
    "            else:\n",
    "                model_engine.backward(loss)\n",
    "\n",
    "            # Step\n",
    "            if is_profiling:\n",
    "                with torch.profiler.record_function(f\"## [GPU {rank}] OPT ##\"):\n",
    "                    model_engine.step()\n",
    "            else:\n",
    "                model_engine.step()\n",
    "\n",
    "            # Metrics\n",
    "            loss_val = loss.item()\n",
    "            epoch_loss += loss_val\n",
    "            num_batches += 1\n",
    "\n",
    "            if rank == 0:\n",
    "                wandb.log({\"loss\": loss_val, \"step\": i})\n",
    "                if i % 10 == 0:\n",
    "                    print(f\"  [GPU {rank}] Epoch {epoch} | Step {i} | Loss: {loss_val:.4f}\")\n",
    "\n",
    "            # --- Profiler Stepping ---\n",
    "            if is_profiling:\n",
    "                prof.step()\n",
    "                if prof_context: prof_context.__exit__(None, None, None)\n",
    "            \n",
    "            # --- STOP & MERGE (But continue training) ---\n",
    "            if i == PROFILING_STEPS:\n",
    "                prof.stop() # Save trace files to disk\n",
    "                \n",
    "                # 1. Sync all ranks to ensure writing is done\n",
    "                if world_size > 1: dist.barrier()\n",
    "                \n",
    "                # 2. Rank 0 performs the merge immediately\n",
    "                if rank == 0:\n",
    "                    print(f\"\\n>>> Profiling complete. Merging traces while training continues... <<<\")\n",
    "                    merge_traces_logic()\n",
    "                    print(\">>> Resuming full training loop... <<<\\n\")\n",
    "\n",
    "    # End of Epoch\n",
    "    if rank == 0:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"TRAINING COMPLETE\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        wandb.finish()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[Rank {rank}] ERROR: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "finally:\n",
    "    if world_size > 1:\n",
    "        dist.barrier()\n",
    "        dist.destroy_process_group()\n",
    "    print(f\"--- [Rank {rank}] Done ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T01:24:09.858819Z",
     "iopub.status.busy": "2025-12-07T01:24:09.858239Z",
     "iopub.status.idle": "2025-12-07T02:40:05.228836Z",
     "shell.execute_reply": "2025-12-07T02:40:05.227827Z",
     "shell.execute_reply.started": "2025-12-07T01:24:09.858793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-07 01:24:17.583336: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765070657.606290    1036 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1765070657.613769    1036 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "[2025-12-07 01:24:22,734] [WARNING] [runner.py:232:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
      "[2025-12-07 01:24:22,734] [INFO] [runner.py:630:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMV19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None --log_level=info train_deepspeed_zeropp.py\n",
      "2025-12-07 01:24:30.146312: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765070670.170110    1088 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1765070670.177110    1088 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "[2025-12-07 01:24:35,272] [INFO] [launch.py:155:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.22.3-1+cuda12.5\n",
      "[2025-12-07 01:24:35,272] [INFO] [launch.py:155:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.22.3-1\n",
      "[2025-12-07 01:24:35,273] [INFO] [launch.py:155:main] 0 NCCL_VERSION=2.22.3-1\n",
      "[2025-12-07 01:24:35,273] [INFO] [launch.py:155:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
      "[2025-12-07 01:24:35,273] [INFO] [launch.py:155:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.22.3-1+cuda12.5\n",
      "[2025-12-07 01:24:35,273] [INFO] [launch.py:155:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
      "[2025-12-07 01:24:35,273] [INFO] [launch.py:155:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.22.3-1\n",
      "[2025-12-07 01:24:35,273] [INFO] [launch.py:162:main] WORLD INFO DICT: {'localhost': [0, 1]}\n",
      "[2025-12-07 01:24:35,273] [INFO] [launch.py:168:main] nnodes=1, num_local_procs=2, node_rank=0\n",
      "[2025-12-07 01:24:35,273] [INFO] [launch.py:179:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1]})\n",
      "[2025-12-07 01:24:35,273] [INFO] [launch.py:180:main] dist_world_size=2\n",
      "[2025-12-07 01:24:35,273] [INFO] [launch.py:184:main] Setting CUDA_VISIBLE_DEVICES=0,1\n",
      "[2025-12-07 01:24:35,274] [INFO] [launch.py:272:main] process 1140 spawned with command: ['/usr/bin/python3', '-u', 'train_deepspeed_zeropp.py', '--local_rank=0']\n",
      "[2025-12-07 01:24:35,274] [INFO] [launch.py:272:main] process 1141 spawned with command: ['/usr/bin/python3', '-u', 'train_deepspeed_zeropp.py', '--local_rank=1']\n",
      "2025-12-07 01:24:40.476458: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765070680.499011    1141 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1765070680.505525    1141 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-07 01:24:40.535345: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765070680.560399    1140 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1765070680.567203    1140 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "--- Initializing DEEPSPEED ZeRO++ (Quantized Communication) ---\n",
      "--- Initializing DEEPSPEED ZeRO++ (Quantized Communication) ---\n",
      "[Rank 0] Initializing process on GPU 0...\n",
      "[Rank 1] Initializing process on GPU 1...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msiddpath\u001b[0m (\u001b[33msiddpath-university-of-maryland\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20251207_012450-sjtn2njr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mDeepSpeed-ZeRO-PlusPlus-ViT-Huge-Food101-2xT4-MBS16-GAS1-Batch-size-16-per-gpu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/siddpath-university-of-maryland/Distributed%20ViT%20training%20systems-Latest_run\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/siddpath-university-of-maryland/Distributed%20ViT%20training%20systems-Latest_run/runs/sjtn2njr\u001b[0m\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-huge-patch14-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Loading pre-trained ViT-Huge model...\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-huge-patch14-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Initializing DeepSpeed with ZeRO++ Config...\n",
      "Parameter Offload - Persistent parameters statistics: param_count = 325, numel = 537701\n",
      "Setting up data...\n",
      "\n",
      "======================================================================\n",
      "--- STARTING TRAINING WITH PROFILING ---\n",
      "  - Profiling: ALL ranks (first 0 steps)\n",
      "  - Training: Continues FULLY after profiling\n",
      "======================================================================\n",
      "\n",
      "  [GPU 0] Epoch 0 | Step 0 | Loss: 4.6094\n",
      "\n",
      ">>> Profiling complete. Merging traces while training continues... <<<\n",
      "\n",
      "[Rank 0] Merging traces from all ranks...\n",
      "  WARNING: No trace files found yet!\n",
      ">>> Resuming full training loop... <<<\n",
      "\n",
      "  [GPU 0] Epoch 0 | Step 10 | Loss: 4.5781\n",
      "  [GPU 0] Epoch 0 | Step 20 | Loss: 4.6016\n",
      "  [GPU 0] Epoch 0 | Step 30 | Loss: 4.5391\n",
      "  [GPU 0] Epoch 0 | Step 40 | Loss: 4.5234\n",
      "  [GPU 0] Epoch 0 | Step 50 | Loss: 4.4805\n",
      "  [GPU 0] Epoch 0 | Step 60 | Loss: 4.4727\n",
      "  [GPU 0] Epoch 0 | Step 70 | Loss: 4.4805\n",
      "  [GPU 0] Epoch 0 | Step 80 | Loss: 4.4297\n",
      "  [GPU 0] Epoch 0 | Step 90 | Loss: 4.2852\n",
      "  [GPU 0] Epoch 0 | Step 100 | Loss: 4.2617\n",
      "  [GPU 0] Epoch 0 | Step 110 | Loss: 4.3828\n",
      "  [GPU 0] Epoch 0 | Step 120 | Loss: 4.2266\n",
      "  [GPU 0] Epoch 0 | Step 130 | Loss: 4.1953\n",
      "  [GPU 0] Epoch 0 | Step 140 | Loss: 4.2031\n",
      "  [GPU 0] Epoch 0 | Step 150 | Loss: 4.0156\n",
      "  [GPU 0] Epoch 0 | Step 160 | Loss: 4.1641\n",
      "  [GPU 0] Epoch 0 | Step 170 | Loss: 3.8965\n",
      "  [GPU 0] Epoch 0 | Step 180 | Loss: 4.0352\n",
      "  [GPU 0] Epoch 0 | Step 190 | Loss: 3.8887\n",
      "  [GPU 0] Epoch 0 | Step 200 | Loss: 3.8477\n",
      "  [GPU 0] Epoch 0 | Step 210 | Loss: 3.8516\n",
      "  [GPU 0] Epoch 0 | Step 220 | Loss: 3.7578\n",
      "  [GPU 0] Epoch 0 | Step 230 | Loss: 3.6719\n",
      "  [GPU 0] Epoch 0 | Step 240 | Loss: 3.5801\n",
      "  [GPU 0] Epoch 0 | Step 250 | Loss: 3.4082\n",
      "  [GPU 0] Epoch 0 | Step 260 | Loss: 3.6504\n",
      "  [GPU 0] Epoch 0 | Step 270 | Loss: 3.6016\n",
      "  [GPU 0] Epoch 0 | Step 280 | Loss: 3.6836\n",
      "  [GPU 0] Epoch 0 | Step 290 | Loss: 3.4551\n",
      "  [GPU 0] Epoch 0 | Step 300 | Loss: 3.2441\n",
      "  [GPU 0] Epoch 0 | Step 310 | Loss: 3.2441\n",
      "  [GPU 0] Epoch 0 | Step 320 | Loss: 3.3574\n",
      "  [GPU 0] Epoch 0 | Step 330 | Loss: 3.1836\n",
      "  [GPU 0] Epoch 0 | Step 340 | Loss: 3.3574\n",
      "  [GPU 0] Epoch 0 | Step 350 | Loss: 3.2500\n",
      "  [GPU 0] Epoch 0 | Step 360 | Loss: 3.2988\n",
      "  [GPU 0] Epoch 0 | Step 370 | Loss: 2.9844\n",
      "  [GPU 0] Epoch 0 | Step 380 | Loss: 3.2715\n",
      "  [GPU 0] Epoch 0 | Step 390 | Loss: 2.8887\n",
      "  [GPU 0] Epoch 0 | Step 400 | Loss: 3.1895\n",
      "  [GPU 0] Epoch 0 | Step 410 | Loss: 3.2227\n",
      "  [GPU 0] Epoch 0 | Step 420 | Loss: 3.0137\n",
      "  [GPU 0] Epoch 0 | Step 430 | Loss: 2.9395\n",
      "  [GPU 0] Epoch 0 | Step 440 | Loss: 3.1523\n",
      "  [GPU 0] Epoch 0 | Step 450 | Loss: 2.8379\n",
      "  [GPU 0] Epoch 0 | Step 460 | Loss: 3.2891\n",
      "  [GPU 0] Epoch 0 | Step 470 | Loss: 2.9316\n",
      "  [GPU 0] Epoch 0 | Step 480 | Loss: 2.7344\n",
      "  [GPU 0] Epoch 0 | Step 490 | Loss: 3.0859\n",
      "  [GPU 0] Epoch 0 | Step 500 | Loss: 2.5293\n",
      "  [GPU 0] Epoch 0 | Step 510 | Loss: 2.7637\n",
      "  [GPU 0] Epoch 0 | Step 520 | Loss: 3.0664\n",
      "  [GPU 0] Epoch 0 | Step 530 | Loss: 2.6387\n",
      "  [GPU 0] Epoch 0 | Step 540 | Loss: 3.0137\n",
      "  [GPU 0] Epoch 0 | Step 550 | Loss: 2.7988\n",
      "  [GPU 0] Epoch 0 | Step 560 | Loss: 2.5195\n",
      "  [GPU 0] Epoch 0 | Step 570 | Loss: 2.9395\n",
      "  [GPU 0] Epoch 0 | Step 580 | Loss: 3.3691\n",
      "  [GPU 0] Epoch 0 | Step 590 | Loss: 2.6074\n",
      "  [GPU 0] Epoch 0 | Step 600 | Loss: 2.5645\n",
      "  [GPU 0] Epoch 0 | Step 610 | Loss: 2.5664\n",
      "  [GPU 0] Epoch 0 | Step 620 | Loss: 2.5293\n",
      "  [GPU 0] Epoch 0 | Step 630 | Loss: 3.0918\n",
      "  [GPU 0] Epoch 0 | Step 640 | Loss: 2.5703\n",
      "  [GPU 0] Epoch 0 | Step 650 | Loss: 2.4199\n",
      "  [GPU 0] Epoch 0 | Step 660 | Loss: 2.6172\n",
      "  [GPU 0] Epoch 0 | Step 670 | Loss: 1.9600\n",
      "  [GPU 0] Epoch 0 | Step 680 | Loss: 2.4336\n",
      "  [GPU 0] Epoch 0 | Step 690 | Loss: 1.8584\n",
      "  [GPU 0] Epoch 0 | Step 700 | Loss: 2.5879\n",
      "  [GPU 0] Epoch 0 | Step 710 | Loss: 2.2461\n",
      "  [GPU 0] Epoch 0 | Step 720 | Loss: 2.0645\n",
      "  [GPU 0] Epoch 0 | Step 730 | Loss: 2.4023\n",
      "  [GPU 0] Epoch 0 | Step 740 | Loss: 2.0840\n",
      "  [GPU 0] Epoch 0 | Step 750 | Loss: 2.2383\n",
      "  [GPU 0] Epoch 0 | Step 760 | Loss: 2.0918\n",
      "  [GPU 0] Epoch 0 | Step 770 | Loss: 2.1094\n",
      "  [GPU 0] Epoch 0 | Step 780 | Loss: 1.7793\n",
      "  [GPU 0] Epoch 0 | Step 790 | Loss: 2.4766\n",
      "  [GPU 0] Epoch 0 | Step 800 | Loss: 1.8633\n",
      "  [GPU 0] Epoch 0 | Step 810 | Loss: 2.1562\n",
      "  [GPU 0] Epoch 0 | Step 820 | Loss: 1.8740\n",
      "  [GPU 0] Epoch 0 | Step 830 | Loss: 2.3984\n",
      "  [GPU 0] Epoch 0 | Step 840 | Loss: 1.7949\n",
      "  [GPU 0] Epoch 0 | Step 850 | Loss: 2.2207\n",
      "  [GPU 0] Epoch 0 | Step 860 | Loss: 1.7803\n",
      "  [GPU 0] Epoch 0 | Step 870 | Loss: 1.6211\n",
      "  [GPU 0] Epoch 0 | Step 880 | Loss: 1.9824\n",
      "  [GPU 0] Epoch 0 | Step 890 | Loss: 2.0625\n",
      "  [GPU 0] Epoch 0 | Step 900 | Loss: 2.0371\n",
      "  [GPU 0] Epoch 0 | Step 910 | Loss: 2.2578\n",
      "  [GPU 0] Epoch 0 | Step 920 | Loss: 1.7256\n",
      "  [GPU 0] Epoch 0 | Step 930 | Loss: 1.9873\n",
      "  [GPU 0] Epoch 0 | Step 940 | Loss: 1.5898\n",
      "  [GPU 0] Epoch 0 | Step 950 | Loss: 1.7686\n",
      "  [GPU 0] Epoch 0 | Step 960 | Loss: 1.6592\n",
      "  [GPU 0] Epoch 0 | Step 970 | Loss: 1.5850\n",
      "  [GPU 0] Epoch 0 | Step 980 | Loss: 1.6396\n",
      "  [GPU 0] Epoch 0 | Step 990 | Loss: 2.1797\n",
      "  [GPU 0] Epoch 0 | Step 1000 | Loss: 1.2559\n",
      "  [GPU 0] Epoch 0 | Step 1010 | Loss: 2.3574\n",
      "  [GPU 0] Epoch 0 | Step 1020 | Loss: 1.8887\n",
      "  [GPU 0] Epoch 0 | Step 1030 | Loss: 1.2334\n",
      "  [GPU 0] Epoch 0 | Step 1040 | Loss: 1.7646\n",
      "  [GPU 0] Epoch 0 | Step 1050 | Loss: 1.6953\n",
      "  [GPU 0] Epoch 0 | Step 1060 | Loss: 1.2188\n",
      "  [GPU 0] Epoch 0 | Step 1070 | Loss: 1.5322\n",
      "  [GPU 0] Epoch 0 | Step 1080 | Loss: 1.5879\n",
      "  [GPU 0] Epoch 0 | Step 1090 | Loss: 1.7227\n",
      "  [GPU 0] Epoch 0 | Step 1100 | Loss: 1.4346\n",
      "  [GPU 0] Epoch 0 | Step 1110 | Loss: 1.5156\n",
      "  [GPU 0] Epoch 0 | Step 1120 | Loss: 1.9258\n",
      "  [GPU 0] Epoch 0 | Step 1130 | Loss: 1.7842\n",
      "  [GPU 0] Epoch 0 | Step 1140 | Loss: 1.2949\n",
      "  [GPU 0] Epoch 0 | Step 1150 | Loss: 1.7949\n",
      "  [GPU 0] Epoch 0 | Step 1160 | Loss: 1.3818\n",
      "  [GPU 0] Epoch 0 | Step 1170 | Loss: 1.3516\n",
      "  [GPU 0] Epoch 0 | Step 1180 | Loss: 1.7021\n",
      "  [GPU 0] Epoch 0 | Step 1190 | Loss: 1.3857\n",
      "  [GPU 0] Epoch 0 | Step 1200 | Loss: 1.5176\n",
      "  [GPU 0] Epoch 0 | Step 1210 | Loss: 2.3359\n",
      "  [GPU 0] Epoch 0 | Step 1220 | Loss: 1.6973\n",
      "  [GPU 0] Epoch 0 | Step 1230 | Loss: 1.5576\n",
      "  [GPU 0] Epoch 0 | Step 1240 | Loss: 1.3271\n",
      "  [GPU 0] Epoch 0 | Step 1250 | Loss: 1.9785\n",
      "  [GPU 0] Epoch 0 | Step 1260 | Loss: 1.4756\n",
      "  [GPU 0] Epoch 0 | Step 1270 | Loss: 1.7451\n",
      "  [GPU 0] Epoch 0 | Step 1280 | Loss: 1.4395\n",
      "  [GPU 0] Epoch 0 | Step 1290 | Loss: 1.3506\n",
      "  [GPU 0] Epoch 0 | Step 1300 | Loss: 1.4404\n",
      "  [GPU 0] Epoch 0 | Step 1310 | Loss: 1.1416\n",
      "  [GPU 0] Epoch 0 | Step 1320 | Loss: 1.9805\n",
      "  [GPU 0] Epoch 0 | Step 1330 | Loss: 1.9443\n",
      "  [GPU 0] Epoch 0 | Step 1340 | Loss: 1.4375\n",
      "  [GPU 0] Epoch 0 | Step 1350 | Loss: 1.6514\n",
      "  [GPU 0] Epoch 0 | Step 1360 | Loss: 1.1436\n",
      "  [GPU 0] Epoch 0 | Step 1370 | Loss: 1.1104\n",
      "  [GPU 0] Epoch 0 | Step 1380 | Loss: 1.0469\n",
      "  [GPU 0] Epoch 0 | Step 1390 | Loss: 0.7383\n",
      "  [GPU 0] Epoch 0 | Step 1400 | Loss: 1.7520\n",
      "  [GPU 0] Epoch 0 | Step 1410 | Loss: 1.1641\n",
      "  [GPU 0] Epoch 0 | Step 1420 | Loss: 1.4355\n",
      "  [GPU 0] Epoch 0 | Step 1430 | Loss: 0.6958\n",
      "  [GPU 0] Epoch 0 | Step 1440 | Loss: 1.0410\n",
      "  [GPU 0] Epoch 0 | Step 1450 | Loss: 1.4404\n",
      "  [GPU 0] Epoch 0 | Step 1460 | Loss: 1.8662\n",
      "  [GPU 0] Epoch 0 | Step 1470 | Loss: 1.0596\n",
      "  [GPU 0] Epoch 0 | Step 1480 | Loss: 1.1201\n",
      "  [GPU 0] Epoch 0 | Step 1490 | Loss: 1.3516\n",
      "  [GPU 0] Epoch 0 | Step 1500 | Loss: 1.2637\n",
      "  [GPU 0] Epoch 0 | Step 1510 | Loss: 1.3184\n",
      "  [GPU 0] Epoch 0 | Step 1520 | Loss: 1.2959\n",
      "  [GPU 0] Epoch 0 | Step 1530 | Loss: 1.5244\n",
      "  [GPU 0] Epoch 0 | Step 1540 | Loss: 1.3320\n",
      "  [GPU 0] Epoch 0 | Step 1550 | Loss: 1.3467\n",
      "  [GPU 0] Epoch 0 | Step 1560 | Loss: 1.4502\n",
      "  [GPU 0] Epoch 0 | Step 1570 | Loss: 1.1025\n",
      "  [GPU 0] Epoch 0 | Step 1580 | Loss: 1.3291\n",
      "  [GPU 0] Epoch 0 | Step 1590 | Loss: 1.0986\n",
      "  [GPU 0] Epoch 0 | Step 1600 | Loss: 1.1729\n",
      "  [GPU 0] Epoch 0 | Step 1610 | Loss: 1.1895\n",
      "  [GPU 0] Epoch 0 | Step 1620 | Loss: 1.4248\n",
      "  [GPU 0] Epoch 0 | Step 1630 | Loss: 1.7412\n",
      "  [GPU 0] Epoch 0 | Step 1640 | Loss: 1.2920\n",
      "  [GPU 0] Epoch 0 | Step 1650 | Loss: 0.9546\n",
      "  [GPU 0] Epoch 0 | Step 1660 | Loss: 0.9814\n",
      "  [GPU 0] Epoch 0 | Step 1670 | Loss: 0.9746\n",
      "  [GPU 0] Epoch 0 | Step 1680 | Loss: 0.6587\n",
      "  [GPU 0] Epoch 0 | Step 1690 | Loss: 1.0801\n",
      "  [GPU 0] Epoch 0 | Step 1700 | Loss: 1.2910\n",
      "  [GPU 0] Epoch 0 | Step 1710 | Loss: 0.9907\n",
      "  [GPU 0] Epoch 0 | Step 1720 | Loss: 0.5488\n",
      "  [GPU 0] Epoch 0 | Step 1730 | Loss: 0.8418\n",
      "  [GPU 0] Epoch 0 | Step 1740 | Loss: 1.5449\n",
      "  [GPU 0] Epoch 0 | Step 1750 | Loss: 1.3418\n",
      "  [GPU 0] Epoch 0 | Step 1760 | Loss: 1.0557\n",
      "  [GPU 0] Epoch 0 | Step 1770 | Loss: 1.5742\n",
      "  [GPU 0] Epoch 0 | Step 1780 | Loss: 1.1934\n",
      "  [GPU 0] Epoch 0 | Step 1790 | Loss: 1.2578\n",
      "  [GPU 0] Epoch 0 | Step 1800 | Loss: 1.2617\n",
      "  [GPU 0] Epoch 0 | Step 1810 | Loss: 1.2041\n",
      "  [GPU 0] Epoch 0 | Step 1820 | Loss: 2.0293\n",
      "  [GPU 0] Epoch 0 | Step 1830 | Loss: 0.7383\n",
      "  [GPU 0] Epoch 0 | Step 1840 | Loss: 1.9951\n",
      "  [GPU 0] Epoch 0 | Step 1850 | Loss: 1.1543\n",
      "  [GPU 0] Epoch 0 | Step 1860 | Loss: 0.5571\n",
      "  [GPU 0] Epoch 0 | Step 1870 | Loss: 1.1035\n",
      "  [GPU 0] Epoch 0 | Step 1880 | Loss: 0.9424\n",
      "  [GPU 0] Epoch 0 | Step 1890 | Loss: 0.7510\n",
      "  [GPU 0] Epoch 0 | Step 1900 | Loss: 0.5200\n",
      "  [GPU 0] Epoch 0 | Step 1910 | Loss: 1.1260\n",
      "  [GPU 0] Epoch 0 | Step 1920 | Loss: 1.1240\n",
      "  [GPU 0] Epoch 0 | Step 1930 | Loss: 0.7422\n",
      "  [GPU 0] Epoch 0 | Step 1940 | Loss: 0.5083\n",
      "  [GPU 0] Epoch 0 | Step 1950 | Loss: 0.4817\n",
      "  [GPU 0] Epoch 0 | Step 1960 | Loss: 0.4011\n",
      "  [GPU 0] Epoch 0 | Step 1970 | Loss: 0.9644\n",
      "  [GPU 0] Epoch 0 | Step 1980 | Loss: 0.8223\n",
      "  [GPU 0] Epoch 0 | Step 1990 | Loss: 1.4893\n",
      "  [GPU 0] Epoch 0 | Step 2000 | Loss: 0.6499\n",
      "  [GPU 0] Epoch 0 | Step 2010 | Loss: 0.4131\n",
      "  [GPU 0] Epoch 0 | Step 2020 | Loss: 0.8516\n",
      "  [GPU 0] Epoch 0 | Step 2030 | Loss: 0.4724\n",
      "  [GPU 0] Epoch 0 | Step 2040 | Loss: 0.8784\n",
      "  [GPU 0] Epoch 0 | Step 2050 | Loss: 1.0293\n",
      "  [GPU 0] Epoch 0 | Step 2060 | Loss: 0.8311\n",
      "  [GPU 0] Epoch 0 | Step 2070 | Loss: 1.1445\n",
      "  [GPU 0] Epoch 0 | Step 2080 | Loss: 1.1738\n",
      "  [GPU 0] Epoch 0 | Step 2090 | Loss: 1.8906\n",
      "  [GPU 0] Epoch 0 | Step 2100 | Loss: 0.7759\n",
      "  [GPU 0] Epoch 0 | Step 2110 | Loss: 0.8271\n",
      "  [GPU 0] Epoch 0 | Step 2120 | Loss: 1.1504\n",
      "  [GPU 0] Epoch 0 | Step 2130 | Loss: 0.7388\n",
      "  [GPU 0] Epoch 0 | Step 2140 | Loss: 0.6899\n",
      "  [GPU 0] Epoch 0 | Step 2150 | Loss: 1.1162\n",
      "  [GPU 0] Epoch 0 | Step 2160 | Loss: 1.1865\n",
      "  [GPU 0] Epoch 0 | Step 2170 | Loss: 0.7285\n",
      "  [GPU 0] Epoch 0 | Step 2180 | Loss: 0.6387\n",
      "  [GPU 0] Epoch 0 | Step 2190 | Loss: 0.9678\n",
      "  [GPU 0] Epoch 0 | Step 2200 | Loss: 0.9160\n",
      "  [GPU 0] Epoch 0 | Step 2210 | Loss: 0.8672\n",
      "  [GPU 0] Epoch 0 | Step 2220 | Loss: 0.8838\n",
      "  [GPU 0] Epoch 0 | Step 2230 | Loss: 1.5176\n",
      "  [GPU 0] Epoch 0 | Step 2240 | Loss: 1.1621\n",
      "  [GPU 0] Epoch 0 | Step 2250 | Loss: 1.0918\n",
      "  [GPU 0] Epoch 0 | Step 2260 | Loss: 0.9360\n",
      "  [GPU 0] Epoch 0 | Step 2270 | Loss: 0.9727\n",
      "  [GPU 0] Epoch 0 | Step 2280 | Loss: 0.6133\n",
      "  [GPU 0] Epoch 0 | Step 2290 | Loss: 0.5146\n",
      "  [GPU 0] Epoch 0 | Step 2300 | Loss: 0.5591\n",
      "  [GPU 0] Epoch 0 | Step 2310 | Loss: 0.5815\n",
      "  [GPU 0] Epoch 0 | Step 2320 | Loss: 0.7598\n",
      "  [GPU 0] Epoch 0 | Step 2330 | Loss: 0.4414\n",
      "  [GPU 0] Epoch 0 | Step 2340 | Loss: 0.6016\n",
      "  [GPU 0] Epoch 0 | Step 2350 | Loss: 0.9067\n",
      "  [GPU 0] Epoch 0 | Step 2360 | Loss: 1.0527\n",
      "\n",
      "======================================================================\n",
      "TRAINING COMPLETE\n",
      "======================================================================\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss ███▇▆▆▆▅▅▅▅▅▄▅▄▄▄▄▃▃▄▄▃▃▂▂▃▃▃▃▃▂▁▂▂▁▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: step ▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss 0.64404\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: step 2367\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mDeepSpeed-ZeRO-PlusPlus-ViT-Huge-Food101-2xT4-MBS16-GAS1-Batch-size-16-per-gpu\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/siddpath-university-of-maryland/Distributed%20ViT%20training%20systems-Latest_run/runs/sjtn2njr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/siddpath-university-of-maryland/Distributed%20ViT%20training%20systems-Latest_run\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251207_012450-sjtn2njr/logs\u001b[0m\n",
      "--- [Rank 1] Done ---\n",
      "--- [Rank 0] Done ---\n",
      "[2025-12-07 02:39:59,430] [INFO] [launch.py:367:main] Process 1141 exits successfully.\n",
      "[2025-12-07 02:40:00,432] [INFO] [launch.py:367:main] Process 1140 exits successfully.\n"
     ]
    }
   ],
   "source": [
    "!deepspeed --num_gpus=2 train_deepspeed_zeropp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T03:16:22.450265Z",
     "iopub.status.busy": "2025-12-07T03:16:22.449452Z",
     "iopub.status.idle": "2025-12-07T03:16:22.462860Z",
     "shell.execute_reply": "2025-12-07T03:16:22.462249Z",
     "shell.execute_reply.started": "2025-12-07T03:16:22.450213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/working/pytorch_traces/deepspeed_zeropp_trace/"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (stored 0%)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.system('zip -r deepspeed_zeropp_trace.zip /kaggle/working/pytorch_traces/deepspeed_zeropp_trace')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
