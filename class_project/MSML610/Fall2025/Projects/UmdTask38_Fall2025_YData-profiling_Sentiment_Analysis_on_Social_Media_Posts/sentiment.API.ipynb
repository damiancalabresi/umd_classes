{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis API\n",
    "\n",
    "Load the trained model and make predictions on new airline tweets.\n",
    "\n",
    "This notebook demonstrates the production API for sentiment prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T20:30:51.231979Z",
     "start_time": "2025-12-14T20:30:50.921460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports OK\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "from typing import Dict, List\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import importlib\n",
    "import sentiment_utils\n",
    "importlib.reload(sentiment_utils)\n",
    "\n",
    "from sentiment_utils import (\n",
    "    predict_sentiment,\n",
    "    get_prediction_proba,\n",
    "    LABEL_MAP,\n",
    ")\n",
    "\n",
    "VECT_PATH = \"tfidf_vectorizer.joblib\"\n",
    "MODEL_PATH = \"logreg_sentiment_model.joblib\"\n",
    "\n",
    "print(\"✓ Imports OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T20:30:53.656018Z",
     "start_time": "2025-12-14T20:30:53.544447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading artifacts...\n",
      "\n",
      "✓ Vectorizer: 7576 features\n",
      "✓ Model: [0 1 2] classes\n",
      "\n",
      "Ready for predictions\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading artifacts...\\n\")\n",
    "\n",
    "vectorizer = load(VECT_PATH)\n",
    "model = load(MODEL_PATH)\n",
    "\n",
    "print(f\"✓ Vectorizer: {len(vectorizer.get_feature_names_out())} features\")\n",
    "print(f\"✓ Model: {model.classes_} classes\")\n",
    "print(f\"\\nReady for predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T20:30:56.392238Z",
     "start_time": "2025-12-14T20:30:56.383747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ SentimentAPI ready\n"
     ]
    }
   ],
   "source": [
    "class SentimentAPI:\n",
    "    \"\"\"Simple API for sentiment prediction.\"\"\"\n",
    "    \n",
    "    def __init__(self, vectorizer, model, label_map=None):\n",
    "        self.vectorizer = vectorizer\n",
    "        self.model = model\n",
    "        self.label_map = label_map or LABEL_MAP\n",
    "    \n",
    "    def predict(self, text: str) -> str:\n",
    "        \"\"\"Predict sentiment for a single text.\"\"\"\n",
    "        return predict_sentiment(text, self.vectorizer, self.model, self.label_map)[0]\n",
    "    \n",
    "    def predict_batch(self, texts: List[str]) -> List[str]:\n",
    "        \"\"\"Predict sentiment for multiple texts.\"\"\"\n",
    "        return predict_sentiment(texts, self.vectorizer, self.model, self.label_map)\n",
    "    \n",
    "    def predict_with_confidence(self, text: str) -> Dict[str, float]:\n",
    "        \"\"\"Predict with probability scores.\"\"\"\n",
    "        return get_prediction_proba(text, self.vectorizer, self.model, self.label_map)\n",
    "    \n",
    "    def predict_batch_with_confidence(self, texts: List[str]) -> List[Dict[str, float]]:\n",
    "        \"\"\"Batch prediction with scores.\"\"\"\n",
    "        return [self.predict_with_confidence(text) for text in texts]\n",
    "\n",
    "\n",
    "api = SentimentAPI(vectorizer, model)\n",
    "print(\"✓ SentimentAPI ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 1: Single Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T20:30:58.583271Z",
     "start_time": "2025-12-14T20:30:58.569628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SINGLE PREDICTIONS\n",
      "============================================================\n",
      "\n",
      "[1] I love flying with this airline! Best experience ever!\n",
      "    → POSITIVE\n",
      "\n",
      "[2] The flight was cancelled with no explanation. Terrible service.\n",
      "    → NEGATIVE\n",
      "\n",
      "[3] The flight arrived on time. Standard service.\n",
      "    → NEGATIVE\n",
      "\n",
      "[4] Amazing crew and comfortable seats!\n",
      "    → POSITIVE\n",
      "\n",
      "[5] Lost my luggage. Very disappointed.\n",
      "    → NEGATIVE\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "    \"I love flying with this airline! Best experience ever!\",\n",
    "    \"The flight was cancelled with no explanation. Terrible service.\",\n",
    "    \"The flight arrived on time. Standard service.\",\n",
    "    \"Amazing crew and comfortable seats!\",\n",
    "    \"Lost my luggage. Very disappointed.\",\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SINGLE PREDICTIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, text in enumerate(examples, 1):\n",
    "    pred = api.predict(text)\n",
    "    print(f\"\\n[{i}] {text}\")\n",
    "    print(f\"    → {pred.upper()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 2: Batch Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T20:31:02.773225Z",
     "start_time": "2025-12-14T20:31:02.760216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BATCH PREDICTIONS\n",
      "============================================================\n",
      "\n",
      "Results:\n",
      "\n",
      "1. [POSITIVE]\n",
      "   I love flying with this airline! Best experience ever!\n",
      "\n",
      "2. [NEGATIVE]\n",
      "   The flight was cancelled with no explanation. Terrible service.\n",
      "\n",
      "3. [NEGATIVE]\n",
      "   The flight arrived on time. Standard service.\n",
      "\n",
      "4. [POSITIVE]\n",
      "   Amazing crew and comfortable seats!\n",
      "\n",
      "5. [NEGATIVE]\n",
      "   Lost my luggage. Very disappointed.\n",
      "\n",
      "\n",
      "Summary:\n",
      "prediction\n",
      "negative    3\n",
      "positive    2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BATCH PREDICTIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "preds = api.predict_batch(examples)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'text': examples,\n",
    "    'prediction': preds\n",
    "})\n",
    "\n",
    "print(\"\\nResults:\")\n",
    "for idx, row in results_df.iterrows():\n",
    "    print(f\"\\n{idx+1}. [{row['prediction'].upper()}]\")\n",
    "    txt = row['text'][:70] + \"...\" if len(row['text']) > 70 else row['text']\n",
    "    print(f\"   {txt}\")\n",
    "\n",
    "print(f\"\\n\\nSummary:\")\n",
    "print(results_df['prediction'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 3: With Confidence Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T20:31:06.195245Z",
     "start_time": "2025-12-14T20:31:06.183341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "WITH CONFIDENCE SCORES\n",
      "============================================================\n",
      "\n",
      "[1] Best airline ever!\n",
      "    Probabilities:\n",
      "      negative  : 0.025 █\n",
      "      neutral   : 0.026 █\n",
      "      positive  : 0.949 █████████████████████████████████████\n",
      "    → Prediction: POSITIVE (95%)\n",
      "\n",
      "[2] Worst flight ever.\n",
      "    Probabilities:\n",
      "      negative  : 0.678 ███████████████████████████\n",
      "      neutral   : 0.207 ████████\n",
      "      positive  : 0.115 ████\n",
      "    → Prediction: NEGATIVE (68%)\n",
      "\n",
      "[3] Flight was okay, nothing special.\n",
      "    Probabilities:\n",
      "      negative  : 0.493 ███████████████████\n",
      "      neutral   : 0.448 █████████████████\n",
      "      positive  : 0.060 ██\n",
      "    → Prediction: NEGATIVE (49%)\n"
     ]
    }
   ],
   "source": [
    "test_texts = [\n",
    "    \"Best airline ever!\",\n",
    "    \"Worst flight ever.\",\n",
    "    \"Flight was okay, nothing special.\",\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"WITH CONFIDENCE SCORES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, text in enumerate(test_texts, 1):\n",
    "    probs = api.predict_with_confidence(text)\n",
    "    top_pred = max(probs, key=probs.get)\n",
    "    top_conf = probs[top_pred]\n",
    "    \n",
    "    print(f\"\\n[{i}] {text}\")\n",
    "    print(f\"    Probabilities:\")\n",
    "    for label in ['negative', 'neutral', 'positive']:\n",
    "        conf = probs[label]\n",
    "        bar = '█' * int(conf * 40)\n",
    "        print(f\"      {label:10s}: {conf:.3f} {bar}\")\n",
    "    print(f\"    → Prediction: {top_pred.upper()} ({top_conf:.0%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 4: Real Feedback Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T20:31:10.668273Z",
     "start_time": "2025-12-14T20:31:10.655649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CUSTOMER FEEDBACK ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Analyzed feedback:\n",
      "                             feedback sentiment\n",
      "Great experience, booked last minute!  positive\n",
      " Delayed 3 hours with no explanation.  negative\n",
      "  On-time arrival, comfortable seats.  positive\n",
      "  Food was cold and service was slow.  negative\n",
      "          Helpful and friendly staff!  positive\n",
      "               Just a regular flight.   neutral\n",
      "\n",
      "\n",
      "Summary:\n",
      "  positive  : 3 (50%)\n",
      "  neutral   : 1 (17%)\n",
      "  negative  : 2 (33%)\n"
     ]
    }
   ],
   "source": [
    "feedback = [\n",
    "    \"Great experience, booked last minute!\",\n",
    "    \"Delayed 3 hours with no explanation.\",\n",
    "    \"On-time arrival, comfortable seats.\",\n",
    "    \"Food was cold and service was slow.\",\n",
    "    \"Helpful and friendly staff!\",\n",
    "    \"Just a regular flight.\",\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CUSTOMER FEEDBACK ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "preds = api.predict_batch(feedback)\n",
    "\n",
    "df_feedback = pd.DataFrame({\n",
    "    'feedback': feedback,\n",
    "    'sentiment': preds\n",
    "})\n",
    "\n",
    "print(\"\\nAnalyzed feedback:\")\n",
    "print(df_feedback.to_string(index=False))\n",
    "\n",
    "print(f\"\\n\\nSummary:\")\n",
    "counts = df_feedback['sentiment'].value_counts()\n",
    "for sentiment in ['positive', 'neutral', 'negative']:\n",
    "    count = counts.get(sentiment, 0)\n",
    "    pct = (count / len(df_feedback)) * 100\n",
    "    print(f\"  {sentiment:10s}: {count} ({pct:.0f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T20:31:14.192253Z",
     "start_time": "2025-12-14T20:31:14.186975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "╔════════════════════════════════════════════════════════════╗\n",
      "║             SENTIMENT ANALYSIS API                          ║\n",
      "╚════════════════════════════════════════════════════════════╝\n",
      "\n",
      "Methods:\n",
      "\n",
      "1. api.predict(text: str) -> str\n",
      "   Single prediction. Returns: \"negative\", \"neutral\", \"positive\"\n",
      "\n",
      "2. api.predict_batch(texts: List[str]) -> List[str]\n",
      "   Batch prediction. Fast for multiple texts.\n",
      "\n",
      "3. api.predict_with_confidence(text: str) -> Dict[str, float]\n",
      "   Returns probabilities: {\"negative\": 0.7, \"neutral\": 0.2, ...}\n",
      "\n",
      "4. api.predict_batch_with_confidence(texts: List) -> List[Dict]\n",
      "   Batch with probabilities.\n",
      "\n",
      "Model Info:\n",
      "- Vectorizer: TF-IDF (20,000 features)\n",
      "- Classifier: Logistic Regression\n",
      "- Training: 14,640 airline tweets\n",
      "- Test accuracy: ~80%\n",
      "\n",
      "Usage Tips:\n",
      "- Use predict() for single texts\n",
      "- Use predict_batch() for efficiency\n",
      "- Check confidence for borderline cases\n",
      "- Works best on English airline-related text\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "╔════════════════════════════════════════════════════════════╗\n",
    "║             SENTIMENT ANALYSIS API                          ║\n",
    "╚════════════════════════════════════════════════════════════╝\n",
    "\n",
    "Methods:\n",
    "\n",
    "1. api.predict(text: str) -> str\n",
    "   Single prediction. Returns: \"negative\", \"neutral\", \"positive\"\n",
    "\n",
    "2. api.predict_batch(texts: List[str]) -> List[str]\n",
    "   Batch prediction. Fast for multiple texts.\n",
    "\n",
    "3. api.predict_with_confidence(text: str) -> Dict[str, float]\n",
    "   Returns probabilities: {\"negative\": 0.7, \"neutral\": 0.2, ...}\n",
    "\n",
    "4. api.predict_batch_with_confidence(texts: List) -> List[Dict]\n",
    "   Batch with probabilities.\n",
    "\n",
    "Model Info:\n",
    "- Vectorizer: TF-IDF (20,000 features)\n",
    "- Classifier: Logistic Regression\n",
    "- Training: 14,640 airline tweets\n",
    "- Test accuracy: ~80%\n",
    "\n",
    "Usage Tips:\n",
    "- Use predict() for single texts\n",
    "- Use predict_batch() for efficiency\n",
    "- Check confidence for borderline cases\n",
    "- Works best on English airline-related text\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
