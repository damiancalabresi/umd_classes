// Dir is https://drive.google.com/drive/folders/1u8ZUAkLc8yZBwGgXvfBcAY_oSCyzT_pp
// 
// 

::: columns
:::: {.column width=15%}
![](data605/lectures_source/images/UMD_Logo.png)
::::
:::: {.column width=75%}

\vspace{0.4cm}
\begingroup \large
UMD DATA605 - Big Data Systems
\endgroup
::::
:::

\vspace{1cm}

\begingroup \Large
**$$\text{\blue{9.3: Python Dask}}$$**
\endgroup

::: columns
:::: {.column width=75%}
- **Instructor**: Dr. GP Saggese, [gsaggese@umd.edu](gsaggese@umd.edu)

- **Resources**
  - Web resources:
    - [Dask project](https://docs.dask.org/en/stable/)
    - [Dask examples](https://examples.dask.org/)
  - Tutorial
    - [Dask\_tutorial](https://github.com/gpsaggese-org/umd_classes/blob/master/data605/tutorials/tutorial_dask/Dask_tutorial.ipynb)
    - [Dask\_advanced\_tutorial](https://github.com/gpsaggese-org/umd_classes/blob/master/data605/tutorials/tutorial_dask/Dask_advanced_tutorial.ipynb)
  - Class project
  - Mastery
    - Data science with Python and Dask, 2019
::::
:::: {.column width=20%}
![](data605/lectures_source/images/lecture_9_2/lec_9_2_slide_2_image_1.png)
::::
:::

* Dataset Size Issues
::: columns
:::: {.column width=75%}
- **Small datasets (< 1 GB)**
  - Fits into RAM
  - No disk paging needed

- **Medium dataset (< 1TB)**
  - Doesn't fit into RAM
  - Fits into local disk
    - Performance penalty with local disk
  - Need multiple CPU cores
    - Difficult to leverage parallelism with Python/Pandas

- **Large dataset (> 1TB)**
  - Doesn't fit into RAM
  - Doesn't fit into local disk
  - Need multiple servers
    - Python/Pandas not built for distributed datasets
    - Use frameworks for massive datasets
    - E.g., Hadoop, Spark, Dask, Ray
::::
:::: {.column width=20%}
![](data605/lectures_source/images/lecture_9_2/lec_9_2_slide_3_image_3.png)

\vspace{1cm}

![](data605/lectures_source/images/lecture_9_2/lec_9_2_slide_3_image_4.png)

\vspace{1cm}

![](data605/lectures_source/images/lecture_9_2/lec_9_2_slide_3_image_1.png)

![](data605/lectures_source/images/lecture_9_2/lec_9_2_slide_3_image_2.png)
::::
:::

* Dataset Size Issues

| **Category**    | **Size**    |
|-----------------|-------------|
| Small datasets  | < 1 GB      |
| Medium datasets | < 1 TB      |
| Large datasets  | > 1 TB      |

- **The thresholds are fuzzy and changing over time**
  - Scale computer 10x to get 10x bigger datasets

- **Problem with scaling datasets**
  - Long run times
  - Rewriting code for different dataset sizes
  - Plan what and how to do efficiently
  - Cumbersome framework (Pandas easy, Hadoop difficult)

* Dask
::: columns
:::: {.column width=60%}
- **Dask is written in Python**
  - Scales Numpy, Pandas, sklearn
  - Dask objects wrap library objects (e.g., Pandas DataFrame, numpy array)
  - Parallel parts are "chunks" or "partitions"
    - Queued for work
    - Shipped between machines
    - Worked locally
::::
:::: {.column width=35%}
![](data605/lectures_source/images/lecture_9_2/lec_9_2_slide_5_image_1.png)
::::
:::

- **Pros**
  - Use familiar interfaces
  - Write code optimized for parallelism
    - Dask handles heavy lifting

- **Scaling Dask is easy**
  - Prototype on local machine, use cluster when needed
  - No code refactoring needed
  - No cluster-specific issues
    - E.g., resource management, data recovery, data movement
  - Runs on multi-core
  - Uses cluster managers
    - E.g., Yarn, Mesos, Kubernetes, AWS ECS

* Dask Layers

![](data605/lectures_source/images/lecture_9_2/lec_9_2_slide_6_image_1.png)

* Scaling Up vs Scaling Out
::: columns
:::: {.column width=70%}
- **Scaling up**
  - Replace equipment with larger, faster options
    - E.g., buy a larger pot, replace knife with food processor
  - **Pros**
    - Better hardware, no code changes needed
  - **Cons**
    - Exceed current machine capacity eventually
    - Cost: more powerful machines are expensive
::::
:::: {.column width=25%}
![](data605/lectures_source/images/lecture_9_2/lec_9_2_slide_7_image_1.png)
::::
:::

\vspace{1cm}

::: columns
:::: {.column width=70%}
- **Scaling out**
  - Divide work between many workers in parallel
    - E.g., buy more pots and hire more cooks
  - **Pros**
    - Task scheduler organizes computation, assigns workers to tasks
    - Cost-effective, no specialized hardware needed
  - **Cons**
    - Write code to expose parallelism
    - Maintain cluster costs
::::
:::: {.column width=25%}
![](data605/lectures_source/images/lecture_9_2/lec_9_2_slide_7_image_2.png)
::::
:::

* Dask: Computation
- **Lazy computations**
  - Define transformations on data
  - Define next computation without waiting
  - Operate in chunks to avoid loading entire data in memory
  - E.g.,
    - Split 2GB file into 32 64MB chunks
    - Operate on 8 chunks per server
    - Max memory use: 512MB = (8 x 64MB)
  - Track object dimensions and data types
    - No code execution

- `compute()`
  - Run computation (materialize)
    ```python
    missing_count_pct = missing_count.compute()
    ```

- `persist()`
  - Discard intermediate work to minimize memory
  - Re-run graph for additional computation on intermediate nodes
  - Keep intermediate result in memory
  - Speed up large, complex DAGs for reuse

* Dask: Data Structures
::: columns
:::: {.column width=75%}
- **Dask DataFrame**
  - Implements Pandas DataFrame
  - Tabular/relational data
::::
:::: {.column width=20%}
![](data605/lectures_source/images/lecture_9_2/lec_9_2_slide_9_image_2.png)
::::
:::

\vspace{1cm}

::: columns
:::: {.column width=65%}
- **Dask Array**
  - Implements numpy ndarray
  - Multidimensional array
::::
:::: {.column width=30%}
![](data605/lectures_source/images/lecture_9_2/lec_9_2_slide_9_image_1.png)
::::
:::

\vspace{1cm}

::: columns
:::: {.column width=75%}
- **Dask Bag**
  - Coordinates Python lists of objects
  - Parallelize computations on unstructured/semi-structured data
::::
:::: {.column width=20%}
![](data605/lectures_source/images/lecture_9_2/lec_9_2_slide_9_image_3.png)
::::
:::

* Dask Reading Data
::: columns
:::: {.column width=55%}
- Consider:

  \scriptsize
  ```python
  import dask.dataframe as dd
  df = dd.read_csv('nyc-parking-tickets-2017.csv')
  missing_values = df.isnull().sum()
  missing_values 
  ```
::::
:::: {.column width=40%}
![](data605/lectures_source/images/lecture_9_2/lec_9_2_slide_10_image_1.png)
::::
:::

\vspace{0.5cm}

::: columns
:::: {.column width=65%}
- `dask.dataframe.read_csv()`
  - Doesn't load data in memory
  - Infers column types
    - Samples data
    - Set data types
    - Use Parquet for data and types together

- Partitions = independent data chunks
  - E.g., 33 partitions
  - Graph = 99 tasks
  - Each partition reads, splits data, initializes df object
::::
:::: {.column width=30%}
![](data605/lectures_source/images/lecture_9_2/lec_9_2_slide_10_image_2.png){height=60%}
::::
:::

* Low Level APIs: Delayed
- Handle computations that don't fit in native Dask data structures
  - E.g., Dask DataFrame
- In the example below there is parallelism that can be exploited

::: columns
:::: {.column width=40%}

![](data605/lectures_source/images/lecture_9_2/lec_9_2_slide_11_image_1.png)
::::
:::: {.column width=40%}

![](data605/lectures_source/images/lecture_9_2/lec_9_2_slide_11_image_2.png){height=60%}
::::
:::

* Low Level APIs: Futures
::: columns
:::: {.column width=45%}
- In parallel programming, a "future" encapsulates asynchronous execution,
  representing the eventual result

- Python `concurrent.futures`
  - High-level interface for asynchronous execution
  - Thread pool or Process pool (`Executor` interface)

- Dask extends `concurrent.futures`
  - Express everything as futures
  - Specify blocking and non-blocking

::::
:::: {.column width=50%}
![](data605/lectures_source/images/lecture_9_2/lec_9_2_slide_12_image_1.png)

![](data605/lectures_source/images/lecture_9_2/lec_9_2_slide_12_image_2.png){width=50%}

![](data605/lectures_source/images/lecture_9_2/lec_9_2_slide_12_image_3.png){width=150%}

![](data605/lectures_source/images/lecture_9_2/lec_9_2_slide_12_image_4.png){width=150%}
::::
:::

* Different Types of Parallel Workload
- Break program in medium-size tasks of computation
  - E.g., a function call

::: columns
:::: {.column width=40%}
![](data605/lectures_source/images/lecture_9_2/lec_9_2_slide_13_image_2.png)
::::
:::: {.column width=40%}
![](data605/lectures_source/images/lecture_9_2/lec_9_2_slide_13_image_1.png){width=80%}
::::
:::
\center
![](data605/lectures_source/images/lecture_9_2/lec_9_2_slide_13_image_3.png){width=40%}

* Encoding Task Graph
- Dask encodes tasks in terms of Python dicts and functions

\center
![](data605/lectures_source/images/lecture_9_2/lec_9_2_slide_14_image_1.png){width=10cm}

![](data605/lectures_source/images/lecture_9_2/lec_9_2_slide_14_image_2.png){width=10cm}

* Task Scheduling
- Data collections (Bags, Arrays, DataFrame) and operations create task graphs
  - Nodes: Python functions
  - Edges: Dependencies (output from one task used as input in another)

- Schedule task graphs for execution
  - Single-machine scheduler
    - Use local process or thread pool
    - Runs on a single machine
  - Distributed scheduler
    - Runs locally or across a cluster

![](data605/lectures_source/images/lecture_9_2/lec_9_2_slide_15_image_1.png)

* Task Scheduling
- **Dask task scheduler orchestrates work dynamically**
  - Not static scheduling like a relational DB
  - During computation, Dask dynamically assesses:
    - Completed tasks
    - Remaining tasks
    - Free resources (CPUs)
    - Data location

::: columns
:::: {.column width=50%}
- **Dynamic approach handles various issues**
  - Worker failure
    - Re-run tasks
  - Workers completing at different speeds due to:
    - Different computation
    - Different hardware
    - Varying server workloads
    - Slower data access
  - Network unreliability
    - Re-run or remove isolated nodes
::::
:::: {.column width=45%}
![](data605/lectures_source/images/lecture_9_2/lec_9_2_slide_16_image_1.png)
::::
:::

* Dask vs Spark
- **Pros**
  - Popular framework for large datasets
  - In-memory alternative to MapReduce/Hadoop

- **Cons**
  - Java library, supports Python via PySpark API
    - Python code runs on JVM
    - Debugging is difficult as execution is outside Python
  - Different DataFrame API than Pandas
    - Learn "the Spark way"
    - May need to implement twice for exploratory analysis and production
  - Optimized for MapReduce operations
  - Difficult to set up and configure
