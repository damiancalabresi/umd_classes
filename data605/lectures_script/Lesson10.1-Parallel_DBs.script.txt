# ##############################################################################
# Intro
# ##############################################################################

In this lesson, we will discuss client-server architecture, the distinctions
between parallel and distributed computing, the evolution of parallel databases,
measuring parallel performance, factors impacting speed-up and scale-up, various
topologies of parallel systems, and the consistency challenges faced in
distributed database systems. Letâ€™s delve into each topic.

# ##############################################################################
# Client-Server Architecture
# ##############################################################################

Let's discuss the client-server model, which is a way to organize distributed
applications. In this model, tasks are divided between clients and servers.
Clients are the ones that request services, like dashboards or graphical user
interfaces. Servers, on the other hand, provide the resources or services, such
as databases. In a database system, the architecture is split into a back-end
and a front-end. The back-end, or server, handles tasks like query evaluation
and concurrency control. The front-end, or clients, use tools like forms and
GUIs. The connection between these two parts is often managed through SQL or
APIs.

Now, let's move on to understanding the differences between parallel and
distributed computing.

# ##############################################################################
# Parallel vs Distributed Computing
# ##############################################################################

We have two main types of computing: parallel and distributed. Parallel
computing involves one computer with multiple CPUs or a cluster of computers
working together on a single task. These nodes are usually similar and located
close to each other. In contrast, distributed computing involves separate
systems that are geographically apart and can be quite different from each
other. These systems perform different tasks independently. Understanding these
differences helps us choose the right approach for our computing needs.

Next, let's dive deeper into parallel systems and their components.

# ##############################################################################
# Parallel Systems
# ##############################################################################

Parallel systems are made up of multiple processors, memories, and disks
connected by a fast network. There are two types of parallel machines:
coarse-grain and fine-grain. Coarse-grain machines have a small number of
powerful processors, like a laptop with multiple CPUs. Fine-grain machines, also
known as massively parallel machines, have thousands of smaller processors,
offering a higher degree of parallelism. These can have shared or separate
memory and include examples like GPUs and The Connection Machine from the 1980s.
Understanding these systems helps us leverage their power for complex
computations.

# ##############################################################################
# Parallel Databases: Introduction
# ##############################################################################

Let's discuss the evolution of parallel databases. Before MapReduce, parallel
databases were the go-to solution for handling large data. As technology
advanced, parallel machines became more accessible and affordable due to the
decreasing costs of microprocessors, memory, and disks. Nowadays, even personal
computers have multiple processors. This trend is expected to continue. With
databases growing larger, they are now used to store vast amounts of transaction
data and multimedia objects. Large-scale parallel databases are essential for
storing big data, processing complex queries, and ensuring high transaction
throughput.

Transition: Now, let's explore how the internet and big data have influenced the
need for parallel databases.

# ##############################################################################
# Parallel Databases
# ##############################################################################

The rise of the internet and big data has created a demand for large and fast
databases capable of storing petabytes of data and processing thousands of
transactions per second, such as those needed by e-commerce websites. Databases
can be parallelized because their set-oriented queries are well-suited for
parallel processing. Some operations, like certain joins, are naturally
parallelizable and can be executed as MapReduce tasks. Parallel databases aim to
increase transactions per second or reduce query time, balancing throughput and
response time. However, perfect speedup is challenging due to start-up costs,
task interference, and data skew.

Transition: Let's delve into how we can measure the performance of parallel
systems.

# ##############################################################################
# How to Measure Parallel Performance
# ##############################################################################

When measuring parallel performance, we focus on throughput and latency.
Throughput refers to the number of tasks completed in a given time, which can be
increased by processing tasks in parallel. Latency is the time it takes to
complete a single task from submission, which can be reduced by performing
subtasks in parallel. Although related, throughput and latency are not the same.
We can increase throughput by reducing latency or by pipelining, which involves
overlapping task execution. For example, while building a car takes weeks,
pipelining allows one car to be completed every hour, similar to microprocessor
instruction pipelining.

# ##############################################################################
# Speed-Up and Scale-Up: Intuition
# ##############################################################################

Let's start by understanding the concepts of speed-up and scale-up. When we have
a workload, like database transactions or data queries, we can change the
workload size, denoted as M. To handle this workload, we can adjust the
computing power, denoted as N, by either upgrading the CPU (scaling up) or
adding more CPUs (scaling out). We measure efficiency in two ways: speed-up,
where we keep the workload size constant and increase computing power, and
scale-up, where we increase both the workload size and computing power.

Transition: Now, let's dive deeper into the differences between speed-up and
scale-up.

# ##############################################################################
# Speed-Up vs Scale-Up
# ##############################################################################

We can change both the computing power (N) and the workload (M). Speed-up
involves solving a fixed-sized problem on a larger system, and it's calculated
by dividing the time taken by a small system by the time taken by a large
system. If the result equals N, speed-up is linear. On the other hand, scale-up
involves increasing both the problem size and system size. It's calculated
similarly, and scale-up is linear if the result equals 1.

Transition: Next, we'll explore the factors that can limit speed-up and
scale-up.

# ##############################################################################
# Factors Limiting Speed-up and Scale-up
# ##############################################################################

Speed-up and scale-up are often not perfectly linear due to certain limitations.
For instance, some computations can be done in parallel, while others must be
done sequentially. Amdahl's Law helps us understand this by showing that the
speed-up is limited by the fraction of the task that can be parallelized. For
example, if 90% of a task is parallelizable, the maximum speed-up is 10 times.
If only 50% is parallelizable, the maximum speed-up is just 2 times, even with
infinite nodes.

# ##############################################################################
# Factors Limiting Speed-up and Scale-up
# ##############################################################################

Let's discuss the factors that can limit how fast and how much we can scale up
our systems. Startup costs can be a big issue because the time it takes to start
processes can overshadow the actual computation time. For example, databases
often create a thread pool when they start up. Interference is another factor,
where processes compete for shared resources like the system bus or disks,
leading to delays. This is similar to developers working on the same code and
causing merge conflicts. The cost of synchronization increases when we break
tasks into smaller pieces, much like hiring many developers in a company.
Lastly, skew occurs when splitting work leads to uneven task response times,
with the slowest task determining the overall execution time.

Let's move on to how we can organize our systems to handle these challenges.

# ##############################################################################
# Topology of Parallel Systems
# ##############################################################################

We have several ways to organize computation and storage in parallel systems.
These include shared memory, shared disk, shared nothing, and hierarchical
topologies. Each topology has its own set of challenges, such as cache
coherency, data communication, fault tolerance, and resource congestion. Shared
memory systems allow multiple processors to access the same memory, while shared
disk systems let processors access the same disks. Shared nothing systems have
separate memory and disks for each processor, and hierarchical systems combine
these approaches. Understanding these topologies helps us choose the right one
for our needs.

Now, let's compare these topologies to see their strengths and weaknesses.

# ##############################################################################
# Topology of Parallel Systems: Comparison
# ##############################################################################

In this section, we compare different topologies of parallel systems. Each
topology has its own advantages and disadvantages. Shared memory systems are
easy to program but can suffer from cache coherency issues. Shared disk systems
provide good fault tolerance but may face data communication challenges. Shared
nothing systems offer excellent scalability but can experience resource
congestion. Hierarchical systems try to balance these factors but can be complex
to manage. By comparing these topologies, we can better understand which one
suits our specific requirements and constraints.

# ##############################################################################
# Distributed Databases
# ##############################################################################

Let's explore distributed databases, which are databases stored across nodes in
different locations. These nodes communicate through high-speed networks or the
Internet. Distributed databases are often necessary for large corporations with
global offices, providing redundancy and disaster recovery in cases like natural
disasters or hacker attacks. They ensure high availability despite failures.
However, they are not typically used for performance reasons; parallel databases
are better for that. Distributed databases operate over wide-area networks,
which have lower bandwidth, higher latency, and a greater chance of failures
compared to local-area networks. Communication delays are common since memory or
disks are not shared, and nodes can vary in size and function, unlike parallel
databases where nodes are similar.

Now, let's move on to discuss consistency issues in distributed database
systems.

# ##############################################################################
# Consistency Issues in Distributed DB Systems
# ##############################################################################

In distributed databases, while query processing works well for reading data,
updating requires consistency enforcement. Atomicity issues arise because
transactions need to be all-or-nothing across multiple nodes. The two-phase
commit (2PC) is a centralized approach where a single coordinator node makes the
commit decision. Each node executes the transaction and reaches a "ready state."
If all nodes are ready, the coordinator commits; if a node fails, it can recover
using write-ahead logs. If a node aborts, the transaction is aborted.
Distributed consensus methods like Paxos and Blockchain can also be used.

Let's continue to explore more consistency issues, focusing on concurrency and
autonomy.

# ##############################################################################
# Consistency Issues in Distributed DB Systems
# ##############################################################################

Concurrency issues occur when multiple processes write and read simultaneously,
requiring locks and deadlock management to ensure smooth operation. Autonomy
issues arise when different units or departments are protective of their
systems, which can complicate administering, patching, and updating systems.
These challenges need careful management to maintain consistency and efficiency
in distributed database systems.

# ##############################################################################
# Outro
# ##############################################################################

In this lesson, we discussed client-server architecture, the differences between
parallel and distributed computing, and explored parallel systems, databases,
performance metrics, and the challenges of speed-up and scale-up. We also
examined distributed databases, their consistency issues, and the importance of
topology in organizing computation.
