::: columns
:::: {.column width=15%}
![](msml610/lectures_source/figures/UMD_Logo.png)
::::
:::: {.column width=75%}

\vspace{0.4cm}
\begingroup \large
MSML610: Advanced Machine Learning
\endgroup
::::
:::

\vspace{1cm}

\begingroup \Large
**$$\text{\blue{Lesson 09.4: State Space Models}}$$**
\endgroup
\vspace{1cm}

**Instructor**: Dr. GP Saggese, [gsaggese@umd.edu](gsaggese@umd.edu)

**References**:

- AIMA 14: Probabilistic reasoning over time
- https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python

// ./notes/math.Kalman_filter.txt
// ./notes/math.Kalman_and_Bayesian_filters_in_Python.Labbe.2018.txt
// ./notebooks/quantopian/quantopian_kalman_filter.ipynb
// ./notebooks/Kalman_and_Bayesian_filters_in_python
// - AIMA 14.4 (p. 479)

# ##############################################################################
# State Space Models and Kalman Filter
# ##############################################################################

* Tracking Objects
- Many problems can be formulated as **tracking objects**

- **Examples**
  - Navigation of aircraft, drones, autonomous cars
  - Robotics: arm kinematics to predict the position of joints
  - Sensor fusion: merge multiple sensor readings
  - Finance: predict economic variables (e.g., stock prices)
  - Computer vision: track moving objects across video

- **Kalman filter**
  - Used for state estimation in dynamic systems with noisy, uncertain
    measurements
  - Track over time using predictions (model) and observations

* Some Guiding Principles
- **The world is noisy**
  - E.g., a car might swerve around a pothole or brake for a pedestrian
  - E.g., wind or ice might change the car's path

- **Sensors are noisy**
  - A kitchen scale gives different readings for the same object

- **Knowledge is uncertain**
  - You alter beliefs based on evidence strength

- Use past information and system knowledge to estimate future information
  - E.g., if a car moves at a certain speed at time $t$, the speed at time $t+1$
    is likely close to the previous speed

- Data is better than a guess, even if noisy
  - Never discard information, no matter how poor
  - E.g., two sensors, even if one is less accurate, are better than one

## #############################################################################
## g-h Filter
## #############################################################################

* Example of Weight: Blending Predictions and Measurements
- Imagine going to the gym to gain muscle mass
  - Estimate your weight over time

- You could:
  1. **Predict your weight**
     - Track calorie intake and energy expense
     - Compute expected weight gain
     - Cons: Difficult to track food intake and exercise accurately
  2. **Measure your weight**
     - Use a scale
     - Cons: Scale is noisy, water weight fluctuates, different clothes

- Prediction doesn't match measurements
  - At time $t - 1$
    - Estimate: $\hat{x}_{t-1} = 158$
  - At time $t$:
    - Scale measures 164
    - Estimate $\hat{x}_{t|t-1} = 159$ based on calorie intake

- **What's your real weight?**
  - You need to blend prediction and measurement

* Example of Weight: Correct Gain_Rate
- **Blend the estimates like:**

  $$
  \text{estimate = 0.6} \times \text{prediction} + (1 - 0.6) \times \text{measurement}
  $$
  - You believe the prediction is more likely correct than the measurement

- **Algorithm**
  1. Start with an initial guess
     - Assume it's correct for now
  2. Predict the next weight based on the model
  3. Measure the weight
  4. Estimate the next weight by merging values:
     - The prediction is always between the prediction and the measurement
  5. Go back to first step

* Example of Weight:

- The black line is the actual weight, i.e., **ground truth**
- The initial guess is 160 lbs
- The \red{red line} is the **prediction** from previous day's weight
- The **measurements** are the circles
- The \blue{blue} line is the **estimate** from the filter
  - Always falls between measurement and prediction

- It's not impressive since the prediction model describes the ground truth, so
  you don't need the measurements

// TODO: Add pic

* Example of Weight: Learning Gain_Rate
- Consider when the model predicts a gain of -10lb/day, which is incorrect
  - Estimates diverge from measurements

- The filter needs a correct guess of the weight change rate
  - Also the rate of change can vary over time

- Solution: estimate the rate of change from measurements
  - "Data is better than a guess, even if it's noisy"
  - Refine the estimate of the gain rate:
    $$
    \text{new gain = old gain + 0.3 (measurement - prediction) / 1 day}
    $$

- The "state" is given by `weight` and `gain_rate`, so you need to predict and
  update both

// TODO

* g-h Filter
- The previous algorithm is called **g-h filter**
  - $g$: scaling used to blend predicted state and measurement
  - $h$: scaling used to update the parameter of the system model based on the
    measurements

- g-h filters have different values of $g$ and $h$ to achieve different
  properties
  - E.g., pick $g$ to minimize the transient error when the derivative of the
    signal has a step (i.e., a discontinuity of the slope)
  - Many filters (including Kalman filter) are just generalizations of a g-h
    filter

* Control Theory Nomenclature
- State space models were developed in control theory, so there is a different
  nomenclature

- **System**: object you want to estimate/track

- **Filter**: algorithm to estimate the state of the system

- **State of the system** `x`: current values you are interested in
  - E.g., weight
  - Part of the state might be hidden (i.e., not observable)
  - You cannot observe the entire state directly, only measure it indirectly

- **Measurement** `z`: the measured value of the system
  - It is observable
  - It can be inaccurate
    - E.g., 99.3kg instead of 100kg

- **State estimate** `x_est`: filter estimate of the state

- **System model**: mathematical model of the system
  - E.g., "weight today = weight yesterday + weight gain"
  - The system model is typically imperfect
  - There is error in the specification of the model

- **System propagation**: predict step using the system model to form a new
  state estimate `x_pred`
  - Because the system model is imperfect, the estimate is imperfect

- **Measurement update**: update step

// TODO(gp): Add a diagram

* g-h Filter Algorithm: Pseudo-Code ::: Columns :::: {.Column Width=55%}

1. Initialization
   - Initialize the state of the filter
   - Initialize your belief in the state
2. Predict
   - Use system model to predict state at next time step
   - Adjust belief to account for uncertainty in prediction
3. Update
   - Get measurement and associated belief about its accuracy
   - Use as estimate of the next state a point between estimated state and
     measurement
::::
:::: {.column width=40%}

```graphviz
digraph BayesianFlow {
    splines=true;
    nodesep=1.0;
    ranksep=0.75;

    node [shape=box, style="rounded,filled", fontname="Helvetica", fontsize=12, penwidth=1.7];

    // Node styles
    x0   [label="Initial Conditions (x_0)", shape=box, fillcolor="#F4A6A6"];
    zk   [label="Measurement (z_k)", shape=box, fillcolor="#FFD1A6"];
    pred [label="Predict\nStep", shape=box, fillcolor="#A6C8F4"];
    upd  [label="Update\nStep", shape=box, fillcolor="#C6A6F4"];
    xhat [label="State Estimate (\hat{x}_k)", shape=box, fillcolor="#B2E2B2"];

    // Force ranks
    {rank=same; x0; zk;}
    {rank=same; pred; upd;}

    // Edges
    x0   -> pred;
    pred -> upd;
    zk   -> upd;
    upd  -> pred;
    pred -> xhat;
}
```
::::
:::

* Interpretation of $g$
- If $g = 0$:
  - The filter follows the system model, ignoring the measurements

- If $g$ increases:
  - The filter follows the measurements more, ignoring the prediction
  - Useful when measurements are accurate and the system model is inaccurate

- If $g = 1$:
  - The filter follows only the measurements, ignoring the system model

// Add pic

* Interpretation of $h$
- You might need to estimate some model parameters from data, e.g.,
  - The change of weight
  - The rate of change of the measurements
  - The speed of the car on different terrains

- If $h = 0$:
  - The filter follows the previous values of the rate of change of the
    underlying model
  - I.e., it adapts slowly to the change of the signals

- If $h = 1$:
  - The filter reacts to the transient rapidly if the signal varies
    significantly with respect to the time step

- **Note**: an incorrect initial state (e.g., initial value/rate of change) is
  similar to a changing state

// Add pic

## #############################################################################
## One Dimensional Kalman Filters
## #############################################################################

* Updating Belief Using Gaussians
- The Bayes theorem tells that:
  $$
  \text{posterior = normalized(prior $\times$ likelihood)}
  $$
- If the prior and the likelihood are Gaussian the result is also Gaussian
  (conjugate prior)
  - The belief and probability are represented as a Gaussian
  - We can encode the PDF in terms of mean and std dev
  - Updating belief is equivalent to sum and multiplication of Gaussians

- Algorithm:

  ```python
   # Create prior (using current estimate and system model)
   prior = predict(x, process_model)

   # Create likelihood (using measurement).
   likelihood = gaussian(z, sensor_var)

   # Update belief using prior and likelihood
   posterior = update(prior, likelihood)
  ```

* Sum of Gaussians
- The sum of two independent Gaussians

  $$
  \begin{aligned}
  & Normal(\mu_1, \sigma_1^2) \\
  & Normal(\mu_2, \sigma_2^2) \\
  \end{aligned}
  $$

  is a Gaussian $Normal(\mu, \sigma^2)$ with:

  $$
  \begin{aligned}
  & \mu = \mu_1 + \mu_2 \\
  & \sigma^2 = \sigma_1^2 + \sigma_2^2 \\
  \end{aligned}
  $$

- The mean is the sum of the mean (by linearity)
- The variance always increases

* Product of Gaussians
- The product of two independent Gaussians

  $$
  \begin{aligned}
  & Normal(\mu_1, \sigma_1^2) \\
  & Normal(\mu_2, \sigma_2^2) \\
  \end{aligned}
  $$

  is a Gaussian $\N(\mu, \sigma^2)$ with:

  $$
  \begin{aligned}
  & \mu = \frac{\mu_1 \sigma_2^2 + \mu_2 \sigma_1^2}{\sigma_1^2 + \sigma_2^2} \\
  & \sigma^2 = \frac{\sigma_1^2 \sigma_2^2}{\sigma_1^2 + \sigma_2^2} \\
  \end{aligned}
  $$

- **Interpretation:**
  - The variance may be reduced as more information is incorporated
  - If one Gaussian $N_1$ is much narrower than the other (i.e., one measure is
    more accurate), the result is pushed towards $N_1$
  - If two Gaussians are similar (i.e., two measures corroborate each other),
    the result becomes more certain

* Kalman Gain
- Assume that:
  - $x$ is the model prediction
  - $z$ indicates the measurements

- The mean of the posterior is:

  $$
  \mu
  = \frac{\sigma_x^2 \mu_z + \sigma_z^2 \mu_x}{\sigma_x^2 + \sigma_z^2}
  = \frac{\sigma_x^2}{\sigma_x^2 + \sigma_z^2} \mu_z +
  \frac{\sigma_z^2}{\sigma_x^2 + \sigma_z^2} \mu_x
  = K \mu_z + (1 - K) \mu_x
  $$

- The Kalman Gain $K$:
  - Is the scaling term that mixes the prediction and the measurement
  - Depends on the ratio of uncertainty of prior and measurement

* Kalman Pseudo-Algorithm
- The typical formulation of the Kalman filter is in terms of the "orthogonal
  projection" approach to minimize mean squared error
  - Instead of a Bayesian formulation

- Typical symbols used in Kalman literature:
  - $x$: state
  - $P$: variance of state (uncertainty, belief)
  - $f()$: system model
  - $Q$: system model error
  - $z$: measurement
  - $R$: measurement noise

- **Initialization**
  - Initialize state of filter $x = x_0$
  - Initialize belief in the state $P = P_0$

- **Predict**
  - Use system model to predict state at the next time step $x = f(x)$
  - Adjust belief to account for uncertainty in prediction $P = P + Q$

- **Update**
  - Get measurement $z$ and belief about its accuracy $R$
  - Compute residual between estimated state $x$ and $z$: $y = z - x$
  - Compute scaling factor (Kalman $K$) based on accuracy of prediction $P$ and
    measurement $R$
  - Update state: $x = x + K * y$
  - Update belief in the state: $P = (1 - K) * P$

```python
def predict(posterior, movement):
  x, P = posterior    # Mean and variance of posterior.
  dx, Q = movement    # Mean and variance of movement.
  x = x + dx          # Compute prediction.
  P = P + Q
  return gaussian(x, P)

def update(prior, measurement):
  x, P = prior        # Mean and variance of prior.
  z, R = measurement  # Mean and variance of measurement.

  y = z - x           # Residual.

  K = P / (P + R)     # Kalman gain.

  x = x + K * y       # Mean of posterior.
  P = (1 - K) * P     # Variance of posterior.
  return gaussian(x, P)
```

## #############################################################################
## Multivariate Gaussians
## #############################################################################

* Multivariate State
- Often the state variable is multivariate, e.g.,
  - Position and velocity of a dog (probably uncorrelated)
  - Height and weight of an adult (correlated)

- **Variance** is a measure of how a population varies, e.g.,
  - Variance = 0 means constant
  - Large variance means lots of variation

- **Covariance** are correlated variances
  - E.g., height and weight are generally positively correlated

- **Covariance matrix**
  - The diagonal contains the variance for each variable
  - The off-diagonal elements contain the covariance between $i$ and $j$
    variables
  - The covariance matrix is symmetric

- Correlation allows prediction
  - E.g., "as winter comes you predict you will spend more on heating your
    house"

* Multivariate Gaussian
- The marginal of a multivariate Gaussian is 1-d Gaussian
- Consider a contour plot (i.e., the intersection of a 2-d Gaussian
  $z = f(x, y)$ with a plane $z = c$)
  - The contour plot is always an ellipses

* Multiplying Two Multivariate Gaussians
- Given two multivariate Gaussians $\sim Normal(\vmu_i, \mSigma_i)$
- The product of the Gaussians is still Gaussian $\sim Normal(\vmu, \mSigma)$
  $$
  \begin{aligned}
  \vmu &= \mSigma_2 (\mSigma_1 + \mSigma_2)^{-1} \vmu_1 +
    \mSigma_1 (\mSigma_1 + \mSigma_2)^{-1} \vmu_2 \\
  \mSigma &= \mSigma_1 (\mSigma_1 + \mSigma_2)^{-1} \mSigma_2 \\
  \end{aligned}
  $$
- **Note**: this is a generalization of the 1-d case to multivariate

  $$
  \begin{aligned}
  & \mu = \frac{\mu_1 \sigma_2^2 + \mu_2 \sigma_1^2}{\sigma_1^2 + \sigma_2^2} \\
  & \sigma^2 = \frac{\sigma_1^2 \sigma_2^2}{\sigma_1^2 + \sigma_2^2} \\
  \end{aligned}
  $$

  replacing:
  - $\sigma^2$ with covariance matrix $\mSigma$
  - Division with matrix inversion

* Multivariate Filtering
- Covariance structure helps improve the estimate, e.g.,
  - You know an airplane direction can't change quickly
  - Knowing an approximate value for the velocity helps constrain possible next
    positions

- **E.g., airplane**
  - You are tracking a plane moving in a direction (1-d problem)
  - At time 1, you are fairly certain about the position $x=0$, but you don't
    know the velocity
    - You plot position and velocity on an x-y plane
    - The covariance matrix between position and velocity is narrow and tall
    - It is narrow on the x-axis since you know that the position is around
      $x=0$
    - It is tall on the y-axis because of your lack of knowledge about velocity
  - After 1 sec, you get a position update of $x=5$
    - You can infer that the velocity is 5/s
    - The covariance matrix is then stretched diagonally

# ##############################################################################
# Multivariate Kalman Filters
# ##############################################################################

* Notation
- A Bayesian notation $a | b$ means "$a$ given the evidence of $b$"
  - The prior is $\hat{\vx}_{t|t-1}$, since you know only the information at
    time $t-1$, i.e., the previous state
  - The posterior is $\hat{\vx}_{t|t}$, since you know all the information at
    time $t$, i.e., the measurement

- **A simpler notation:**
  - Indicate the "prior" version of the variables (i.e., after the system
    update) with an overline (E.g., $\overline{x}$, $\overline{\bx}$,
    $\overline{\bX}$)
  - Omit the indices $t + 1$ and $t$ and use an assignment notation
    (representing "update in place" of a variable):
    $$
    x = x + 1
    $$
    instead of the mathematical notation using a different variable for each
    time step:
    $$
    x_{t+1} = x_t + 1
    $$
  - With this notation:
    - The prior is $\overline{x} = \hat{x}_{t|t-1}$
    - The posterior is $x = \hat{x}_{t|t}$

* Multivariate Kalman Filter

- With the previous notation:
  - State update: $\overline{\bx} = \bF \bx + \bB \bu$
  - State uncertainty: $\overline{\bP} = \bF \bP \bF^T + \bQ$
  - Residual: $\by = \bz - \bH \overline{\bx}$
  - Kalman gain:
    $\bK = \overline{\bP} \bH^T (\bH \overline{\bP} \bH^T + \bR)^{-1}$
  - Updated state: $\bx = \overline{\bx} + \bK \by$
  - Update state uncertainty: $\bP = (\bI - \bK \bH) \overline{\bP}$

- Where
  - $\bx$ and $\bP$ are the state mean and covariance
  - $\bF$ is the state transition function
  - $\bQ$ is the system error (i.e., the noise in the model assessment)
  - $\bB$ and $\bu$ model the control inputs to the system
  - $\bH$ is the measurement function
  - $\bz$ and $\bR$ are the measurement mean and covariance
  - $\by$ is the residual
  - $\bK$ is the Kalman gain

- Use the system model to predict the next state
  - When we multiply $\bF$ to $\bx$ we get the prior (i.e., the state before
    seeing any measurement)
- Form an estimate between the prior and the measurement

* From Univariate to Multivariate Kalman Filter

- Let's compare

\begingroup \scriptsize
\begin{tabular}{|c|c|c|c|}
\hline
  \textbf{Definition} &
  \textbf{Univariate (Bayesian)} &
  \textbf{Univariate (Kalman)} &
  \textbf{Multivariate (Kalman)} \\
\hline
\hline
  State update &
  $\overline{\mu} = \mu + \mu_{f}$ &
  $\overline{x} = x + dx$ &
  $\overline{\bx} = \bF \bx + \bB \bu$ \\

\hline
  State uncertainty &
  $\overline{\sigma}^2 = \sigma^2 + \sigma_f^2$ &
  $\overline{P} = P + Q$ &
  $\overline{\bP} = \bF \bP \bF^T + \bQ$ \\

\hline
  Residual &
  &
  $y = z - \overline{x}$ &
  $\by = \bz - \bH \overline{\bx}$ \\

\hline
  Kalman gain &
  &
  $K = \frac{\overline{P}}{\overline{P} + R}$ &
  $\bK = \overline{\bP} \bH^T (\bH \overline{\bP} \bH^T + \bR)^{-1}$ \\

\hline
  Updated state &
  $\hat{\mu}
  = \frac{\overline{\sigma}^2 \mu_z + \sigma_z^2 \overline{\mu}}
    {\overline{\sigma}^2 + \sigma_z^2}$ &
  $x = \overline{x} + K y$ &
  $\bx = \overline{\bx} + \bK \by$ \\

\hline
  Upd. state uncertainty &
  $\sigma^2
  = \frac{\overline{\sigma}^2 \sigma_z^2}{\overline{\sigma}^2 + \sigma_z^2}$ &
  $P = (1 - K) \overline{P}$ &
  $\bP = (\bI - \bK \bH) \overline{\bP}$ \\
\hline
\end{tabular}
\endgroup

* Designing a Kalman filter

- The designer of the model needs to design:
  - The form of the state $\vx$ and $\mP$
  - The system model $\mF$ and $\mQ$
  - The measurement $\vz$ and $\mR$
  - The measurement function $\mH$
  - The control inputs $\mB$ and $\vu$ if there are control inputs

## #############################################################################
## Tracking a Dog with a Kalman Filter
## #############################################################################

* Tracking 1D Dog: Problem formulation
::: columns
:::: {.column width=55%}
- There is a dog moving on a 1-d track
- The dog moves approximately 1 meter per step
  - The velocity has variance due to noise/imperfect model specification
- There is a sensor that measures the position of the dog
  - The sensor has a certain error
- Time is discrete
::::
:::: {.column width=40%}
![](msml610/lectures_source/figures/bichon_pic.jpg){ height=20%}
(Nuvolo)
::::
:::

### ############################################################################
### Predict Step
### ############################################################################

* Tracking Dog: Predict Step
- At each step, the position is described with a Gaussian distribution
  $Normal(\mu, \sigma^2)$

- The position is part of the system's state, along with the velocity
  - The position is "observed" by a sensor
  - The velocity is a "hidden" variable
  - You could use more variables (E.g., acceleration, jerk, etc.)

* Tracking Dog: Design State Covariance
- Initialize variances to reasonable values
  - E.g., $\sigma_{position} = 500m$ due to uncertainty about initial position
  - Top speed for a dog is 21m/s, so set $3 \sigma_{velocity} = 21$
  - Assume covariances to be zero due to unknown initial correlation between
    position and velocity
  - $\mP$ is diagonal

* Tracking Dog: Design System Model
- Describe mathematically the behavior of the system
  $$
  x_{t+1} = x_t + v \Delta t
  $$
- No model to predict how dog velocity changes over time
  - Assume it remains constant
    $$
    \dot{x}_{t+1} = \dot{x}_t
    $$
  - This is not correct, but if velocity doesn't change much, the filter will
    perform well
- Put the model in matrix form $\vx_{t+1} = \mF \vx_t$

* Tracking Dog: Predicting the System

- If we predict the system without measurements:
  - The state follows the system model
  - The state uncertainty grows
    - This is true even without system error (noise)

* Tracking Dog: Design System Noise

- Consider a car driving on a road with cruise control on
- It should travel at constant speed:

  $$
  x_t = \dot{x}_{t-1} \Delta t + x_{t-1}
  $$

- In reality, it is affected by unknown factors:
  - The cruise control is not perfect
  - Wind, hills, potholes affect the car
  - Passengers roll down windows, changing the drag profile of the car

- Model this as:

  $$
  \dot{x}_t = \dot{x}_{t-1} + w
  $$

- Model all of this with a covariance matrix $\mQ = \EE[\vw \cdot \vw^T]$:
  - Assume the noise is iid, has zero mean, and is independent from the system
  - For these reasons, you don't have to change the position, only the velocity

* Tracking Dog: Design the Control Function
- Incorporate control inputs to predict state based on this information
  $$
  \Delta \overline{\vx} = \mB \vu
  $$
- E.g., in the case of the car
  - Steering
  - Acceleration
- E.g., in the case of the dog, control inputs can be
  - The voice of its master
  - Seeing a squirrel

### ############################################################################
### Update Step
### ############################################################################

* Tracking Dog: Design the Measurement Function
- Kalman filter computes the update step in the measurement space

- If the measurement is in the same units as the state, the residual is simple
  to compute:

  $$
  \text{residual = measured position - predicted position}
  $$

- E.g., assume we are tracking the position of the dog using a sensor that
  outputs a voltage
  - We cannot compute the residual as:
    $$
    \text{measure voltage - predicted position}
    $$
  - We need to convert the position into voltage

- The Kalman space allows to have a measurement matrix $\mH$ to convert the
  state into a measurement

  $$
  \vy = \vz - \mH \overline{\vx}
  $$

* Why Working in Measurement and Not in State Space?
- The problem is that it is possible to convert state into measurement, but not
  vice versa because of the hidden variables
  - E.g., transform position (discarding velocity) into voltage
  - If the sensor doesn't read velocity how do we estimate the measured velocity

* Tracking Dog: Design the Measurement
- Typically $\vz$ is easy since it just contains the measurements from the
  sensor

- The measurement noise matrix $\mR$ can be difficult to estimate
  - Noise can be not Gaussian
  - There can be a bias in the sensor
  - The error can be not symmetrical (e.g., temperature sensor is less precise
    as the temperature increases)

## #############################################################################
## Non-Linear Filtering
## #############################################################################

* Optimality
- **Assumptions:**
  - Everything is linear
  - System and sensor noise is Gaussian
- Under these assumptions, the Kalman filter is optimal in a least square sense

- The Kalman filter is a mathematical model of the world
  - The output is only as accurate as the model of the world

* The World Is Non-Linear
- The Kalman filter uses linear equations and can only handle linear problems

- **The world is non-linear:**
  - System model can be non-linear:
    - Many physical systems are described by non-linear differential equations
    - E.g., a ball flying through air is affected by drag, leading to non-linear
      behaviors
  - Measurements can be non-linear:
    - To measure the height on a plane, you can measure the distance of the
      plane from the radar. Given the Pythagorean theorem, you get:
      $$
      x = \sqrt{\text{dist}^2 - \text{height}^2}
      $$

- Rarely does a physical system have equations that can be solved analytically

* Extended Kalman Filter
- Aka EKF
- EKF is a nonlinear version of the Kalman filter
  - Linearize the differential equations to compute the Jacobian (i.e., matrix
    of partial derivatives) at the point of the current estimate
  - Used for estimating the state of a nonlinear dynamic system

- Pros
  - Use the linear Kalman machinery
- Cons:
  - Analytical solution:
    - Difficult or impossible
  - Numerical solution:
    - Expensive computationally
    - Errors can compound forcing the filter to diverge (unstable)

* Unscented Kalman Filter
- Aka UKF
- It is superior to EKF in almost every way

* Intuition of Sampling Techniques
- Assume you have a distribution $X$ and a non-linearity $\phi$

- For every measurement:
  - Generate many points from $X$
  - Pass them through the non-linear function $\phi$
  - Approximate the result (E.g., compute mean and variance)

- **Problem**:
  - "How many points are needed to build an accurate output distribution"?
  - Even if $n$=500,000 points are enough for 1 dimension, for $k$ dimensions
    you might need $n^k$ points (curse of dimensionality)

* Unscented Transform
- Unscented transform estimates the result of applying a non-linear
  transformation to a probability distribution characterized by a finite number
  of moments (e.g., mean and covariance)
  - E.g., compute the non-linear transform of a distribution, given mean and
    covariance estimate
  - Called "unscented" since "it doesn't stink."

- **Intuition**
  - Given a PDF $C$ with mean $\vmu$ and covariance $\mSigma$
  - Encode mean and covariance in a set of points (sigma points) that represent
    a discrete PMF $D$ with the same mean $\vmu$ and covariance $\mSigma$
  - Propagate the discrete PMF $D$ by applying the non-linear function $\phi$ to
    each point of the PMF
  - The mean and covariance of $\phi(D)$ approximate the mean and covariance of
    $\phi(C)$

* Unscented Transform: 1D Case
- The idea is that we need 3 sigma points for a 1-d Gaussian
  - One point for the mean
  - Two points around the mean
- Each point has a weight

* Unscented Transform: Sigma Points
- Consider a distribution $F$ and a non-linearity $\phi$
- There are algorithms to generate points and weights (given the mean and
  covariance of $F$) to evaluate mean and covariance of $F$ transformed through
  $\phi$

- In $n$ dimensions, we need $2n + 1$ points $\vx_i$ and weights $w_i^m, w_i^c$

  $$
  \begin{aligned}
  \sum_i w_i^m &= 1 \\
  \sum_i w_i^c &= 1 \\
  \mu(\phi) &= \sum_i w_i^m \phi(\vx_i) \\
  \Sigma(\phi) &= \sum_i w_i^c (\phi(\vx_i) - \mu(\phi))(\phi(\vx_i) - \mu(\phi))^T \\
  \end{aligned}
  $$

- Note that selecting the sigma points has not a single solution

* Monte Carlo Sampling
- Use a finite number of randomly sampled points to represent the problem
- Run the points through the transformation (e.g., non-linear function / system
  you are modeling)
- Compute the results on the transformed points

* Particle Filters
- Aka Sequential Monte Carlo (SMC) methods
- = Monte Carlo algorithms to solve problems in Bayesian statistical inference
  (e.g., in filtering problems)
- The goal is to compute posterior distributions of the states, given some data

* Generic particle filter algorithm
1) Randomly generate particle
  - Particles have all state variable that needs to be estimated (e.g.,
    position, velocity)
  - Each particle has a weight representing the probability that it represents
    the actual state of the system
2) Predict next state of the particles
3) Update weighting
  - Update the weighting of the particles based on the measurements
  - Particles that match closely the measurements are weighted higher
4) Resample
  - Discard highly improbable particle
5) Compute estimate
  - Compute weighted mean and covariance of the particles to get an estimate of
    the state and uncertainty

# #############################################################################
# Dynamic Bayesian networks
# #############################################################################

// ## 14.5, Dynamic Bayesian networks (p. 498)

* Dynamic Bayesian Networks (DBNs)
- DBNs extend Bayesian networks to model temporal processes

- Main idea
  - "Unroll" the model over time
  - Capture intra-slice (within time) and inter-slice (across time) dependencies
- Each time slice includes:
  - State variables $X_t$
  - Evidence variables $E_t$

- Assumptions
  - First-order Markov process: current state depends only on the previous state
  - First-order sensor Markov process: evidence depends only on current state
  - Stationarity: each time slice is the same, both structure and parameters do
    not change over time
    - Structure and CPTs (Conditional Probability Tables) are the same across
      slices (time-homogeneous model)
  - No Gaussian distribution

* DBNs vs HMMs
- DBNs generalize Hidden Markov Models (HMMs)

- HMMs are a special case with a single hidden and evidence variable per time
  step

- DBNs model more complex systems than HMMs by:
  - Using multiple state variables
    - Enables modeling large systems like robot localization with many state
      components
  - Exploiting sparse connections among variables yielding compact model
    - HMM: transition matrix of size $O(d^{2n})$
    - DBN: size $O(nd^k)$ with $k$ bounded parents per variable

* DBNs vs Kalman Filters
- DBNs generalize Kalman filters

- Every Kalman filter can be represented in a DBN with:
  - Continuous variables
  - Linear / Gaussian conditional distributions

- Not every DBN can be represented by a Kalman filter, since:
  - DBN variables can mix discrete/continuous and non-Gaussian
  - Allow arbitrary conditional dependencies among variables

- **Pros of DBNs**
  - DBNs are applicable to broader domains including:
    - Fault diagnosis in networks
    - Complex system monitoring

- **Pros of Kalman filters:**
  - Optimal for linear systems with Gaussian noise
  - Support exact inference, DBNs often require approximate methods

* Constructing a DBN
- Key components of a DBN
  - Prior distribution of state $\Pr(X_0)$
  - Transition model $\Pr(X_{t+1} | X_t)$
  - Sensor model $\Pr(E_t | X_t)$
  - Transition and sensor models are time-homogeneous
- Network topology includes:
  - Intra-slice topology
  - Inter-slice links

* DBN Example: Tracking a Robot (1/3)
- **Problem:**
  - Tracking a robot moving randomly on a line $X$ over time

- **Initial model:**
  - Position $X_t$ and velocity $\dot{X_t}$ as state variables
  - Update via Newton's laws
  - Easy to generalize for 2d or 3d by using a $\vX_t$

- **Issue:**
  - Velocity changes over time
  - Battery exhaustion affects velocity systematically
  - Effect depends on cumulative energy use
  - Violates the Markov property (future depends on full history)

- **Solution:**
  - Include battery level $Battery_t$ in the state $X_t$
  - Restores the Markov assumption
  - Allows motion prediction considering energy constraints
  - Enables coherent reasoning about motion and power consumption over time

- **New requirement for state:**
  - $S_t = (X_t, \dot{X}_t, \text{BatteryLevel}_t)$
  - $E_t = (\text{GPS}_t, \text{BMeter}_t)$

* DBN Example: Tracking a Robot (2/3)
::: columns
:::: {.column width=40%}
- The DBN structure models both intra-slice (within time) and inter-slice
  (across time) dependencies

- Intra-slice dependencies:
  - Position $\text{X}_t$ influences velocity $\dot{X}_t$
  - $\text{BatteryLevel}_t$ influences velocity $\dot{X}_t$
  - $\text{Battery}_{t+1}$ depends on $\text{Battery}_t$ and $\dot{X}_t$
  - $\text{BMeter}_t$ depends on $\text{Battery}_t$
  - $\text{GPS}_t$ depends on $X_t$

- Inter-slice dependencies:
  - Position $X_{t+1}$ depends on Position $X_t$ and
    velocity $\dot{X}_t$
  - Velocity $\dot{X}_{t+1}$ depends on $\dot{X}_t$ and $\text{Battery}_t$
::::
:::: {.column width=55%}
```graphviz
digraph BayesianFlow {
    splines=true;
    nodesep=1.0;
    ranksep=0.75;

    // Default node style
    node [shape=box, style="rounded,filled", fontname="Helvetica", fontsize=12, penwidth=1.4];

    // States (rounded boxes)
    Battery_0 [label="Battery_0", fillcolor="#A6C8F4"];
    Battery_1 [label="Battery_1", fillcolor="#A6C8F4"];
    BMeter_1 [label="BMeter_1", fillcolor="#A6C8F4"];

    // Variables (circles)
    node [shape=circle];
    Xdot_0 [label="Ẋ_0", fillcolor="#B2E2B2"];
    Xdot_1 [label="Ẋ_1", fillcolor="#B2E2B2"];
    X_0 [label="X_0", fillcolor="#C6A6F4"];
    X_1 [label="X_1", fillcolor="#C6A6F4"];
    Z_1 [label="Z_1", fillcolor="#FFD1A6"];

    // Edges
    Battery_0 -> Battery_1;
    Battery_0 -> Xdot_1;
    Battery_0 -> X_1;
    Battery_1 -> BMeter_1;
    Xdot_0 -> Xdot_1;
    Xdot_0 -> X_1;
    X_0 -> X_1;
    X_1 -> Z_1;
}
```

::::
:::

* DBN Example: Tracking a Robot (3/3)

::: columns
:::: {.column width=40%}

- **Replicate for Multiple Time Slices**:
   - Create slices for $t = 0, 1, 2, \ldots$ with the above variables and
     dependencies
   - Group each time slice vertically or horizontally for clarity
- **Unrolling**:
   - Visualize the full DBN by unrolling these slices over the desired number of
     time steps (e.g., three slices for $t = 0, 1, 2$)
::::
:::: {.column width=55%}

```graphviz
digraph RobotDBN {
    splines=true;
    nodesep=1.0;
    ranksep=0.75;

    node [shape=box, style="rounded,filled", fontname="Helvetica", fontsize=12, penwidth=1.4];

    // Time slice 0 (Red)
    Battery_0_0 [label="Battery_{0}", fillcolor="#F4A6A6"];
    BMeter_0_0 [label="BMeter_{0}", fillcolor="#F4A6A6"];
    Xdot_0_0 [label="Ẋ_{0}", shape=circle, fillcolor="#F4A6A6"];
    X_0_0 [label="X_{0}", shape=circle, fillcolor="#F4A6A6"];
    Z_0_0 [label="Z_{0}", shape=circle, fillcolor="#F4A6A6"];

    // Time slice 1 (Green)
    Battery_1_1 [label="Battery_{1}", fillcolor="#B2E2B2"];
    BMeter_1_1 [label="BMeter_{1}", fillcolor="#B2E2B2"];
    Xdot_1_1 [label="Ẋ_{1}", shape=circle, fillcolor="#B2E2B2"];
    X_1_1 [label="X_{1}", shape=circle, fillcolor="#B2E2B2"];
    Z_1_1 [label="Z_{1}", shape=circle, fillcolor="#B2E2B2"];

    // Time slice 2 (Violet)
    Battery_2_2 [label="Battery_{2}", fillcolor="#C6A6F4"];
    BMeter_2_2 [label="BMeter_{2}", fillcolor="#C6A6F4"];
    Xdot_2_2 [label="Ẋ_{2}", shape=circle, fillcolor="#C6A6F4"];
    X_2_2 [label="X_{2}", shape=circle, fillcolor="#C6A6F4"];
    Z_2_2 [label="Z_{2}", shape=circle, fillcolor="#C6A6F4"];

    // Intra-slice dependencies
    Battery_0_0 -> BMeter_0_0;
    X_0_0 -> Z_0_0;

    Battery_1_1 -> BMeter_1_1;
    X_1_1 -> Z_1_1;

    Battery_2_2 -> BMeter_2_2;
    X_2_2 -> Z_2_2;

    // Inter-slice dependencies
    Battery_0_0 -> Battery_1_1;
    Battery_1_1 -> Battery_2_2;

    Xdot_0_0 -> Xdot_1_1;
    Xdot_1_1 -> Xdot_2_2;

    X_0_0 -> X_1_1;
    X_1_1 -> X_2_2;

    Xdot_0_0 -> X_1_1;
    Xdot_1_1 -> X_2_2;

    Battery_0_0 -> Xdot_1_1;
    Battery_1_1 -> Xdot_2_2;

    Xdot_0_0 -> Battery_1_1;
    Xdot_1_1 -> Battery_2_2;
}
```
::::
:::

* Inference in DBNs
- DBNs are Bayesian networks and we can use the same inference algorithms
  - "Unroll" the DBN over time (i.e., replicate slices for each time step) and
    apply standard BN inference
  - We can't unroll "forever", but we limit to a certain number of slices to
    approximate a fixed amount of time dependency

- Use recursive methods to get a constant time and space update complexity
  - Variable elimination with temporal ordering
  - At time step $t + 1$ add slice $t + 2$ and remove slice $t$ so one has
    always two slices to do inference
  - Maintains constant memory by keeping only two slices at a time

- Complexity:
  - Exponential in number of state variables ($O(nd^{n+k})$)
  - More efficient than full HMM representation ($O(d^{2n})$)

- Even though we can use DBNs to represent very complex temporal processes with
  many sparsely connected variables, we cannot reason efficiently and exactly
  about those processes
  - The prior joint distribution over all the variables is factorizable into its
    constituents CPTs
  - The posterior joint distribution conditioned on observation sequence is not
    factorizable

* Approximate Inference in DBNs
- Particle Filtering:
  - Represent belief state with weighted samples (particles)
  - Steps: propagate, weight, resample
- Benefits:
  - Focuses computation on high-probability regions
  - Maintains manageable memory and time per step
- Challenges:
  - Approximation error
  - Sensitive to transition and observation model assumptions
- Used when exact inference is computationally impractical
- Real-world application: robot localization, speech recognition

* DBN to Represent Changing Model
- We can model the fact that the system can change over time
  - Transient failure: a sensor reads wrong measures
  - Persistent failure model: we can model it with additional variables (e.g.,
    $Sensor Broken$)

* DBN: Inference
- We can unroll the DBN and get a BayesNet and then perform exact or approximate
  inference with the known methods (e.g., MCMC)

* DBN: Optimization for Inference
- Many optimizations are possible, e.g.,
  - Instead of running each sample through the entire DBN one can run all the
    samples evaluating one slice at a time to compute the posterior distribution

# ##############################################################################
# State Space Model
# ##############################################################################
