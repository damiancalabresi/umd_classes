// notes_to_pdf.py --input lectures_source/Lesson07-Bayesian_statistics_1.txt --output tmp.pdf --type slides --debug_on_error --skip_action cleanup_after --toc_type navigation

::: columns
:::: {.column width=15%}
![](msml610/lectures_source/figures/UMD_Logo.png)
::::
:::: {.column width=75%}

\vspace{0.4cm}
\begingroup \large
MSML610: Advanced Machine Learning
\endgroup
::::
:::

\vspace{1cm}

\begingroup \Large
**$$\text{\blue{Lesson 06.1: Bayesian Networks}}$$**
\endgroup
\vspace{1cm}

::: columns
:::: {.column width=75%}
\vspace{1cm}
**Instructor**: Dr. GP Saggese, [gsaggese@umd.edu](gsaggese@umd.edu)

**References**:

- AIMA (Artificial Intelligence: a Modern Approach)
  - Chap 12, Quantifying uncertainty
  - Chap 13: Probabilistic reasoning
  - Chap 14: Probabilistic reasoning over time

::::
:::: {.column width=20%}

![](msml610/lectures_source/figures/book_covers/Book_cover_AIMA.jpg){ height=20% }

::::
:::



# ##############################################################################
# Logic-Based AI Under Uncertainty
# ##############################################################################

* Logic-Based AI Under Uncertainty: Problem

- **Logic-based AI systems**:
  - Based on **propositional logic**
  - Represent **actions** using **rules** like:
    - _"If preconditions P hold, then action A causes effect E"_
  - Example:
    - _"If I turn the car key, the engine starts"_
    - **But**: the battery might be dead, there's no fuel, the starter is
      broken, etc.

- Real-world agents face **uncertainty** from:
  - Partial observability
    - Agent can't see the full state of the world
  - Non-determinism
    - Actions don't always have predictable outcomes
  - Adversarial conditions
    - Other agents may interfere

* Logic-Based AI Under Uncertainty: Naive Solution

- A possible solution to uncertainty is:

  1. Use a **belief state**, i.e., set of all possible current world states
  2. Use **causal and exhaustive augmentation** for rules
     - Must consider all possible preconditions for acting, even unlikely ones
  3. Construct **contingent plans** that handle every possible sensor report and
     belief
     - Plans become large and complex
     - No guaranteed plan may exist, yet action is required

* Logic-Based AI Under Uncertainty: Example
- **Goal**: start a car by turning the car key

- **Obvious preconditions**
  - The car has fuel
  - The car battery is charged
  - The car key is the right one
  - The starter motor is working
  - ...

- **Less obvious preconditions**
  - The fuel lines are not clogged
  - The fuel pump is working
  - The electrical system is intact (no blown fuses)
  - The engine oil level is sufficient
  - ...

- Every precondition requires something different to do to achieve the goal!

* Causal and Exhaustive Augmentation
- To use propositional logic under uncertainty, augment the left-side of
  $X \implies Y$ to make it:
  1. **Causal**: identify true causal-effect relationships
  2. **Exhaustive**: identify all possible conditions leading to the outcome

- **Logical qualification problem**
  - Enumerate all the preconditions necessary for an action to succeed

- **Difficulties**
  - Every action can have more hidden conditions in order to succeed
    - E.g., start the engine $\implies$ turn car key $\implies$ starter motor is
      working $\implies$ battery is charged $\implies$ ...
  - Preconditions can change depending on the situation
    - E.g., start the engine $\implies$ battery is charged $\implies$ it's not
      too cold $\implies$ ...

* Causal and Exhaustive Augmentation
- **Limitations** of logical qualification
  1. **Laziness**
     - Too much work to create all possible rules
  2. **Theoretical ignorance**
     - Science doesn't always have a complete theory of the domain
     - E.g., medical science doesn't know all the "rules"
  3. **Practical ignorance**
     - Even if you knew all the rules, you might not have all the information
       needed
     - E.g., not all necessary medical tests can be run for a particular patient

- Expert systems failure and AI winter (mid 1980s, 1990s)
  - The real world is complex and open-ended
  - Logical rules can't capture all necessary and sufficient conditions

* Failure of Logic-Based AI: Wet Grass Example

::: columns
:::: {.column width=65%}
- Consider the propositions:
  - $Rain$ = "it rains"
  - $WetGrass$ = "the grass is wet"

- You would expect $Rain \implies WetGrass$
::::
:::: {.column width=30%}
![](msml610/lectures_source/figures/Lesson06_grass_sprinkler.png)
::::
:::

- "$Rain \implies WetGrass$" is not true in general
  - If it rains but there is a cover over the grass, the grass will not be wet
  - If it rains but there is high temperature, the wet grass might dry quickly

- "$WetGrass \implies Rain$" is not true in general
  - The grass could be wet because of a sprinkler system
  - The grass could be wet because of morning dew

- You need to consider also the propositions:
  - $Cover$ = "there is a protective cover over the grass"
  - $Evaporate$ = "the water evaporates quickly"
  - $Sprinkler$ = "the sprinkler system is on"
  - $Dew$ = "there is morning dew"

* Failure of Logic-Based AI: Wet Grass Example

- Identify all exceptions and dependencies to make $X \implies Y$:
  1. **Causal**
     - "If it rains and there is no other source of water, the grass will be wet"
     - $Rain \implies WetGrass \lor Cover \lor Evaporate \ldots$
     - $Rain \land \lnot (Cover \land Evaporate ...) \implies WetGrass$
  2. **Exhaustive**
     - "The grass is wet, if it rains or sprinkler is on or there is morning dew"
     - $WetGrass \implies Rain \lor Sprinkler \lor Dew \ldots$
```graphviz
digraph BayesianFlow {
    splines=true;
    nodesep=1.0;
    ranksep=0.75;

    node [shape=box, style="rounded,filled", fontname="Helvetica", fontsize=12, penwidth=1.7];

    // Nodes
    Rain       [label="Rain", fillcolor="#A6C8F4"];
    WetGrass   [label="WetGrass", fillcolor="#B2E2B2"];
    Cover      [label="Cover", fillcolor="#FFD1A6"];
    Evaporate  [label="Evaporate", fillcolor="#F4A6A6"];
    Sprinkler  [label="Sprinkler", fillcolor="#A0D6D1"];
    Dew        [label="Dew", fillcolor="#A6E7F4"];

    // Force ranks
    { rank=same; Cover; Evaporate; }
    { rank=same; Sprinkler; Dew; }

    // Edges
    Rain -> WetGrass;
    Rain -> Cover;
    Rain -> Evaporate;
    Cover -> WetGrass [label="blocks", style=dashed];
    Evaporate -> WetGrass [label="blocks", style=dashed];
    Sprinkler -> WetGrass;
    Dew -> WetGrass;
}
```

* Acting Under Uncertainty: Actual Solution
- Can't use propositional logic under uncertainty

- Acting under uncertainty requires combining:
  - **Probability**: to handle uncertainty and partial knowledge
  - **Utilities**: for evaluating desirability of each outcome

- **Key idea:**
  - Rational choice = plan that maximizes expected utility
    - Performance measure: combines goals like punctuality, comfort, legal
      compliance
    - Belief: agent's internal estimate of outcome likelihoods
  - Evaluate plans based on performance on average, given known information
  - But success is not guaranteed!

* The Paradox of Probability and Knowledge
- **Paradox**
  - _"There is no uncertainty in the actual world!"_
  - E.g., the grass is wet, but either it has rained or not

- **Knowledge is subjective**
  - Probabilities relate to a knowledge state, not to the real world
  - Updating knowledge changes probability statements

* The Paradox of Probability and Knowledge
- E.g., updating belief about wet grass and rain

- Initially, you observe wet grass
  - From past data you know that $\Pr(Rain | WetGrass) = 0.8$
  - 80% chance it rained if grass is wet
  - This is the Bayesian prior

- You learn new information:
  - Sprinkler was on
  - Wet grass could be due to the sprinkler, not rain
  - Belief changes: $\Pr(Rain | WetGrass \land Sprinkler) = 0.4$
  - This is a Bayesian update

- You further observe:
  - Weather report says there was no rain
  - Certain it did not rain, despite wet grass
  - Evidence overrides prior: $\Pr(Rain | WetGrass \land WeatherReport) = 0$

- All the statements were true even if contradictory (given the state of
  knowledge!)
  - You need non-monotonic logic

# ##############################################################################
# Probabilistic Reasoning
# ##############################################################################

// From AIMA 13, Probabilistic reasoning (p. 425)

## Conditional Independence

// ## 13.1, Representing knowledge in an uncertain domain (p. 425)

* Full Joint Probability Distribution

- Consider a set of random variables $X_1, X_2, \dots, X_n$

- The **full joint probability distribution**
  - Assigns a probability to every possible world:
    $$
    \Pr(X_1 = x_1, X_2 = x_2, \dots, X_n = x_n)
    $$
    where a **possible world** is a particular assignment of values to all
    variables
  - Can answer any probabilistic query about the domain

- **Cons**
  - Size grows exponentially $k^n$ with the number of variables $n$ and number of
    values $k$
  - Impractical for real-world problems with many variables
  - Manually specifying each entry is tedious

- **Independence** (conditional and absolute) simplifies modeling
  - In the real world, many variables are not fully dependent on all others
  - Reduces the number of variables needed in the model
  - Makes compact and structured representations possible
    - E.g., factorized probabilistic models, Bayesian networks

* Independence of Random Variables: Definition
- Two random variables $X$ and $Y$ are **independent** iff:
  $$
  \Pr(X, Y) = \Pr(X) \cdot \Pr(Y)
  $$
  - Equivalently, knowing $Y$ tells nothing about $X$
  $$
  \Pr(X | Y) = \Pr(X)
  $$
- E.g.,
  - The events "coin flip" and "weather" are independent
    $$
    \Pr(Coin=Heads | Weather=Rainy) = \Pr(Coin=Heads)
    $$

- **Independence** of random variables
  - Reduces the number of parameters needed to model a system, e.g.,
    $$
    \Pr(X_1 | X_2, X_3) = \Pr(X_1)
    $$
  - Allows factorization of joint distribution, e.g.,
    $$
    \Pr(X_1, X_2, X_3) = \Pr(X_1) \cdot \Pr(X_2) \cdot \Pr(X_3)
    $$

* Conditional Independence: Definition
- Two random variables $X$ and $Y$ are **conditionally independent** given a
  random variable $Z$ iff knowing $Z$ makes $X$ and $Y$ independent:
  $$
  X \perp Y | Z \iff \Pr(X, Y | Z) = \Pr(X | Z) \cdot \Pr(Y | Z)
  $$

- **Example**
  - $X$ = _"it is raining today"_
  - $Y$ = _"a person is carrying an umbrella"_
  - $Z$ = _"the weather forecast"_
  - **Without $Z$**: there is a relationship between $X$ and $Y$ (i.e., $X$ and
    $Y$ are not independent)
  - **Given $Z$**: rain $X$ may not directly influence whether a person carries
    an umbrella $Y$
  - Thus, $X$ and $Y$ are conditionally independent given $Z$

- **Pros**
  - Conditional independence is more common than absolute independence
  - Simplify probabilistic models by factorizing the joint conditional
    distribution into product of individual conditional distributions

* Conditional Independence: Example

::: columns
:::: {.column width=65%}
- Two events can become independent once we know a third event

- **Example**
  - $Fire$ = _"there is a fire"_
  - $Toast$ = _"someone burned toast"_
  - $Alarm$ = _"the fire alarm rings"_
  - $Call$ = _"a friend calls to check on you"_

- **Dependencies**
  - $Alarm$ depends on $Fire$ or $Toast$
  - $Call$ depends on whether $Alarm$ rings

- **Conditional independence**
  - Once we know the alarm rang, the specific cause doesn't affect whether the
    friend calls
  - $\Pr(Call \mid Alarm, Fire) = \Pr(Call \mid Alarm)$

::::
:::: {.column width=30%}
```graphviz
digraph BayesianFlow {
    splines=true;
    nodesep=1.0;
    ranksep=0.75;

    node [shape=box, style="rounded,filled", fontname="Helvetica", fontsize=12, penwidth=1.4];

    Fire   [label="Fire",       fillcolor="#F4A6A6"];
    Toast  [label="Toast",      fillcolor="#FFD1A6"];
    Alarm  [label="Alarm",      fillcolor="#A6E7F4"];
    Call   [label="Call",       fillcolor="#A6C8F4"];

    { rank = same; Fire; Toast; }
    { rank = same; Call; }

    Fire  -> Alarm;
    Toast -> Alarm;
    Alarm -> Call;
}
```
::::
:::
- **Interpretation**
  - $Call$ is conditionally independent of $Fire$ and $Toast$ given $Alarm$
  - Knowing the alarm rang "blocks" the path of influence from $Fire$ and $Toast$
    to $Call$

* Conditional Independence: Garden Example

- Garden world with $Rain$, $Sprinkler$, and $WetGrass$
  - Is $\Pr(Rain | Sprinkler) = \Pr(Rain)$ ?
    - **No**: if the sprinkler is on, it's less likely it rained
    - $Rain$ and $Sprinkler$ are not independent
  - Is $\Pr(Rain | Sprinkler, WetGrass) = \Pr(Rain | WetGrass)$ ?
    - **Yes**: knowing the grass is wet, whether the sprinkler was on tells you
      nothing more about the rain
    - $Rain$ and $Sprinkler$ are conditionally independent given $WetGrass$

::: columns
:::: {.column width=60%}
- **Interpretation**:
  - Without $WetGrass$: $Rain$ and $Sprinkler$ affect each other because they
    both explain $WetGrass$
  - With $WetGrass$: once $WetGrass$ is observed, the "explaining away" effect
    occurs
::::
:::: {.column width=35%}

```graphviz
digraph BayesianFlow {
    splines=true;
    nodesep=1.0;
    ranksep=0.75;

    node [shape=box, style="rounded,filled", fontname="Helvetica", fontsize=12, penwidth=1.4];

    Rain       [label="Rain",       fillcolor="#A6C8F4"];
    Sprinkler  [label="Sprinkler",  fillcolor="#FFD1A6"];
    WetGrass   [label="WetGrass",   fillcolor="#B2E2B2"];

    { rank = same; Rain; Sprinkler; }

    Rain      -> WetGrass;
    Sprinkler -> WetGrass;

    // Added dotted arrows between Rain and Sprinkler
    Rain -> Sprinkler [style=dashed];
    Sprinkler -> Rain [style=dashed];
}
```
::::
:::

- **"Explaining away" occurs when**
  - Two variables (causes) independently influence a third variable (effect)
  - Observing the effect creates a dependence between the causes
  - Evidence for one explains the effect and reduces the need to believe in the
    other

## Bayesian Networks

* Bayesian Networks: Definition
- Aka:
  - "Bayes nets",
  - "Belief networks"
  - "Probabilistic networks"
  - "Graphical models" (somehow a broader class of statistical models)
  - "Causal networks" (arrows have special meaning)

- A **Bayesian network** is a Directed Acyclic Graph (DAG)
  1. **Nodes** $X_i$ correspond to random variables (discrete or continuous)
  2. **Edges** $X \to Y$ connect nodes and represent direct dependencies among
     variables
     - We say that $X = Parent(Y)$, $Y = Child(X)$, ancestors, spouses, ...
  3. Each node $X_i$ is associated with a **conditional probability** (CPD):
     $$
     \Pr(X_i | Parents(X_i))
     $$
     quantifying the effect of the parents on the node
     - If a node has no parents, it has a prior probability

// TODO: Add example graph

* Bayesian Network: Intuition
- Bayesian networks are the analogous for uncertain knowledge to propositional
  logic for definite knowledge
  - \red{Propositional logic} = rigid rules, i.e., `True` or `False`
  - \blue{Bayesian networks} = flexible inference, i.e., degrees of belief
  - Replace $X \implies Y$ with $\Pr(Y | X)$

- E.g., wet grass example
  - $R$ = "It is raining"
  - $W$ = "The grass is wet"
  - \red{Propositional logic}
    - If $R \rightarrow W$ and $R$ is true, then $W$ must be true
  - \blue{Bayesian network}
    - $\Pr(R = True) = 0.2$
    - $\Pr(W | R) = 0.9$
    - $\Pr(W | \neg R) = 0.1$

- E.g., medical diagnosis
  - \red{Propositional logic}
    - "Patient has disease $D$" $\implies$ "Patient has symptom $S$"
  - \blue{Bayesian network}
    - "Probability of $S$ given $D$ is high, but not certain"

* Bayesian Network and Full-joint distribution
- It can be shown that **topology** and **conditional probabilities** are
  sufficient to specify the full joint distribution
    - **Any full joint** distribution
    - **Very concisely** (often)

- Nodes are:
  - Directly influenced by their parents
  - Indirectly influenced by all their ancestors

- The topology of the network (nodes and edges) specifies conditional
  independence relationships
  - E.g., $X \to Y$ means _"$X$ has a direct influence on $Y$"_, i.e., _"$X$
    relates to $Y$"_ (not necessarily "causes")

- How to build a Bayesian Network:
  - Domain experts can decide what relationships exist among domain variables,
    determining the topology
  - Conditional probabilities can be specified or estimated

* Bayesian Networks: Wet Grass Example

::: columns
:::: {.column width=50%}
- Consider a world with 5 variables
  - $Weather$
    - Represents general environmental conditions (e.g., sunny, cloudy)
    - Can't be observed
  - $Rain$
    - Directly influenced by $Weather$
  - $Sprinkler$
    - Influenced by $Weather$ (e.g., less likely when raining)
  - $WetGrass$
    - Represents whether the grass is wet
    - Affected by both $Rain$ and $Sprinkler$
  - $StockMarketUp$
    - Indicates whether the stock market is up or down
::::
:::: {.column width=45%}
```graphviz
digraph BayesianFlow {
    splines=true;
    nodesep=1.0;
    ranksep=0.75;

    node [shape=box, style="rounded,filled", fontname="Helvetica", fontsize=12, penwidth=1.4];

    Weather       [label="Weather",       fillcolor="#A6E7F4", xlabel="P(W)"];
    Rain          [label="Rain",          fillcolor="#A6C8F4", xlabel="P(R | W)"];
    Sprinkler     [label="Sprinkler",     fillcolor="#FFD1A6", xlabel="P(S | W)"];
    WetGrass      [label="WetGrass",      fillcolor="#B2E2B2", xlabel="P(G | R, S)"];
    StockMarketUp [label="StockMarketUp", fillcolor="#C6A6F4", xlabel="P(M)"];

    { rank = same; Rain; Sprinkler; }

    Weather   -> Rain;
    Weather   -> Sprinkler;
    Rain      -> WetGrass;
    Sprinkler -> WetGrass;
}
```
::::
:::

* Bayesian Networks: Wet Grass Example
::: columns
:::: {.column width=60%}
- $Rain$ and $Sprinkler$ are **dependent** (marginally)
  $$Rain \not\perp Sprinkler \iff Rain \leftrightarrow Sprinkler$$
  - If there is no $Rain$, $Weather = sunny$ and $Sprinkler$ is more likely to
    happen (since sprinklers are usually turned on in sunny weather)
  - $Rain$ and $Sprinkler$ are related since they share a common parent $Weather$

::::
:::: {.column width=35%}
```graphviz
digraph BayesianFlow {
    splines=true;
    nodesep=1.0;
    ranksep=0.75;

    node [shape=box, style="rounded,filled", fontname="Helvetica", fontsize=12, penwidth=1.4];

    Weather       [label="Weather",       fillcolor="#A6E7F4", xlabel="P(W)"];
    Rain          [label="Rain",          fillcolor="#A6C8F4", xlabel="P(R | W)"];
    Sprinkler     [label="Sprinkler",     fillcolor="#FFD1A6", xlabel="P(S | W)"];
    WetGrass      [label="WetGrass",      fillcolor="#B2E2B2", xlabel="P(G | R, S)"];
    StockMarketUp [label="StockMarketUp", fillcolor="#C6A6F4", xlabel="P(M)"];

    { rank = same; Rain; Sprinkler; }

    Weather   -> Rain;
    Weather   -> Sprinkler;
    Rain      -> WetGrass;
    Sprinkler -> WetGrass;
}
```
::::
:::

- $Rain$ and $Sprinkler$ are **conditionally independent** given $Weather$
  $$Rain \perp Sprinkler | Weather$$
  - Once $Weather$ is fixed, knowing whether it rained tells you nothing about
    the $Sprinkler$
  - The correlation is "explained away" by $Weather$

* Bayesian Networks: Wet Grass Example
::: columns
:::: {.column width=60%}
- $Rain$ and $Sprinkler$ are **conditionally independent** given $WetGrass$,
  but only if $Weather$ is not observed
  $$Rain \perp Sprinkler | WetGrass (not Weather)$$
  - If we condition on $WetGrass$, i.e., the grass is wet, knowing that the
    sprinkler was off increases the chances that it must have rained (and vice
    versa)
::::
:::: {.column width=35%}
```graphviz
digraph BayesianFlow {
    splines=true;
    nodesep=1.0;
    ranksep=0.75;

    node [shape=box, style="rounded,filled", fontname="Helvetica", fontsize=12, penwidth=1.4];

    Weather       [label="Weather",       fillcolor="#A6E7F4", xlabel="P(W)"];
    Rain          [label="Rain",          fillcolor="#A6C8F4", xlabel="P(R | W)"];
    Sprinkler     [label="Sprinkler",     fillcolor="#FFD1A6", xlabel="P(S | W)"];
    WetGrass      [label="WetGrass",      fillcolor="#B2E2B2", xlabel="P(G | R, S)"];
    StockMarketUp [label="StockMarketUp", fillcolor="#C6A6F4", xlabel="P(M)"];

    { rank = same; Rain; Sprinkler; }

    Weather   -> Rain;
    Weather   -> Sprinkler;
    Rain      -> WetGrass;
    Sprinkler -> WetGrass;
}
```
::::
:::

- $Rain$ and $Sprinkler$ are **conditionally dependent** given $WetGrass$,
  and $Weather$
  $$Rain \not\perp Sprinkler | WetGrass, Weather$$
  - If you know that it's sunny, rain is unlikely and sprinkler likely
  - If you also know that $WetGrass$
    - If you learn $Sprinkler$ off $\implies$ must have $Rain$
  - Fork path (common cause) and collider path (common effect)

- $StockMarketUp$ is **(unconditionally) independent** of all other variables

* Conditional Probability Table
- **Conditional Probability Table** (CPT) encodes the probability of one node
  $X_i$ given its parents $Parents(X_i)$
  $$
  \Pr(X_i | Parents(X_i))
  $$

- Each row of the CPT contains the conditional probability of the node under a
  conditioning case (i.e., a possible combination of the values for the parent
  nodes)

- E.g., $\Pr(A | B, C)$

\begingroup \scriptsize
| **A**    | **P(A\|B,C)** | **P(A\|B,-C)** | **P(A\|-B,C)**  | **P(A\|-B,-C)**|
| ---------|---------------| ---------------|-----------------|-----------------|
| True     | 0.80          | 0.10           | 0.05            | 0.05 |
| False    | 0.05          | 0.85           | 0.10            | 0.0 |
\endgroup

- **Note**:
  - Natural for discrete variables, but can be extended to continuous variables
  - A conditional probability table summarizes an infinite set of circumstances
    in the table

* Bayesian Networks: Burglar Example

- Famous example from Judea Pearl

- An $Alarm$ system installed at a home in LA
  - Fairly reliable at detecting $Burglary$
  - Also responds to minor $Earthquakes$ (false positive)

- Two neighbors, $John$ and $Mary$ will $Call$ you when they hear the $Alarm$
  - $John$:
    - Almost always $Call$s when he hears the alarm
    - Sometimes confuses telephone with the $Alarm$ and $Call$s (false positives)
  - $Mary$:
    - Misses the alarm 30% of the cases (false negatives)

::: columns
:::: {.column width=60%}
- The **structure of the graph** shows that:
  - $Burglary$ and $Earthquake$ affects the event $Alarm$
  - $JohnCalls$ and $MaryCalls$ depend only on the $Alarm$, and not on
    $Burglary$ and $Earthquake$
::::
:::: {.column width=35%}
```graphviz[width=70%]
digraph BayesianFlow {
    splines=true;
    nodesep=1.0;
    ranksep=0.75;

    node [shape=box, style="rounded,filled", fontname="Helvetica", fontsize=12, penwidth=1.4];

    Burglary     [label="Burglary",     fillcolor="#A6C8F4"];
    Earthquake   [label="Earthquake",   fillcolor="#FFD1A6"];
    Alarm        [label="Alarm",        fillcolor="#B2E2B2"];
    JohnCalls    [label="JohnCalls",    fillcolor="#C6A6F4"];
    MaryCalls    [label="MaryCalls",    fillcolor="#C6A6F4"];

    { rank = same; Burglary; Earthquake; }
    { rank = same; JohnCalls; MaryCalls; }

    Burglary   -> Alarm;
    Earthquake -> Alarm;
    Alarm      -> JohnCalls;
    Alarm      -> MaryCalls;
}
```
::::
:::

* Bayesian Networks: Burglar Example
::: columns
:::: {.column width=60%}
- The probability of $Burglary$ is 0.001
- The probability of $Earthquake$ is 0.002

- $Alarm$ system
  - Is fairly reliable at detecting $Burglary$
  - Responds to minor $Earthquakes$

\begingroup \scriptsize
| **Burglary** | **Earthquake** | **P(Alarm\| B,E)** |
| ------------ | -------------- | -------------------- |
| True         | True           | 0.95                 |
| True         | False          | 0.90                 |
| False        | True           | 0.30                 |
| False        | False          | 0.01                 |
\endgroup
::::
:::: {.column width=35%}
```graphviz
digraph BayesianFlow {
    splines=true;
    nodesep=1.0;
    ranksep=0.75;

    node [shape=box, style="rounded,filled", fontname="Helvetica", fontsize=12, penwidth=1.4];

    Burglary     [label="Burglary",     fillcolor="#A6C8F4", xlabel="P(B) = 0.001"];
    Earthquake   [label="Earthquake",   fillcolor="#FFD1A6", xlabel="P(E) = 0.002"];
    Alarm        [label="Alarm",        fillcolor="#B2E2B2", xlabel="P(A | B,E)"];
    JohnCalls    [label="JohnCalls",    fillcolor="#C6A6F4", xlabel="P(J | A)"];
    MaryCalls    [label="MaryCalls",    fillcolor="#C6A6F4", xlabel="P(M | A)"];

    { rank = same; Burglary; Earthquake; }
    { rank = same; JohnCalls; MaryCalls; }

    Burglary   -> Alarm;
    Earthquake -> Alarm;
    Alarm      -> JohnCalls;
    Alarm      -> MaryCalls;
}
```
::::
:::

- Since events are independent:
  $$\Pr(Alarm) = \Pr(Alarm | Burglary, Earthquake) \Pr(Burglary) \Pr(Earthquake)$$

* Bayesian Networks: Burglar Example

- Two neighbors, $John$ and $Mary$ will $Call$ you when they hear the $Alarm$
  - $John$:
    - Almost always $Call$s when he hears the alarm
    - Sometimes confuses telephone with the $Alarm$ and $Call$s (false positives)
  - $Mary$:
    - Misses the alarm 30% of the cases (false negatives)

- $JohnCalls$ and $MaryCalls$ are represented by:

\begingroup \scriptsize
| **Alarm (A)** | **P(JohnCalls\| Alarm)** |
| ------------- | ---------------------- |
| True          | 0.90                   |
| False         | 0.05                   |
\endgroup

\begingroup \scriptsize
| **Alarm (A)** | **P(MaryCalls\| Alarm)** |
| ------------- | ---------------------- |
| True          | 0.70                   |
| False         | 0.01                   |
\endgroup

* Conditional Probability Table

::: columns
:::: {.column width=60%}
- A **node without parents** has an unconditional probability
::::
:::: {.column width=35%}
\begingroup \scriptsize
| **P(Burglary)** |
| ----------------- |
| .001              |
\endgroup

::::
:::

\vspace{0.5cm}

::: columns
:::: {.column width=40%}
- The **sum of probabilities** must be 1
  - If there is a single input variable, it is possible to remove the redundancy
::::
:::: {.column width=55%}
\vspace{-0.5cm}
\begingroup \scriptsize
| **Alarm (A)** | **P(JohnCalls\| .)** | **P(-JohnCalls \| .)** |
| ------------- | ---------------------- | ------------------------ |
| True          | 0.90                   | 0.10                     |
| False         | 0.05                   | 0.95                     |
\endgroup

\begingroup \scriptsize
| **Alarm (A)** | **P(JohnCalls\| .)** |
| ------------- | ---------------------- |
| True          | 0.90                   |
| False         | 0.05                   |
\endgroup
::::
:::

\vspace{1cm}

::: columns
:::: {.column width=60%}
- **A node with $k$ parents** has $2^k$ possible rows in the table

::::
:::: {.column width=35%}
\vspace{-0.5cm}

\begingroup \scriptsize
| **Burglary** | **Earthquake** | **P(Alarm \| .)** |
| ------------ | -------------- | ------------------- |
| T            | T              | .95                 |
| T            | F              | .94                 |
| ...          | ...            | ...                 |
\endgroup
::::
:::

